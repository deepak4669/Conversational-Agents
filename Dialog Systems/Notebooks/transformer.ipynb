{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processing\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# For visualising metrics\n",
    "from visdom import Visdom\n",
    "\n",
    "# For visualising gradients plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device found: cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"The device found: \"+str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisdomLinePlotter(object):\n",
    "    \"\"\"Plots to Visdom\"\"\"\n",
    "    \n",
    "    def __init__(self, env_name='main'):\n",
    "        self.viz = Visdom()\n",
    "        self.env = env_name\n",
    "        self.plots = {}\n",
    "    def plot(self, var_name, split_name, title_name, x, y):\n",
    "        if var_name not in self.plots:\n",
    "            self.plots[var_name] = self.viz.line(X=np.array([x,x]), Y=np.array([y,y]), env=self.env, opts=dict(\n",
    "                legend=[split_name],\n",
    "                title=title_name,\n",
    "                xlabel='Epochs',\n",
    "                ylabel=var_name\n",
    "            ))\n",
    "        else:\n",
    "            self.viz.line(X=np.array([x]), Y=np.array([y]), env=self.env, win=self.plots[var_name], name=split_name, update = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    \"\"\"\n",
    "        Plotting gradient flow across various layers\n",
    "        Thanks to: https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/2\n",
    "    \"\"\"   \n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final data corpus folder: C:\\Users\\deepa\\Conversational Agents\\Datasets\\cornell movie-dialogs corpus\n"
     ]
    }
   ],
   "source": [
    "path='C:\\\\Users\\\\deepa\\\\Conversational Agents\\\\Datasets'\n",
    "dataset='cornell movie-dialogs corpus'\n",
    "\n",
    "data_folder=os.path.join(path,dataset)\n",
    "\n",
    "print(\"The final data corpus folder: \"+str(data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_conversations():\n",
    "    \"\"\"\n",
    "    Loads movie lines and conversations from the dataset.\n",
    "    \n",
    "    data_folder: Destination where conversations and lines are stored.\n",
    "    \n",
    "    movie_lines: Consist of movie lines as given by the dataset.\n",
    "    movie_conversations: Consist of movie conversations as given by the dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "    f=open(os.path.join(data_folder,'movie_lines.txt'),'r')\n",
    "    movie_lines=f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "    f=open(os.path.join(data_folder,'movie_conversations.txt'),'r')\n",
    "    movie_conversations=f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "    return movie_lines,movie_conversations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting movie lines and movie conversations...\n",
      "Number of distinct lines: 304713\n",
      "Number of conversations: 83097\n",
      "Average Number of lines per conversations: 3.6669554857576085\n",
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "Extracting took place in: 1.0753915309906006\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "print(\"Extracting movie lines and movie conversations...\")\n",
    "movie_lines,movie_conversations=get_lines_conversations()\n",
    "\n",
    "print(\"Number of distinct lines: \"+str(len(movie_lines)))\n",
    "print(\"Number of conversations: \"+str(len(movie_conversations)))\n",
    "print(\"Average Number of lines per conversations: \"+str(len(movie_lines)/len(movie_conversations)))\n",
    "\n",
    "print(movie_lines[0])\n",
    "print(movie_conversations[0])\n",
    "\n",
    "print(\"Extracting took place in: \"+str(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLines(movie_lines,fields):\n",
    "    lines={}\n",
    "    for line in movie_lines:\n",
    "        values=line.split(\" +++$+++ \")\n",
    "        \n",
    "        lineVals={}\n",
    "        \n",
    "#         print(\"values\"+str(len(values)))\n",
    "#         print(\"fields\"+str(len(fields)))\n",
    "              \n",
    "        for i,field in enumerate(fields):\n",
    "            lineVals[field]=values[i]\n",
    "        \n",
    "        lines[lineVals['lineID']]=lineVals\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def loadConversations(movie_conversations,lines,fields):\n",
    "    conversations=[]\n",
    "    \n",
    "    for convo in movie_conversations:\n",
    "        values=convo.split(\" +++$+++ \")\n",
    "        conVals={}\n",
    "       \n",
    "        for i,field in enumerate(fields):\n",
    "            conVals[field]=values[i]\n",
    "        \n",
    "        lineIDs=eval(conVals[\"utteranceIDs\"])\n",
    "        \n",
    "        conVals[\"lines\"]=[]\n",
    "        \n",
    "        for lineID in lineIDs:\n",
    "            conVals[\"lines\"].append(lines[lineID])\n",
    "        conversations.append(conVals)\n",
    "        \n",
    "    return conversations\n",
    "\n",
    "def sentencePairs(conversations):\n",
    "    qr_pairs=[]\n",
    "    \n",
    "    for conversation in conversations:\n",
    "        for i in range(len(conversation[\"lines\"])-1):\n",
    "            query=conversation[\"lines\"][i][\"text\"].strip()\n",
    "            response=conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            \n",
    "            if query and response:\n",
    "                qr_pairs.append([query,response])\n",
    "        \n",
    "    return qr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating meaningfull information for our model...\n",
      "The number of query-response pairs are: 221282\n",
      "Separation took place in: 6.745468616485596\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "print(\"Separating meaningfull information for our model...\")\n",
    "\n",
    "lines={}\n",
    "conversations=[]\n",
    "qr_pairs=[]\n",
    "\n",
    "movie_lines_fields=[\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"]\n",
    "movie_convo_fields=[\"charcaterID\",\"character2ID\",\"movieID\",\"utteranceIDs\"]\n",
    "\n",
    "lines=loadLines(movie_lines,movie_lines_fields)\n",
    "conversations=loadConversations(movie_conversations,lines,movie_convo_fields)\n",
    "qr_pairs=sentencePairs(conversations)\n",
    "\n",
    "print(\"The number of query-response pairs are: \"+str(len(qr_pairs)))\n",
    "print(\"Separation took place in: \"+str(time.time()-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_Token=0\n",
    "START_Token=1\n",
    "END_Token=2\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.trimmed=False\n",
    "        self.word2count={}\n",
    "        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n",
    "        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n",
    "        self.num_words=3\n",
    "        \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word]=self.num_words\n",
    "            self.index2word[self.num_words]=word\n",
    "            self.word2count[word]=1\n",
    "            self.num_words=self.num_words+1\n",
    "        else:\n",
    "            self.word2count[word]+=1\n",
    "            \n",
    "    def trim(self,min_count):\n",
    "        \n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed=True\n",
    "        \n",
    "        keep_words=[]\n",
    "        \n",
    "        for word,freq in self.word2count.items():\n",
    "            if freq>=min_count:\n",
    "                keep_words.append(word)\n",
    "        \n",
    "        self.word2count={}\n",
    "        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n",
    "        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n",
    "        self.num_words=3\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset and corresponding vocabulary...\n",
      "Preparation took place in: 25.352969646453857\n"
     ]
    }
   ],
   "source": [
    "Max_Length=10\n",
    "\n",
    "def normalizeString(s):\n",
    "    s=s.lower().strip()\n",
    "    s=re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s=re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s=re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def readVocs(qr_pairs):\n",
    "    \n",
    "    for qr_pair in qr_pairs:\n",
    "        qr_pair[0]=normalizeString(qr_pair[0])\n",
    "        qr_pair[1]=normalizeString(qr_pair[1])\n",
    "    \n",
    "    voc=Vocabulary()\n",
    "    return voc,qr_pairs\n",
    "\n",
    "def filterPair(pair):\n",
    "    return len(pair[0].split(\" \"))<Max_Length and len(pair[1].split(\" \"))<Max_Length\n",
    "\n",
    "def filterPairs(qr_pairs):\n",
    "    return [pair for pair in qr_pairs if filterPair(pair)]\n",
    "\n",
    "def prepareDataset(qr_pairs):\n",
    "    voc, qr_pairs=readVocs(qr_pairs)\n",
    "    qr_pairs=filterPairs(qr_pairs)\n",
    "       \n",
    "    for pair in qr_pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "#     print(\"Number\"+str(voc.num_words))\n",
    "    return voc,qr_pairs\n",
    "\n",
    "t1=time.time()\n",
    "print(\"Preparing dataset and corresponding vocabulary...\")\n",
    "voc, pairs=prepareDataset(qr_pairs)\n",
    "print(\"Preparation took place in: \"+str(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming rare words from vocabulary and dataset..\n",
      "Trimming took place in: 0.21587419509887695\n"
     ]
    }
   ],
   "source": [
    "Min_Count=3\n",
    "\n",
    "def trimRareWords(voc,qr_pairs):\n",
    "    \n",
    "    voc.trim(Min_Count)\n",
    "    keep_pairs=[]\n",
    "    \n",
    "    for pair in qr_pairs:\n",
    "        input_sentence=pair[0]\n",
    "        output_sentence=pair[1]\n",
    "        \n",
    "        keep_input=True\n",
    "        keep_output=True\n",
    "        \n",
    "        for word in input_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input=False\n",
    "                break\n",
    "        \n",
    "        for word in output_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output=False\n",
    "                break\n",
    "                \n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "            \n",
    "    return keep_pairs\n",
    "\n",
    "t1=time.time()\n",
    "print(\"Trimming rare words from vocabulary and dataset..\")\n",
    "\n",
    "pairs=trimRareWords(voc,pairs)\n",
    "\n",
    "print(\"Trimming took place in: \"+str(time.time()-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc,sentence):\n",
    "    tokenised_sentence=[]\n",
    "    tokenised_sentence.append(START_Token)\n",
    "    \n",
    "    for word in sentence.split(\" \"):\n",
    "        tokenised_sentence.append(voc.word2index[word])\n",
    "        \n",
    "    tokenised_sentence.append(END_Token)\n",
    "    \n",
    "    assert len(tokenised_sentence)<=Max_Length+2\n",
    "    for _ in range(Max_Length+2-len(tokenised_sentence)):\n",
    "        tokenised_sentence.append(PAD_Token)\n",
    "        \n",
    "    return tokenised_sentence\n",
    "\n",
    "def binaryMatrix(l,value=PAD_Token):\n",
    "    m=[]\n",
    "    for i,seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token==value:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "        \n",
    "    return m\n",
    "\n",
    "def inputVar(voc,l):\n",
    "    \n",
    "    indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n",
    "    input_lengths=torch.tensor([len(index) for index in indexes_batch])\n",
    "    padVar=torch.LongTensor(indexes_batch)\n",
    "    return input_lengths,padVar\n",
    "\n",
    "def outputVar(voc,l):\n",
    "    indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n",
    "    max_target_len=torch.tensor([len(index) for index in indexes_batch])\n",
    "    mask=binaryMatrix(indexes_batch)\n",
    "    mask=torch.ByteTensor(mask)\n",
    "    padVar=torch.LongTensor(indexes_batch)\n",
    "    return max_target_len, mask, padVar\n",
    "\n",
    "def batch2TrainData(voc,pair_batch):\n",
    "    #sort function see \n",
    "    input_batch=[]\n",
    "    output_batch=[]\n",
    "\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "                                  \n",
    "    \n",
    "    input_lengths,tokenised_input=inputVar(voc,input_batch)\n",
    "    max_out_length,mask,tokenised_output=outputVar(voc,output_batch)\n",
    "    return input_lengths,tokenised_input,max_out_length,mask,tokenised_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of query-response pairs after all the preprocessing: \"+str(len(pairs)))\n",
    "\n",
    "#Sample batch\n",
    "batch=[random.choice(pairs) for _ in range(5)]\n",
    "input_lengths,tokenised_input,max_out_length,mask,tokenised_output=batch2TrainData(voc,batch)\n",
    "\n",
    "print(\"Input length: \"+str(input_lengths)+\" Size: \"+str(input_lengths.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Tokenised Input: \"+str(tokenised_input)+\" Size: \"+str(tokenised_input.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Max out length: \"+str(max_out_length)+\" Size: \"+str(max_out_length.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Mask: \"+str(mask)+\" Size: \"+str(mask.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Tokenised Output: \"+str(tokenised_output)+\" Size: \"+str(tokenised_output.shape))\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,encoder,decoder,source_embed,target_embed,generator):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        \n",
    "        self.source_embed=source_embed\n",
    "        self.target_embed=target_embed\n",
    "        \n",
    "        self.generator=generator # Linear + Log_softmax\n",
    "        \n",
    "    def forward(self,source,target,source_mask,target_mask):\n",
    "        return self.generator(self.decode(self.encode(source,source_mask),source_mask,target,target_mask))\n",
    "    \n",
    "    def encode(self,source,source_mask):\n",
    "        return self.encoder(self.source_embed(source),source_mask)\n",
    "    \n",
    "    def decode(self,memory, source_mask,target,target_mask):\n",
    "        return self.decoder(self.target_embed(target),memory,source_mask,target_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,vocab_size):\n",
    "        super().__init__()\n",
    "        self.projection=nn.Linear(d_model,vocab_size)\n",
    "        \n",
    "    def forward(self,decoder_output):\n",
    "        return F.log_softmax(self.projection(decoder_output),dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module,N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,layer,N):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers=clones(layer,N)\n",
    "        self.norm=LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self,x,mask):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x=layer(x,mask)\n",
    "        \n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,size,self_attn,feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn=self_attn\n",
    "        self.feed_forward=feed_forward\n",
    "        self.sublayer=clones(SublayerConnection(size,dropout),2)\n",
    "        self.size=size\n",
    "        \n",
    "    def forward(self,x,mask):\n",
    "        \n",
    "        x=self.sublayer[0](x,lambda x: self.attn(x,x,x,mask))\n",
    "        return self.sublayer[1](x,self.feed_forward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self,features,eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2=nn.Parameter(torch.ones(features))\n",
    "        self.b_2=nn.Parameter(torch.zeros(features))\n",
    "        self.eps=eps\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean=x.mean(-1,keepdim=True)\n",
    "        std=x.std(-1,keepdim=True)\n",
    "        return self.a_2*(x-mean)/(x+std)+self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \n",
    "    def __init__(self,size,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.norm=LayerNorm(size)\n",
    "        \n",
    "    def forward(self,x,sublayer):\n",
    "        return x+self.dropout(sublayer(self.norm(x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,layer,N):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers=clones(layer,N)\n",
    "        self.norm=LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self,x,memory,curr_mask,tgt_mask):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x=layer(x,memory,curr_mask,tgt_mask)\n",
    "            \n",
    "        return self.norm(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self,size,self_attn,src_attn,feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.size=size\n",
    "        self.self_attn=self_attn\n",
    "        self.src_attn=src_attn\n",
    "        self.feed_forward=feed_forward\n",
    "        \n",
    "        self.sublayer=clones(SublayerConnection(size,dropout),3)\n",
    "        \n",
    "    def forward(self,x,memory,src_mask,tgt_mask):\n",
    "        \n",
    "        m=memory\n",
    "        x=self.sublayer[0](x,lambda x:self.self_attn(x,x,x,tgt_mask))\n",
    "        x=self.sublayer[1](x,lambda x: self.src_attn(x,m,m,src_mask))\n",
    "        return self.sublayer[2](x,self.feed_forward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,h,d_model,dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_model%h==0\n",
    "        \n",
    "        self.d_k=d_model//h\n",
    "        self.h=h\n",
    "        self.linears=clones(nn.Linear(d_model,d_model),4)\n",
    "        self.attn=None\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,query,key,values,mask=None):\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask=mask.unsqueeze(1)\n",
    "            \n",
    "        nbatches=query.size(0)\n",
    "        \n",
    "        query,key,values=[l(x).view(nbatches,-1,self.h,self.d_k).transpose(1,2) for l, x in zip(self.linears,(query,key,values))]\n",
    "        \n",
    "        x,self.attn=attention(query,key,values,mask=mask,dropout=self.dropout)\n",
    "        \n",
    "        x=x.transpose(1,2).contiguous().view(nbatches,-1,self.h*self.d_k)\n",
    "        \n",
    "        return self.linears[-1](x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query,key,value,mask=None,dropout=None):\n",
    "    \n",
    "    d_k=query.size(-1)\n",
    "\n",
    "    scores=torch.matmul(query,key.transpose(-2,-1))/math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scores=scores.masked_fill(mask==0,-1e9)\n",
    "        \n",
    "    p_attn=F.softmax(scores,dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        p_attn=dropout(p_attn)\n",
    "        \n",
    "    return torch.matmul(p_attn,value),p_attn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.w_1=nn.Linear(d_model,d_ff)\n",
    "        self.w_2=nn.Linear(d_ff,d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,vocab):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed=nn.Embedding(vocab,d_model)\n",
    "        self.d_model=d_model\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.embed(x)*math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,dropout,max_len=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        pe=torch.zeros(max_len,d_model,dtype=torch.float)\n",
    "        position=torch.arange(0.,max_len).unsqueeze(1)\n",
    "        div_term=torch.exp(torch.arange(0.,d_model,2)*-(math.log(10000.0)/d_model))\n",
    "        \n",
    "        pe[:,0::2]=torch.sin(position*div_term)\n",
    "        pe[:,1::2]=torch.cos(position*div_term)\n",
    "        \n",
    "        pe=pe.unsqueeze(0)\n",
    "        self.register_buffer('pe',pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=x+Variable(self.pe[:,:x.size(1)],requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab,tgt_vocab,N=6,d_model=512,d_ff=2048,h=8,dropout=0.1):\n",
    "    \n",
    "    c=copy.deepcopy\n",
    "    attn=MultiHeadedAttention(h,d_model)\n",
    "    ff=PositionwiseFeedForward(d_model,d_ff,dropout)\n",
    "    position=PositionalEncoding(d_model,dropout)\n",
    "    model=EncoderDecoder(Encoder(EncoderLayer(d_model,c(attn),c(ff),dropout),N),\n",
    "                        Decoder(DecoderLayer(d_model,c(attn),c(attn),c(ff),dropout),N),\n",
    "                        nn.Sequential(Embeddings(d_model,src_vocab),c(position)),\n",
    "                        nn.Sequential(Embeddings(d_model,tgt_vocab),c(position)),\n",
    "                        Generator(d_model,tgt_vocab))\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model=make_model(voc.num_words,voc.num_words,1,512,2048,8,0.1)\n",
    "# print(sample_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Output size: torch.Size([5, 12, 17974])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Sample Run\n",
    "source=torch.ones(5,12,dtype=torch.long)\n",
    "target=torch.ones(5,12,dtype=torch.long)\n",
    "source_mask=None\n",
    "target_mask=torch.ones(5,12,12,dtype=torch.long)\n",
    "out=sample_model(source,target,source_mask,target_mask)\n",
    "print(\"-\"*80)\n",
    "print(\"Output size: \"+str(out.shape))\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "triu function generates a copy of matrix with elemens below kth diagonal zeroed.\n",
    "The main diagonal is zeroeth diagonal above is first(k=1) and so on.\n",
    "\n",
    "Eg:\n",
    "A=[[1,2,3],[4,5,6],[7,8,9]]\n",
    "for above matrix:\n",
    "triu(A,k=1)\n",
    "will give [[0,2,3],[0,0,6],[0,0,0]]\n",
    "\"\"\"\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    attn_shape=(1,size,size)\n",
    "    mask=np.triu(np.ones(attn_shape),k=1).astype('uint8')\n",
    "    \n",
    "    return torch.from_numpy(mask)==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data,model,loss_compute):\n",
    "    \n",
    "    start_time=time.time()\n",
    "    total_tokens=0\n",
    "    total_loss=0\n",
    "    tokens=0\n",
    "    \n",
    "    out=model.forward(data.src,data.trg,data.src_mask,data.trg_mask)\n",
    "    loss=loss_compute(out,data.trg_y,data.ntokens)\n",
    "    \n",
    "    return loss.item()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \n",
    "    def __init__(self,sample_batch,pad):\n",
    "        \n",
    "        self.src=sample_batch[1]\n",
    "        self.src_mask=self.make_src_mask(self.src,pad)\n",
    "        self.trg=sample_batch[-1][:,:-1]\n",
    "        self.trg_mask=self.make_trg_mask(self.trg,pad)\n",
    "        self.trg_y=sample_batch[-1][:,1:]\n",
    "        self.ntokens=(self.trg_y!=pad).data.sum()\n",
    "        \n",
    "    @staticmethod\n",
    "    def make_src_mask(src,pad):\n",
    "        return (src!=pad).unsqueeze(-2)\n",
    "    @staticmethod    \n",
    "    def make_trg_mask(trg,pad):\n",
    "        return (trg!=pad).unsqueeze(-2)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.criteria=nn.CrossEntropyLoss()\n",
    "    def forward(self,x,target):\n",
    "        return self.criteria(x,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LossCompute:\n",
    "    \n",
    "    def __init__(self,model,criterion,opt):\n",
    "        \n",
    "        self.criterion=criterion\n",
    "        self.opt=opt\n",
    "        self.model=model\n",
    "    \n",
    "    def __call__(self,x,y,norm):\n",
    "        \n",
    "        x=self.model.generator(x) \n",
    "        print(x.shape) #shape should be (batch_size,vocab_size)\n",
    "        print(y.shape)\n",
    "#         x=x.view(-1,x.shape[-1])\n",
    "#         y=y.view(-1)\n",
    "        x=x.transpose(-2,-1)\n",
    "    \n",
    "        \n",
    "        loss=self.criterion(x,y)/norm\n",
    "        loss.backward()\n",
    "        _=nn.utils.clip_grad_norm(model.parameters(),50000.0)\n",
    "        plot_grad_flow(self.model.named_parameters())\n",
    "        \n",
    "#         self.opt.step()\n",
    "#         self.opt.zero_grad()\n",
    "        \n",
    "        return loss.item()*norm\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(pairs,batch_size,n_batches):\n",
    "    \n",
    "    sample_batches=[batch2TrainData(voc,[random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_batches)]\n",
    "    batches=[]\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        batches.append(Batch(sample_batches[i],PAD_Token))\n",
    "    \n",
    "    return batches\n",
    "        \n",
    "batches=data_generation(pairs,5,100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'Batch' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-127-32c30683fb82>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'Batch' has no len()"
     ]
    }
   ],
   "source": [
    "print(len(batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.2212)\n"
     ]
    }
   ],
   "source": [
    "loss_fnc=nn.CrossEntropyLoss()\n",
    "x=torch.randn(5,100,11)\n",
    "target=torch.empty(5,11,dtype=torch.long).random_(100)\n",
    "out_loss=loss_fnc(x,target)\n",
    "print(out_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising and creating models....\n",
      "====================================================================================================\n",
      "Creating Models took: 0.9986324310302734\n",
      "tensor([[[ -12.2073,   -9.1461,   -9.3678,  ...,  -11.5109,   -8.9930,\n",
      "            -9.0992],\n",
      "         [ -98.7049,  -85.8148, -186.5238,  ..., -280.2966, -235.5048,\n",
      "           -73.5489],\n",
      "         [ -31.8378,  -30.6696,  -18.2382,  ...,  -27.3217,  -22.2967,\n",
      "           -36.3104],\n",
      "         ...,\n",
      "         [ -12.7466,  -10.8591,  -10.5168,  ...,  -12.0961,  -12.0082,\n",
      "           -10.0820],\n",
      "         [-125.1351, -152.2385,  -65.1978,  ...,  -43.9635, -130.3086,\n",
      "           -64.6976],\n",
      "         [  -7.6304,  -13.0883,  -11.6867,  ...,  -13.0879,  -13.7224,\n",
      "            -9.7357]],\n",
      "\n",
      "        [[ -14.2765,  -16.6503,  -19.6322,  ...,  -23.8381,  -25.5692,\n",
      "           -20.1059],\n",
      "         [  -9.0588,   -9.1729,  -13.7695,  ...,  -11.5850,  -10.3695,\n",
      "           -10.3588],\n",
      "         [ -12.0873,  -23.3037,  -51.1988,  ...,  -38.0977,   -7.8583,\n",
      "           -60.1603],\n",
      "         ...,\n",
      "         [ -15.0912,  -11.4355,  -15.4651,  ...,  -24.5282,  -21.4732,\n",
      "           -15.6429],\n",
      "         [ -10.0060,  -27.7772,  -10.4565,  ...,  -29.3425,  -25.4436,\n",
      "            -9.0025],\n",
      "         [ -41.5719,  -20.0850,  -34.7778,  ...,  -41.8302,  -25.6620,\n",
      "           -33.9512]],\n",
      "\n",
      "        [[  -9.8339,  -11.1899,  -14.8552,  ...,  -15.0743,  -12.7036,\n",
      "           -17.1827],\n",
      "         [ -10.7205,  -11.7688,  -11.9689,  ...,  -15.8447,  -11.9665,\n",
      "           -12.6074],\n",
      "         [ -10.1787,  -12.6483,   -9.7142,  ...,  -11.2864,   -9.8231,\n",
      "            -9.3754],\n",
      "         ...,\n",
      "         [ -43.2138,  -86.2398,  -39.1440,  ...,  -59.0105,  -62.2623,\n",
      "           -81.4481],\n",
      "         [ -22.3397,  -20.4495,  -32.9781,  ...,  -35.9997,  -38.1737,\n",
      "           -21.7776],\n",
      "         [ -13.0998,  -12.5735,  -11.4871,  ...,   -7.8797,   -7.3593,\n",
      "            -9.4390]],\n",
      "\n",
      "        [[ -20.9156,  -40.3500,  -25.9896,  ...,  -43.8989,  -18.1773,\n",
      "           -33.8326],\n",
      "         [ -11.3733,  -12.7999,  -37.6691,  ...,  -38.2258,  -20.2260,\n",
      "           -40.5078],\n",
      "         [  -7.9945,  -10.2741,   -8.3466,  ...,  -13.5704,  -13.3024,\n",
      "           -11.5522],\n",
      "         ...,\n",
      "         [ -12.1244,  -10.1507,   -9.5432,  ...,  -13.1654,  -10.0668,\n",
      "           -11.3636],\n",
      "         [ -66.6819,  -83.6348,  -11.7740,  ...,  -33.9313,  -63.2531,\n",
      "           -47.3448],\n",
      "         [ -12.4370,  -14.5683,  -11.1497,  ...,   -9.8430,   -8.0581,\n",
      "           -12.0331]],\n",
      "\n",
      "        [[ -11.7000,   -7.5688,  -12.9851,  ...,   -7.2726,  -12.0842,\n",
      "           -13.4891],\n",
      "         [ -17.9798,  -19.1467,  -13.6622,  ...,   -9.0252,  -17.7072,\n",
      "           -22.6330],\n",
      "         [ -42.8422,  -75.2443,  -62.0990,  ...,  -26.1506,  -54.5126,\n",
      "           -42.3928],\n",
      "         ...,\n",
      "         [  -9.8720,   -9.4504,  -12.5314,  ...,  -10.1308,   -9.3167,\n",
      "           -10.8871],\n",
      "         [ -12.9331,  -20.3175,  -39.7054,  ...,  -14.4807,  -24.1961,\n",
      "           -28.5137],\n",
      "         [ -18.3603,  -12.5313,  -10.5461,  ...,  -15.8638,  -12.6577,\n",
      "            -9.0895]]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [55 x 17974], m2: [512 x 17974] at ..\\aten\\src\\TH/generic/THTensorMath.cpp:961",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-37f60df14ac0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mcurrent_batch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mloss_val\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrun_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mLossCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmodel_opt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Epoch: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"Loss Value: \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-117-124c55e252c8>\u001b[0m in \u001b[0;36mrun_epoch\u001b[1;34m(data, model, loss_compute)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     print(\"Model's Output: \"+str(out.shape))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_compute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrg_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mntokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-120-1b90866138d9>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x, y, norm)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#shape should be (batch_size,vocab_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-90-0a9a3950fe79>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, decoder_output)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprojection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecoder_output\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    491\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 493\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    494\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1406\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1407\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1408\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1409\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: size mismatch, m1: [55 x 17974], m2: [512 x 17974] at ..\\aten\\src\\TH/generic/THTensorMath.cpp:961"
     ]
    }
   ],
   "source": [
    "print(\"Initialising and creating models....\")\n",
    "t1=time.time()\n",
    "criterion=LabelSmoothing()\n",
    "model=make_model(voc.num_words,voc.num_words)\n",
    "model_opt=torch.optim.Adam(model.parameters(),lr=0.0001,betas=(0.9,0.988),eps=1e-9)\n",
    "print(\"=\"*100)\n",
    "print(\"Creating Models took: \"+str(time.time()-t1))\n",
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(10):\n",
    "    \n",
    "    current_batch=batches[epoch]\n",
    "    loss_val=run_epoch(current_batch,model,LossCompute(model,criterion,model_opt))\n",
    "    print(\"Epoch: \"+str(epoch)+\"Loss Value: \"+str(loss_val))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
