{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processing\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# For visualising metrics\n",
    "from visdom import Visdom\n",
    "\n",
    "# For visualising gradients plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device found: cuda\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device=torch.device(\"cpu\")\n",
    "print(\"The device found: \"+str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisdomLinePlotter(object):\n",
    "    \"\"\"Plots to Visdom\"\"\"\n",
    "    \n",
    "    def __init__(self, env_name='main'):\n",
    "        self.viz = Visdom()\n",
    "        self.env = env_name\n",
    "        self.plots = {}\n",
    "    def plot(self, var_name, split_name, title_name, x, y):\n",
    "        if var_name not in self.plots:\n",
    "            self.plots[var_name] = self.viz.line(X=np.array([x,x]), Y=np.array([y,y]), env=self.env, opts=dict(\n",
    "                legend=[split_name],\n",
    "                title=title_name,\n",
    "                xlabel='Epochs',\n",
    "                ylabel=var_name\n",
    "            ))\n",
    "        else:\n",
    "            self.viz.line(X=np.array([x]), Y=np.array([y]), env=self.env, win=self.plots[var_name], name=split_name, update = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    \"\"\"\n",
    "        Plotting gradient flow across various layers\n",
    "        Thanks to: https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/2\n",
    "    \"\"\"   \n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final data corpus folder: C:\\Users\\deepa\\Conversational Agents\\Datasets\\cornell movie-dialogs corpus\n"
     ]
    }
   ],
   "source": [
    "path='C:\\\\Users\\\\deepa\\\\Conversational Agents\\\\Datasets'\n",
    "dataset='cornell movie-dialogs corpus'\n",
    "\n",
    "data_folder=os.path.join(path,dataset)\n",
    "\n",
    "print(\"The final data corpus folder: \"+str(data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_conversations():\n",
    "    \"\"\"\n",
    "    Loads movie lines and conversations from the dataset.\n",
    "    \n",
    "    data_folder: Destination where conversations and lines are stored.\n",
    "    \n",
    "    movie_lines: Consist of movie lines as given by the dataset.\n",
    "    movie_conversations: Consist of movie conversations as given by the dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "    f=open(os.path.join(data_folder,'movie_lines.txt'),'r')\n",
    "    movie_lines=f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "    f=open(os.path.join(data_folder,'movie_conversations.txt'),'r')\n",
    "    movie_conversations=f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "    return movie_lines,movie_conversations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting movie lines and movie conversations...\n",
      "Number of distinct lines: 304713\n",
      "Number of conversations: 83097\n",
      "Average Number of lines per conversations: 3.6669554857576085\n",
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "Extracting took place in: 0.3919515609741211\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "print(\"Extracting movie lines and movie conversations...\")\n",
    "movie_lines,movie_conversations=get_lines_conversations()\n",
    "\n",
    "print(\"Number of distinct lines: \"+str(len(movie_lines)))\n",
    "print(\"Number of conversations: \"+str(len(movie_conversations)))\n",
    "print(\"Average Number of lines per conversations: \"+str(len(movie_lines)/len(movie_conversations)))\n",
    "\n",
    "print(movie_lines[0])\n",
    "print(movie_conversations[0])\n",
    "\n",
    "print(\"Extracting took place in: \"+str(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLines(movie_lines,fields):\n",
    "    lines={}\n",
    "    for line in movie_lines:\n",
    "        values=line.split(\" +++$+++ \")\n",
    "        \n",
    "        lineVals={}\n",
    "        \n",
    "#         print(\"values\"+str(len(values)))\n",
    "#         print(\"fields\"+str(len(fields)))\n",
    "              \n",
    "        for i,field in enumerate(fields):\n",
    "            lineVals[field]=values[i]\n",
    "        \n",
    "        lines[lineVals['lineID']]=lineVals\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def loadConversations(movie_conversations,lines,fields):\n",
    "    conversations=[]\n",
    "    \n",
    "    for convo in movie_conversations:\n",
    "        values=convo.split(\" +++$+++ \")\n",
    "        conVals={}\n",
    "       \n",
    "        for i,field in enumerate(fields):\n",
    "            conVals[field]=values[i]\n",
    "        \n",
    "        lineIDs=eval(conVals[\"utteranceIDs\"])\n",
    "        \n",
    "        conVals[\"lines\"]=[]\n",
    "        \n",
    "        for lineID in lineIDs:\n",
    "            conVals[\"lines\"].append(lines[lineID])\n",
    "        conversations.append(conVals)\n",
    "        \n",
    "    return conversations\n",
    "\n",
    "def sentencePairs(conversations):\n",
    "    qr_pairs=[]\n",
    "    \n",
    "    for conversation in conversations:\n",
    "        for i in range(len(conversation[\"lines\"])-1):\n",
    "            query=conversation[\"lines\"][i][\"text\"].strip()\n",
    "            response=conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            \n",
    "            if query and response:\n",
    "                qr_pairs.append([query,response])\n",
    "        \n",
    "    return qr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating meaningfull information for our model...\n",
      "The number of query-response pairs are: 221282\n",
      "Separation took place in: 2.262349843978882\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "print(\"Separating meaningfull information for our model...\")\n",
    "\n",
    "lines={}\n",
    "conversations=[]\n",
    "qr_pairs=[]\n",
    "\n",
    "movie_lines_fields=[\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"]\n",
    "movie_convo_fields=[\"charcaterID\",\"character2ID\",\"movieID\",\"utteranceIDs\"]\n",
    "\n",
    "lines=loadLines(movie_lines,movie_lines_fields)\n",
    "conversations=loadConversations(movie_conversations,lines,movie_convo_fields)\n",
    "qr_pairs=sentencePairs(conversations)\n",
    "\n",
    "print(\"The number of query-response pairs are: \"+str(len(qr_pairs)))\n",
    "print(\"Separation took place in: \"+str(time.time()-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_Token=0\n",
    "START_Token=1\n",
    "END_Token=2\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.trimmed=False\n",
    "        self.word2count={}\n",
    "        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n",
    "        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n",
    "        self.num_words=3\n",
    "        \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word]=self.num_words\n",
    "            self.index2word[self.num_words]=word\n",
    "            self.word2count[word]=1\n",
    "            self.num_words=self.num_words+1\n",
    "        else:\n",
    "            self.word2count[word]+=1\n",
    "            \n",
    "    def trim(self,min_count):\n",
    "        \n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed=True\n",
    "        \n",
    "        keep_words=[]\n",
    "        \n",
    "        for word,freq in self.word2count.items():\n",
    "            if freq>=min_count:\n",
    "                keep_words.append(word)\n",
    "        \n",
    "        self.word2count={}\n",
    "        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n",
    "        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n",
    "        self.num_words=3\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset and corresponding vocabulary...\n",
      "Preparation took place in: 8.442412376403809\n"
     ]
    }
   ],
   "source": [
    "Max_Length=10\n",
    "\n",
    "def normalizeString(s):\n",
    "    s=s.lower().strip()\n",
    "    s=re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s=re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s=re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def readVocs(qr_pairs):\n",
    "    \n",
    "    for qr_pair in qr_pairs:\n",
    "        qr_pair[0]=normalizeString(qr_pair[0])\n",
    "        qr_pair[1]=normalizeString(qr_pair[1])\n",
    "    \n",
    "    voc=Vocabulary()\n",
    "    return voc,qr_pairs\n",
    "\n",
    "def filterPair(pair):\n",
    "    return len(pair[0].split(\" \"))<Max_Length and len(pair[1].split(\" \"))<Max_Length\n",
    "\n",
    "def filterPairs(qr_pairs):\n",
    "    return [pair for pair in qr_pairs if filterPair(pair)]\n",
    "\n",
    "def prepareDataset(qr_pairs):\n",
    "    voc, qr_pairs=readVocs(qr_pairs)\n",
    "    qr_pairs=filterPairs(qr_pairs)\n",
    "       \n",
    "    for pair in qr_pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "#     print(\"Number\"+str(voc.num_words))\n",
    "    return voc,qr_pairs\n",
    "\n",
    "t1=time.time()\n",
    "print(\"Preparing dataset and corresponding vocabulary...\")\n",
    "voc, pairs=prepareDataset(qr_pairs)\n",
    "print(\"Preparation took place in: \"+str(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming rare words from vocabulary and dataset..\n",
      "Trimming took place in: 0.16062235832214355\n"
     ]
    }
   ],
   "source": [
    "Min_Count=3\n",
    "\n",
    "def trimRareWords(voc,qr_pairs):\n",
    "    \n",
    "    voc.trim(Min_Count)\n",
    "    keep_pairs=[]\n",
    "    \n",
    "    for pair in qr_pairs:\n",
    "        input_sentence=pair[0]\n",
    "        output_sentence=pair[1]\n",
    "        \n",
    "        keep_input=True\n",
    "        keep_output=True\n",
    "        \n",
    "        for word in input_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input=False\n",
    "                break\n",
    "        \n",
    "        for word in output_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output=False\n",
    "                break\n",
    "                \n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "            \n",
    "    return keep_pairs\n",
    "\n",
    "t1=time.time()\n",
    "print(\"Trimming rare words from vocabulary and dataset..\")\n",
    "\n",
    "pairs=trimRareWords(voc,pairs)\n",
    "\n",
    "print(\"Trimming took place in: \"+str(time.time()-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc,sentence):\n",
    "    tokenised_sentence=[]\n",
    "    tokenised_sentence.append(START_Token)\n",
    "    \n",
    "    for word in sentence.split(\" \"):\n",
    "        tokenised_sentence.append(voc.word2index[word])\n",
    "        \n",
    "    tokenised_sentence.append(END_Token)\n",
    "    \n",
    "    assert len(tokenised_sentence)<=Max_Length+2\n",
    "    for _ in range(Max_Length+2-len(tokenised_sentence)):\n",
    "        tokenised_sentence.append(PAD_Token)\n",
    "        \n",
    "    return tokenised_sentence\n",
    "\n",
    "def binaryMatrix(l,value=PAD_Token):\n",
    "    m=[]\n",
    "    for i,seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token==value:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "        \n",
    "    return m\n",
    "\n",
    "def inputVar(voc,l):\n",
    "    \n",
    "    indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n",
    "    input_lengths=torch.tensor([len(index) for index in indexes_batch])\n",
    "    padVar=torch.LongTensor(indexes_batch)\n",
    "    return input_lengths,padVar\n",
    "\n",
    "def outputVar(voc,l):\n",
    "    indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n",
    "    max_target_len=torch.tensor([len(index) for index in indexes_batch])\n",
    "    mask=binaryMatrix(indexes_batch)\n",
    "    mask=torch.ByteTensor(mask)\n",
    "    padVar=torch.LongTensor(indexes_batch)\n",
    "    return max_target_len, mask, padVar\n",
    "\n",
    "def batch2TrainData(voc,pair_batch):\n",
    "    #sort function see \n",
    "    input_batch=[]\n",
    "    output_batch=[]\n",
    "\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "                                  \n",
    "    \n",
    "    input_lengths,tokenised_input=inputVar(voc,input_batch)\n",
    "    max_out_length,mask,tokenised_output=outputVar(voc,output_batch)\n",
    "    return input_lengths,tokenised_input,max_out_length,mask,tokenised_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of query-response pairs after all the preprocessing: 53113\n",
      "Input length: tensor([12, 12, 12, 12, 12]) Size: torch.Size([5])\n",
      "--------------------------------------------------------------------------------\n",
      "Tokenised Input: tensor([[   1,  167,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   1,    5,    7,  534,   96,   53,  498,    4,    2,    0,    0,    0],\n",
      "        [   1,    3,   37,   12,  204, 2744,   96,   45, 1011,    4,    2,    0],\n",
      "        [   1,   47,    7,  118,  492, 1710,    6,    2,    0,    0,    0,    0],\n",
      "        [   1,   16,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0]]) Size: torch.Size([5, 12])\n",
      "--------------------------------------------------------------------------------\n",
      "Max out length: tensor([12, 12, 12, 12, 12]) Size: torch.Size([5])\n",
      "--------------------------------------------------------------------------------\n",
      "Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8) Size: torch.Size([5, 12])\n",
      "--------------------------------------------------------------------------------\n",
      "Tokenised Output: tensor([[   1,   50,   37,   36,   18,    6,    2,    0,    0,    0,    0,    0],\n",
      "        [   1,  318,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   1,  124,  167,  385,  159,    6, 1014,   23,    4,    2,    0,    0],\n",
      "        [   1,   25,  148,  356,  492,    4,    2,    0,    0,    0,    0,    0],\n",
      "        [   1,   16,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0]]) Size: torch.Size([5, 12])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of query-response pairs after all the preprocessing: \"+str(len(pairs)))\n",
    "\n",
    "#Sample batch\n",
    "batch=[random.choice(pairs) for _ in range(5)]\n",
    "input_lengths,tokenised_input,max_out_length,mask,tokenised_output=batch2TrainData(voc,batch)\n",
    "\n",
    "print(\"Input length: \"+str(input_lengths)+\" Size: \"+str(input_lengths.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Tokenised Input: \"+str(tokenised_input)+\" Size: \"+str(tokenised_input.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Max out length: \"+str(max_out_length)+\" Size: \"+str(max_out_length.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Mask: \"+str(mask)+\" Size: \"+str(mask.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Tokenised Output: \"+str(tokenised_output)+\" Size: \"+str(tokenised_output.shape))\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,encoder,decoder,source_embed,target_embed,generator):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        \n",
    "        self.source_embed=source_embed\n",
    "        self.target_embed=target_embed\n",
    "        \n",
    "        self.generator=generator # Linear + Log_softmax\n",
    "        \n",
    "    def forward(self,source,target,source_mask,target_mask):\n",
    "        return self.decode(self.encode(source,source_mask),source_mask,target,target_mask)\n",
    "    \n",
    "    def encode(self,source,source_mask):\n",
    "        return self.encoder(self.source_embed(source),source_mask)\n",
    "    \n",
    "    def decode(self,memory, source_mask,target,target_mask):\n",
    "        return self.decoder(self.target_embed(target),memory,source_mask,target_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,vocab_size):\n",
    "        super().__init__()\n",
    "        self.projection=nn.Linear(d_model,vocab_size)\n",
    "        \n",
    "    def forward(self,decoder_output):\n",
    "        return F.log_softmax(self.projection(decoder_output),dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module,N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,layer,N):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers=clones(layer,N)\n",
    "        self.norm=LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self,x,mask):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x=layer(x,mask)\n",
    "        \n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self,features,eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2=nn.Parameter(torch.ones(features))\n",
    "        self.b_2=nn.Parameter(torch.zeros(features))\n",
    "        self.eps=eps\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean=x.mean(-1,keepdim=True)\n",
    "        std=x.std(-1,keepdim=True)\n",
    "        return self.a_2*(x-mean)/(std+self.eps)+self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \n",
    "    def __init__(self,size,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.norm=LayerNorm(size)\n",
    "        \n",
    "    def forward(self,x,sublayer):\n",
    "        return x+self.dropout(sublayer(self.norm(x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,size,self_attn,feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn=self_attn\n",
    "        self.feed_forward=feed_forward\n",
    "        self.sublayer=clones(SublayerConnection(size,dropout),2)\n",
    "        self.size=size\n",
    "        \n",
    "    def forward(self,x,mask):\n",
    "        \n",
    "        x=self.sublayer[0](x,lambda x: self.attn(x,x,x,mask))\n",
    "        return self.sublayer[1](x,self.feed_forward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,layer,N):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers=clones(layer,N)\n",
    "        self.norm=LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self,x,memory,curr_mask,tgt_mask):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x=layer(x,memory,curr_mask,tgt_mask)\n",
    "            \n",
    "        return self.norm(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self,size,self_attn,src_attn,feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.size=size\n",
    "        self.self_attn=self_attn\n",
    "        self.src_attn=src_attn\n",
    "        self.feed_forward=feed_forward\n",
    "        \n",
    "        self.sublayer=clones(SublayerConnection(size,dropout),3)\n",
    "        \n",
    "    def forward(self,x,memory,src_mask,tgt_mask):\n",
    "        \n",
    "        m=memory\n",
    "        x=self.sublayer[0](x,lambda x:self.self_attn(x,x,x,tgt_mask))\n",
    "        x=self.sublayer[1](x,lambda x: self.src_attn(x,m,m,src_mask))\n",
    "        return self.sublayer[2](x,self.feed_forward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query,key,value,mask=None,dropout=None):\n",
    "    \n",
    "    d_k=query.size(-1)\n",
    "\n",
    "    scores=torch.matmul(query,key.transpose(-2,-1))/math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scores=scores.masked_fill(mask==0,-1e9)\n",
    "        \n",
    "    p_attn=F.softmax(scores,dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        p_attn=dropout(p_attn)\n",
    "        \n",
    "    return torch.matmul(p_attn,value),p_attn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,h,d_model,dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_model%h==0\n",
    "        \n",
    "        self.d_k=d_model//h\n",
    "        self.h=h\n",
    "        self.linears=clones(nn.Linear(d_model,d_model),4)\n",
    "        self.attn=None\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,query,key,values,mask=None):\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask=mask.unsqueeze(1)\n",
    "            \n",
    "        nbatches=query.size(0)\n",
    "        \n",
    "        query,key,values=[l(x).view(nbatches,-1,self.h,self.d_k).transpose(1,2) for l, x in zip(self.linears,(query,key,values))]\n",
    "        \n",
    "        x,self.attn=attention(query,key,values,mask=mask,dropout=self.dropout)\n",
    "        \n",
    "        x=x.transpose(1,2).contiguous().view(nbatches,-1,self.h*self.d_k)\n",
    "        \n",
    "        return self.linears[-1](x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.w_1=nn.Linear(d_model,d_ff)\n",
    "        self.w_2=nn.Linear(d_ff,d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,vocab):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed=nn.Embedding(vocab,d_model)\n",
    "        self.d_model=d_model\n",
    "    \n",
    "    def forward(self,x):\n",
    "#         print(x.device)\n",
    "        return self.embed(x)*math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,dropout,max_len=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        pe=torch.zeros(max_len,d_model,dtype=torch.float)\n",
    "        position=torch.arange(0.,max_len).unsqueeze(1)\n",
    "        div_term=torch.exp(torch.arange(0.,d_model,2)*-(math.log(10000.0)/d_model))\n",
    "        \n",
    "        pe[:,0::2]=torch.sin(position*div_term)\n",
    "        pe[:,1::2]=torch.cos(position*div_term)\n",
    "        \n",
    "        pe=pe.unsqueeze(0)\n",
    "        self.register_buffer('pe',pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=x+Variable(self.pe[:,:x.size(1)],requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model2(src_vocab,tgt_vocab,N=6,d_model=512,d_ff=2048,h=8,dropout=0.1):\n",
    "    \n",
    "    c=copy.deepcopy\n",
    "    attn=MultiHeadedAttention(h,d_model)\n",
    "    ff=PositionwiseFeedForward(d_model,d_ff,dropout)\n",
    "    position=PositionalEncoding(d_model,dropout)\n",
    "    model=EncoderDecoder(Encoder(EncoderLayer(d_model,c(attn),c(ff),dropout),N),\n",
    "                        Decoder(DecoderLayer(d_model,c(attn),c(attn),c(ff),dropout),N),\n",
    "                        nn.Sequential(Embeddings(d_model,src_vocab),c(position)),\n",
    "                        nn.Sequential(Embeddings(d_model,tgt_vocab),c(position)),\n",
    "                        Generator(d_model,tgt_vocab))\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (source_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (embed): Embedding(7816, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (target_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (embed): Embedding(7816, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (projection): Linear(in_features=512, out_features=7816, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_model=make_model2(voc.num_words,voc.num_words,1,512,2048,8,0.1)\n",
    "sample_model.to(device)\n",
    "# print(sample_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Output size: torch.Size([5, 12, 512])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Sample Run\n",
    "source=torch.ones(5,12,dtype=torch.long,device=device)\n",
    "target=torch.ones(5,12,dtype=torch.long,device=device)\n",
    "source_mask=torch.ones(5,12,12,dtype=torch.long,device=device)\n",
    "target_mask=torch.ones(5,12,12,dtype=torch.long,device=device)\n",
    "out=sample_model(source,target,source_mask,target_mask)\n",
    "print(\"-\"*80)\n",
    "print(\"Output size: \"+str(out.shape))\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "triu function generates a copy of matrix with elemens below kth diagonal zeroed.\n",
    "The main diagonal is zeroeth diagonal above is first(k=1) and so on.\n",
    "\n",
    "Eg:\n",
    "A=[[1,2,3],[4,5,6],[7,8,9]]\n",
    "for above matrix:\n",
    "triu(A,k=1)\n",
    "will give [[0,2,3],[0,0,6],[0,0,0]]\n",
    "\"\"\"\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    attn_shape=(1,size,size)\n",
    "    mask=np.triu(np.ones(attn_shape),k=1).astype('uint8')\n",
    "    \n",
    "    return torch.from_numpy(mask)==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(pairs,batch_size,n_batches):\n",
    "    \n",
    "    sample_batches=[batch2TrainData(voc,[random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_batches)]\n",
    "    batches=[]\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        batches.append(Batch(sample_batches[i][1],sample_batches[i][-1]))\n",
    "   \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        src=torch.tensor(src).to(torch.int64)\n",
    "        trg=torch.tensor(trg).to(torch.int64)\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "        self.src.to(device)\n",
    "        self.trg.to(device)\n",
    "        self.src_mask.to(device)\n",
    "        self.trg_mask.to(device)\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data,model,loss_compute):\n",
    "    \n",
    "    start_time=time.time()\n",
    "    total_tokens=0\n",
    "    total_loss=0\n",
    "    tokens=0\n",
    "    source=data.src\n",
    "    source=source.to(device)\n",
    "    target=data.trg\n",
    "    target=target.to(device)\n",
    "    source_mask=data.src_mask\n",
    "    source_mask=source_mask.to(device)\n",
    "    target_mask=data.trg_mask\n",
    "    target_mask=target_mask.to(device)\n",
    "    target_y=data.trg_y\n",
    "    target_y=target_y.to(device)\n",
    "#     print(source.device)\n",
    "    out=model(source,target,source_mask,target_mask)\n",
    "#     print(\"Model output: \"+str(out.size()))\n",
    "    loss=loss_compute(out,target_y,data.ntokens)\n",
    "    \n",
    "    return loss.item()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "#         print(\"Before assertion: \"+str(x.size())+str(self.size))\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "#         print(str(x.size())+\" \"+str(y.size()))\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        _=nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
    "        plot_grad_flow(model.named_parameters())\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.item()* norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(batches,model,n_epochs,n_batches,criterion,model_opt,loadFile):\n",
    "    \n",
    "    start_epoch=0\n",
    "    if loadFile:\n",
    "        start_epoch=torch.load(loadFile)[\"epoch\"]\n",
    "    \n",
    "    for epoch in range(start_epoch,n_epochs):\n",
    "        t1=time.time()\n",
    "        loss=0\n",
    "        for i in range(n_batches):\n",
    "            current_batch=batches[i]\n",
    "            loss_val=run_epoch(current_batch,model,SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "            loss+=loss_val\n",
    "        print(\"Epoch: \"+str(epoch)+\" Loss Value: \"+str(loss/100))\n",
    "        print(\"Time taken: \"+str(time.time()-t1))\n",
    "\n",
    "        directory=os.path.join(save_dir,'transformer','cornell-movie')\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        torch.save({\n",
    "            \"epoch\":epoch,\n",
    "            \"model\":model.state_dict(),\n",
    "            \"opt\":model_opt.optimizer.state_dict(),\n",
    "            \"loss\":loss\n",
    "        },os.path.join(directory,'{}_{}.tar'.format(epoch,'checkpoint')))\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\deepa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "batches=data_generation(pairs,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising and creating models....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "C:\\Users\\deepa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Creating Models took: 1.2213692665100098\n",
      "Epoch: 2 Loss Value: 9.621907196044923\n",
      "Time taken: 4.151185035705566\n",
      "Epoch: 3 Loss Value: 9.47308807373047\n",
      "Time taken: 4.13934063911438\n",
      "Epoch: 4 Loss Value: 9.138953247070312\n",
      "Time taken: 4.283360242843628\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Initialising and creating models....\")\n",
    "V=voc.num_words\n",
    "t1=time.time()\n",
    "# criterion=LabelSmoothing()\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "\n",
    "model=make_model(V,V)\n",
    "model.cuda()\n",
    "\n",
    "# model_opt=torch.optim.Adam(model.parameters(),lr=0.0001,betas=(0.9,0.988),eps=1e-9)\n",
    "model_opt = NoamOpt(model.src_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "print(\"=\"*100)\n",
    "print(\"Creating Models took: \"+str(time.time()-t1))\n",
    "\n",
    "save_dir='C:\\\\Users\\\\deepa\\\\Conversational Agents'\n",
    "loadFile=os.path.join(save_dir,'transformer','cornell-movie','2_checkpoint')\n",
    "loadFile=\"C:\\\\Users\\\\deepa\\\\Conversational Agents\\\\transformer\\\\cornell-movie\\\\2_checkpoint.tar\"\n",
    "\n",
    "if(loadFile):\n",
    "    checkpoint=torch.load(loadFile)\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "    model_opt.optimizer.load_state_dict(checkpoint['opt'])\n",
    "    \n",
    "    \n",
    "\n",
    "model.train()\n",
    "training(batches,model,5,5,criterion,model_opt,loadFile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (norm): LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (src_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(7816, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (tgt_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (lut): Embedding(7816, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (proj): Linear(in_features=512, out_features=7816, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(997)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'dad', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'yes', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(3)\n",
      "tensor(37)\n",
      "tensor(34)\n",
      "tensor(5978)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'there', 's', 'no', 'mirror', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'there', 's', 'not', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(4111)\n",
      "tensor(1075)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'butch', 'called', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'did', 'he', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(76)\n",
      "tensor(271)\n",
      "tensor(117)\n",
      "tensor(504)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'it', 'isn', 't', 'finished', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'no', 'mr', '.', 'kane', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(68)\n",
      "tensor(7)\n",
      "tensor(41)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'did', 'you', 'say', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'd', 'think', 'about', 'it', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(92)\n",
      "tensor(7)\n",
      "tensor(96)\n",
      "tensor(53)\n",
      "tensor(533)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'are', 'you', 'in', 'the', 'service', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'the', 'postal', 'service', '.', 'i', 'm', 'a', 'mailman', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(77)\n",
      "tensor(387)\n",
      "tensor(25)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'who', 'am', 'i', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'don', 't', 'know', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(76)\n",
      "tensor(37)\n",
      "tensor(2196)\n",
      "tensor(96)\n",
      "tensor(159)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'it', 's', 'dark', 'in', 'here', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'get', 'used', 'to', 'the', 'darkness', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(5443)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'madeleine', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'please', 'let', 'me', 'go', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(122)\n",
      "tensor(50)\n",
      "tensor(47)\n",
      "tensor(7)\n",
      "tensor(614)\n",
      "tensor(45)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'and', 'what', 'do', 'you', 'call', 'this', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'the', 'family', 'jewels', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(197)\n",
      "tensor(117)\n",
      "tensor(669)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'don', 't', 'worry', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'why', 'not', 'what', 'are', 'you', 'going', 'to', 'do', '?', 'EOS']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(25)\n",
      "tensor(2632)\n",
      "tensor(36)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', '.', '.', '.', 'i', 'needed', 'that', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'tell', 'me', 'about', 'it', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(76)\n",
      "tensor(37)\n",
      "tensor(112)\n",
      "tensor(12)\n",
      "tensor(3869)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'it', 's', 'just', 'a', 'corpse', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'know', 'that', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(131)\n",
      "tensor(65)\n",
      "tensor(197)\n",
      "tensor(117)\n",
      "tensor(18)\n",
      "tensor(50)\n",
      "tensor(25)\n",
      "tensor(118)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'because', 'they', 'don', 't', 'like', 'what', 'i', 'want', '.', 'EOS', 'PAD']\n",
      "['SOS', 'what', 's', 'that', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(280)\n",
      "tensor(98)\n",
      "tensor(12)\n",
      "tensor(1544)\n",
      "tensor(565)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'care', 'for', 'a', 'hot', 'dog', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'buying', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(76)\n",
      "tensor(37)\n",
      "tensor(265)\n",
      "tensor(109)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'it', 's', 'friday', 'night', '.', '.', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'yes', '.', 'do', 'you', 'have', 'a', 'date', '?', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(101)\n",
      "tensor(37)\n",
      "tensor(187)\n",
      "tensor(4816)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'he', 's', 'dead', 'sheila', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'feel', 'sick', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(1263)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'mother', '.', '.', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'know', 'son', 'i', 'know', '.', '.', '.', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(200)\n",
      "tensor(512)\n",
      "tensor(98)\n",
      "tensor(492)\n",
      "tensor(6689)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'm', 'looking', 'for', 'some', 'perfume', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'any', 'particular', 'brand', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(33)\n",
      "tensor(197)\n",
      "tensor(117)\n",
      "tensor(7)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'well', 'don', 't', 'you', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 're', 'always', 'teasing', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(5935)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'luke', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'hi', 'han', '.', '.', '.', 'chewie', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(424)\n",
      "tensor(76)\n",
      "tensor(40)\n",
      "tensor(83)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'give', 'it', 'to', 'me', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'when', 'you', 'bring', 'in', 'doucet', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(1947)\n",
      "tensor(153)\n",
      "tensor(27)\n",
      "tensor(38)\n",
      "tensor(778)\n",
      "tensor(75)\n",
      "tensor(7)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'brother', 'were', 'we', 'all', 'wet', 'about', 'you', '!', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'forget', 'it', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(83)\n",
      "tensor(252)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'me', 'neither', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'what', 's', 'gotten', 'into', 'you', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(167)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'yeah', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'someone', 'got', 'hurt', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(34)\n",
      "tensor(953)\n",
      "tensor(95)\n",
      "tensor(5547)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'no', 'choice', 'now', 'scotty', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'sir', 'heat', 'shields', 'at', 'maximum', '!', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(167)\n",
      "tensor(523)\n",
      "tensor(53)\n",
      "tensor(2414)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'yeah', 'watch', 'the', 'road', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'll', 'total', 'the', 'whole', 'car', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(2336)\n",
      "tensor(112)\n",
      "tensor(212)\n",
      "tensor(40)\n",
      "tensor(53)\n",
      "tensor(596)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'nothin', 'just', 'goin', 'to', 'the', 'bathroom', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'is', 'anything', 'wrong', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'down', 'and', 'not', 'steak', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(2979)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'toy', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 't', 'o', 'y', '.', 'toy', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(2666)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'cooper', '.', '.', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'yeah', '?', '.', '.', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(665)\n",
      "tensor(4960)\n",
      "tensor(4)\n",
      "tensor(147)\n",
      "tensor(153)\n",
      "tensor(19)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'morning', 'radar', '.', 'how', 'were', 'things', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'splendid', 'sir', '.', 'no', 'problems', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(131)\n",
      "tensor(101)\n",
      "tensor(102)\n",
      "tensor(3211)\n",
      "tensor(75)\n",
      "tensor(83)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'because', 'he', 'was', 'worried', 'about', 'me', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'your', 'husband', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(266)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'right', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'so', 'it', 's', 'on', 'the', 'street', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(47)\n",
      "tensor(27)\n",
      "tensor(47)\n",
      "tensor(95)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'do', 'we', 'do', 'now', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'we', 'wait', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(389)\n",
      "tensor(7)\n",
      "tensor(50)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'may', 'you', 'what', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'oh', 'nothing', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(76)\n",
      "tensor(37)\n",
      "tensor(107)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'it', 's', 'beautiful', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'just', 'a', 'little', 'you', 'know', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(95)\n",
      "tensor(50)\n",
      "tensor(37)\n",
      "tensor(45)\n",
      "tensor(47)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'now', 'what', 's', 'this', 'do', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'goes', 'up', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(74)\n",
      "tensor(76)\n",
      "tensor(37)\n",
      "tensor(112)\n",
      "tensor(935)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'think', 'it', 's', 'just', 'over', 'there', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'is', 'that', 'what', 'i', 'think', 'it', 'is', '?', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(76)\n",
      "tensor(405)\n",
      "tensor(2199)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'it', 'says', 'ray', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'sweet', '.', 'hey', 'you', 'got', 'a', 'tattoo', 'too', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'hot', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(34)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'no', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'underwear', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(76)\n",
      "tensor(102)\n",
      "tensor(177)\n",
      "tensor(12)\n",
      "tensor(2559)\n",
      "tensor(191)\n",
      "tensor(117)\n",
      "tensor(76)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'it', 'was', 'on', 'a', 'sunday', 'wasn', 't', 'it', '?', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'don', 't', 'remember', '.', 'maybe', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(65)\n",
      "tensor(215)\n",
      "tensor(7)\n",
      "tensor(14)\n",
      "tensor(53)\n",
      "tensor(180)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'they', 'said', 'you', 're', 'the', 'one', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'the', 'one', 'what', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(2699)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'treadstone', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'never', 'heard', 'of', 'it', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(281)\n",
      "tensor(67)\n",
      "tensor(7)\n",
      "tensor(35)\n",
      "tensor(77)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'if', 'not', 'you', 'then', 'who', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'mueller', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(318)\n",
      "tensor(1435)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'yes', 'baron', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'and', 'as', 'for', 'you', 'waiter', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'a', 'little', 'pounds', '?', 'EOS', '?', 'EOS']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-eb3f463891d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msource\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0msource_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_mask\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0moutput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgreedy_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msource_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0msrc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mtrg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-9f44eb0aa859>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[1;34m(model, src, src_mask, max_len, start_symbol)\u001b[0m\n\u001b[0;32m      6\u001b[0m                            \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m                            Variable(subsequent_mask(ys.size(1))\n\u001b[1;32m----> 8\u001b[1;33m                                     .type_as(src.data)))\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mprob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_word\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-47-8b5c5d485387>\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, memory, src_mask, tgt, tgt_mask)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtgt_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-4cfe73c881ce>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-55-4d66f66320a7>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, memory, src_mask, tgt_mask)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mself_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_attn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeed_forward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-b1fea0696ed6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, sublayer)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msublayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[1;34m\"Apply residual connection to any sublayer with the same size.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msublayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-51-cb52f652a350>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mmean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mstd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ma_2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstd\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meps\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch in batches:\n",
    "    for i in range(5):\n",
    "        source=batch.src[i].view(-1,12).to(device)\n",
    "        source_mask=batch.src_mask[i].view(1,-1,12).to(device)\n",
    "        output=greedy_decode(model,source,source_mask,10,1)\n",
    "        src=batch.src[i].view(-1)\n",
    "        trg=batch.trg[i].view(-1)\n",
    "        pred=output.view(-1)\n",
    "        print(src.size())\n",
    "        for id in src:\n",
    "            print(id)\n",
    "        src_sentence=[voc.index2word[id.item()] for id in src]\n",
    "        trg_sentence=[voc.index2word[id.item()] for id in trg]\n",
    "        pred_sentence=[voc.index2word[id.item()] for id in pred]\n",
    "        print(src_sentence)\n",
    "        print(trg_sentence)\n",
    "        print(pred_sentence)\n",
    "        print(\"-\"*80)\n",
    "#         print(\"-\"*80)\n",
    "#         print(str(output)+\" \"+str(batch.src[i])+\" \"+str(batch.trg[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2, 10, 10,  9,  5,  3,  2,  9,  5]])\n"
     ]
    }
   ],
   "source": [
    "src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]) )\n",
    "src_mask = Variable(torch.ones(1, 1, 10) )\n",
    "print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,sentence,max_length):\n",
    "    input_tokens=[indexesFromSentence(voc,sentence)]\n",
    "    input_tokens=torch.LongTensor(input_tokens)\n",
    "    input_mask=(input_tokens!=0)\n",
    "    input_tokens=input_tokens.view(1,-1,12)\n",
    "    input_mask=input_mask.view(-1,12)\n",
    "    \n",
    "    output_tokens=greedy_decode(model,input_tokens,input_mask,max_length,1)\n",
    "    output_tokens=output_tokens.view(-1)\n",
    "    decoded_words=[voc.index2word[id.item()] for id in output_tokens]\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateInput(model,voc,max_length):\n",
    "    \n",
    "    input_sentence=''\n",
    "    \n",
    "    while(1):\n",
    "        try:\n",
    "            input_sentence=input('<')\n",
    "            if(input_sentence=='q' or input_sentence=='quit'):\n",
    "                break\n",
    "            input_sentence=normalizeString(input_sentence)\n",
    "            output_words=evaluate(model,input_sentence,max_length)\n",
    "            output_words=[x for x in output_words if not(x=='EOS' or x=='PAD')]\n",
    "            print('Bot: ',' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Unknown Words\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hello there\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_index_select",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-b88dc530373f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mevaluateInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-75-4723eefc1395>\u001b[0m in \u001b[0;36mevaluateInput\u001b[1;34m(model, voc, max_length)\u001b[0m\n\u001b[0;32m     21\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0minput_sentence\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnormalizeString\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0moutput_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_sentence\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0moutput_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_words\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'EOS'\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'PAD'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Bot: '\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-75-4723eefc1395>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(model, sentence, max_length)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0minput_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0moutput_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgreedy_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0moutput_tokens\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_tokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mdecoded_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mid\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_tokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-72-9f44eb0aa859>\u001b[0m in \u001b[0;36mgreedy_decode\u001b[1;34m(model, src, src_mask, max_len, start_symbol)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgreedy_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mmemory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_symbol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype_as\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         out = model.decode(memory, src_mask, \n",
      "\u001b[1;32m<ipython-input-47-8b5c5d485387>\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, src, src_mask)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msrc_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msrc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtgt_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-60-c147fc65cd16>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlut\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0md_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m         return F.embedding(\n\u001b[0;32m    113\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   1482\u001b[0m         \u001b[1;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1483\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1484\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected object of device type cuda but got device type cpu for argument #3 'index' in call to _th_index_select"
     ]
    }
   ],
   "source": [
    "evaluateInput(model,voc,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
