{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-Processing\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "#Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# For visualising metrics\n",
    "from visdom import Visdom\n",
    "\n",
    "# For visualising gradients plot\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The device found: cpu\n"
     ]
    }
   ],
   "source": [
    "device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(\"The device found: \"+str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisdomLinePlotter(object):\n",
    "    \"\"\"Plots to Visdom\"\"\"\n",
    "    \n",
    "    def __init__(self, env_name='main'):\n",
    "        self.viz = Visdom()\n",
    "        self.env = env_name\n",
    "        self.plots = {}\n",
    "    def plot(self, var_name, split_name, title_name, x, y):\n",
    "        if var_name not in self.plots:\n",
    "            self.plots[var_name] = self.viz.line(X=np.array([x,x]), Y=np.array([y,y]), env=self.env, opts=dict(\n",
    "                legend=[split_name],\n",
    "                title=title_name,\n",
    "                xlabel='Epochs',\n",
    "                ylabel=var_name\n",
    "            ))\n",
    "        else:\n",
    "            self.viz.line(X=np.array([x]), Y=np.array([y]), env=self.env, win=self.plots[var_name], name=split_name, update = 'append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    \"\"\"\n",
    "        Plotting gradient flow across various layers\n",
    "        Thanks to: https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/2\n",
    "    \"\"\"   \n",
    "    ave_grads = []\n",
    "    layers = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            ave_grads.append(p.grad.abs().mean())\n",
    "    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlim(xmin=0, xmax=len(ave_grads))\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The final data corpus folder: C:\\Users\\deepa\\Conversational Agents\\Datasets\\cornell movie-dialogs corpus\n"
     ]
    }
   ],
   "source": [
    "path='C:\\\\Users\\\\deepa\\\\Conversational Agents\\\\Datasets'\n",
    "dataset='cornell movie-dialogs corpus'\n",
    "\n",
    "data_folder=os.path.join(path,dataset)\n",
    "\n",
    "print(\"The final data corpus folder: \"+str(data_folder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lines_conversations():\n",
    "    \"\"\"\n",
    "    Loads movie lines and conversations from the dataset.\n",
    "    \n",
    "    data_folder: Destination where conversations and lines are stored.\n",
    "    \n",
    "    movie_lines: Consist of movie lines as given by the dataset.\n",
    "    movie_conversations: Consist of movie conversations as given by the dataset.\n",
    "    \n",
    "    \"\"\"\n",
    "    f=open(os.path.join(data_folder,'movie_lines.txt'),'r')\n",
    "    movie_lines=f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "    f=open(os.path.join(data_folder,'movie_conversations.txt'),'r')\n",
    "    movie_conversations=f.read().splitlines()\n",
    "    f.close()\n",
    "    \n",
    "    return movie_lines,movie_conversations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting movie lines and movie conversations...\n",
      "Number of distinct lines: 304713\n",
      "Number of conversations: 83097\n",
      "Average Number of lines per conversations: 3.6669554857576085\n",
      "L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n",
      "u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n",
      "Extracting took place in: 0.35601353645324707\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "print(\"Extracting movie lines and movie conversations...\")\n",
    "movie_lines,movie_conversations=get_lines_conversations()\n",
    "\n",
    "print(\"Number of distinct lines: \"+str(len(movie_lines)))\n",
    "print(\"Number of conversations: \"+str(len(movie_conversations)))\n",
    "print(\"Average Number of lines per conversations: \"+str(len(movie_lines)/len(movie_conversations)))\n",
    "\n",
    "print(movie_lines[0])\n",
    "print(movie_conversations[0])\n",
    "\n",
    "print(\"Extracting took place in: \"+str(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadLines(movie_lines,fields):\n",
    "    lines={}\n",
    "    for line in movie_lines:\n",
    "        values=line.split(\" +++$+++ \")\n",
    "        \n",
    "        lineVals={}\n",
    "        \n",
    "#         print(\"values\"+str(len(values)))\n",
    "#         print(\"fields\"+str(len(fields)))\n",
    "              \n",
    "        for i,field in enumerate(fields):\n",
    "            lineVals[field]=values[i]\n",
    "        \n",
    "        lines[lineVals['lineID']]=lineVals\n",
    "    \n",
    "    return lines\n",
    "\n",
    "def loadConversations(movie_conversations,lines,fields):\n",
    "    conversations=[]\n",
    "    \n",
    "    for convo in movie_conversations:\n",
    "        values=convo.split(\" +++$+++ \")\n",
    "        conVals={}\n",
    "       \n",
    "        for i,field in enumerate(fields):\n",
    "            conVals[field]=values[i]\n",
    "        \n",
    "        lineIDs=eval(conVals[\"utteranceIDs\"])\n",
    "        \n",
    "        conVals[\"lines\"]=[]\n",
    "        \n",
    "        for lineID in lineIDs:\n",
    "            conVals[\"lines\"].append(lines[lineID])\n",
    "        conversations.append(conVals)\n",
    "        \n",
    "    return conversations\n",
    "\n",
    "def sentencePairs(conversations):\n",
    "    qr_pairs=[]\n",
    "    \n",
    "    for conversation in conversations:\n",
    "        for i in range(len(conversation[\"lines\"])-1):\n",
    "            query=conversation[\"lines\"][i][\"text\"].strip()\n",
    "            response=conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            \n",
    "            if query and response:\n",
    "                qr_pairs.append([query,response])\n",
    "        \n",
    "    return qr_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Separating meaningfull information for our model...\n",
      "The number of query-response pairs are: 221282\n",
      "Separation took place in: 2.5202975273132324\n"
     ]
    }
   ],
   "source": [
    "t1=time.time()\n",
    "print(\"Separating meaningfull information for our model...\")\n",
    "\n",
    "lines={}\n",
    "conversations=[]\n",
    "qr_pairs=[]\n",
    "\n",
    "movie_lines_fields=[\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"]\n",
    "movie_convo_fields=[\"charcaterID\",\"character2ID\",\"movieID\",\"utteranceIDs\"]\n",
    "\n",
    "lines=loadLines(movie_lines,movie_lines_fields)\n",
    "conversations=loadConversations(movie_conversations,lines,movie_convo_fields)\n",
    "qr_pairs=sentencePairs(conversations)\n",
    "\n",
    "print(\"The number of query-response pairs are: \"+str(len(qr_pairs)))\n",
    "print(\"Separation took place in: \"+str(time.time()-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_Token=0\n",
    "START_Token=1\n",
    "END_Token=2\n",
    "\n",
    "class Vocabulary:\n",
    "    def __init__(self):\n",
    "        self.trimmed=False\n",
    "        self.word2count={}\n",
    "        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n",
    "        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n",
    "        self.num_words=3\n",
    "        \n",
    "    def addSentence(self,sentence):\n",
    "        for word in sentence.split(\" \"):\n",
    "            self.addWord(word)\n",
    "    def addWord(self,word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word]=self.num_words\n",
    "            self.index2word[self.num_words]=word\n",
    "            self.word2count[word]=1\n",
    "            self.num_words=self.num_words+1\n",
    "        else:\n",
    "            self.word2count[word]+=1\n",
    "            \n",
    "    def trim(self,min_count):\n",
    "        \n",
    "        if self.trimmed:\n",
    "            return\n",
    "        self.trimmed=True\n",
    "        \n",
    "        keep_words=[]\n",
    "        \n",
    "        for word,freq in self.word2count.items():\n",
    "            if freq>=min_count:\n",
    "                keep_words.append(word)\n",
    "        \n",
    "        self.word2count={}\n",
    "        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n",
    "        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n",
    "        self.num_words=3\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing dataset and corresponding vocabulary...\n",
      "Preparation took place in: 8.285846710205078\n"
     ]
    }
   ],
   "source": [
    "Max_Length=10\n",
    "\n",
    "def normalizeString(s):\n",
    "    s=s.lower().strip()\n",
    "    s=re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s=re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s=re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def readVocs(qr_pairs):\n",
    "    \n",
    "    for qr_pair in qr_pairs:\n",
    "        qr_pair[0]=normalizeString(qr_pair[0])\n",
    "        qr_pair[1]=normalizeString(qr_pair[1])\n",
    "    \n",
    "    voc=Vocabulary()\n",
    "    return voc,qr_pairs\n",
    "\n",
    "def filterPair(pair):\n",
    "    return len(pair[0].split(\" \"))<Max_Length and len(pair[1].split(\" \"))<Max_Length\n",
    "\n",
    "def filterPairs(qr_pairs):\n",
    "    return [pair for pair in qr_pairs if filterPair(pair)]\n",
    "\n",
    "def prepareDataset(qr_pairs):\n",
    "    voc, qr_pairs=readVocs(qr_pairs)\n",
    "    qr_pairs=filterPairs(qr_pairs)\n",
    "       \n",
    "    for pair in qr_pairs:\n",
    "        voc.addSentence(pair[0])\n",
    "        voc.addSentence(pair[1])\n",
    "#     print(\"Number\"+str(voc.num_words))\n",
    "    return voc,qr_pairs\n",
    "\n",
    "t1=time.time()\n",
    "print(\"Preparing dataset and corresponding vocabulary...\")\n",
    "voc, pairs=prepareDataset(qr_pairs)\n",
    "print(\"Preparation took place in: \"+str(time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trimming rare words from vocabulary and dataset..\n",
      "Trimming took place in: 0.2712748050689697\n"
     ]
    }
   ],
   "source": [
    "Min_Count=3\n",
    "\n",
    "def trimRareWords(voc,qr_pairs):\n",
    "    \n",
    "    voc.trim(Min_Count)\n",
    "    keep_pairs=[]\n",
    "    \n",
    "    for pair in qr_pairs:\n",
    "        input_sentence=pair[0]\n",
    "        output_sentence=pair[1]\n",
    "        \n",
    "        keep_input=True\n",
    "        keep_output=True\n",
    "        \n",
    "        for word in input_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_input=False\n",
    "                break\n",
    "        \n",
    "        for word in output_sentence.split(\" \"):\n",
    "            if word not in voc.word2index:\n",
    "                keep_output=False\n",
    "                break\n",
    "                \n",
    "        if keep_input and keep_output:\n",
    "            keep_pairs.append(pair)\n",
    "            \n",
    "    return keep_pairs\n",
    "\n",
    "t1=time.time()\n",
    "print(\"Trimming rare words from vocabulary and dataset..\")\n",
    "\n",
    "pairs=trimRareWords(voc,pairs)\n",
    "\n",
    "print(\"Trimming took place in: \"+str(time.time()-t1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(voc,sentence):\n",
    "    tokenised_sentence=[]\n",
    "    tokenised_sentence.append(START_Token)\n",
    "    \n",
    "    for word in sentence.split(\" \"):\n",
    "        tokenised_sentence.append(voc.word2index[word])\n",
    "        \n",
    "    tokenised_sentence.append(END_Token)\n",
    "    \n",
    "    assert len(tokenised_sentence)<=Max_Length+2\n",
    "    for _ in range(Max_Length+2-len(tokenised_sentence)):\n",
    "        tokenised_sentence.append(PAD_Token)\n",
    "        \n",
    "    return tokenised_sentence\n",
    "\n",
    "def binaryMatrix(l,value=PAD_Token):\n",
    "    m=[]\n",
    "    for i,seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token==value:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "        \n",
    "    return m\n",
    "\n",
    "def inputVar(voc,l):\n",
    "    \n",
    "    indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n",
    "    input_lengths=torch.tensor([len(index) for index in indexes_batch])\n",
    "    padVar=torch.LongTensor(indexes_batch)\n",
    "    return input_lengths,padVar\n",
    "\n",
    "def outputVar(voc,l):\n",
    "    indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n",
    "    max_target_len=torch.tensor([len(index) for index in indexes_batch])\n",
    "    mask=binaryMatrix(indexes_batch)\n",
    "    mask=torch.ByteTensor(mask)\n",
    "    padVar=torch.LongTensor(indexes_batch)\n",
    "    return max_target_len, mask, padVar\n",
    "\n",
    "def batch2TrainData(voc,pair_batch):\n",
    "    #sort function see \n",
    "    input_batch=[]\n",
    "    output_batch=[]\n",
    "\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[1])\n",
    "                                  \n",
    "    \n",
    "    input_lengths,tokenised_input=inputVar(voc,input_batch)\n",
    "    max_out_length,mask,tokenised_output=outputVar(voc,output_batch)\n",
    "    return input_lengths,tokenised_input,max_out_length,mask,tokenised_output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of query-response pairs after all the preprocessing: 53113\n",
      "Input length: tensor([12, 12, 12, 12, 12]) Size: torch.Size([5])\n",
      "--------------------------------------------------------------------------------\n",
      "Tokenised Input: tensor([[   1,   16,  147,   92,    7,    6,    2,    0,    0,    0,    0,    0],\n",
      "        [   1, 1503,    4,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   1,    7,  379,   41,   36,    4,    2,    0,    0,    0,    0,    0],\n",
      "        [   1,  318,    6,    2,    0,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   1,   38,  266, 2727,   50,   47,    7,  456,    6,    2,    0,    0]]) Size: torch.Size([5, 12])\n",
      "--------------------------------------------------------------------------------\n",
      "Max out length: tensor([12, 12, 12, 12, 12]) Size: torch.Size([5])\n",
      "--------------------------------------------------------------------------------\n",
      "Mask: tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]], dtype=torch.uint8) Size: torch.Size([5, 12])\n",
      "--------------------------------------------------------------------------------\n",
      "Tokenised Output: tensor([[   1,   62, 3037,    4,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   1, 1503,    4,   36,   37,   12, 5377,   66,    2,    0,    0,    0],\n",
      "        [   1,  923,   37,   12,  179,  266,    6,    2,    0,    0,    0,    0],\n",
      "        [   1, 1492, 3716,    4,    2,    0,    0,    0,    0,    0,    0,    0],\n",
      "        [   1,   25,  456,   12,  780,  716, 1231,    4,    2,    0,    0,    0]]) Size: torch.Size([5, 12])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of query-response pairs after all the preprocessing: \"+str(len(pairs)))\n",
    "\n",
    "#Sample batch\n",
    "batch=[random.choice(pairs) for _ in range(5)]\n",
    "input_lengths,tokenised_input,max_out_length,mask,tokenised_output=batch2TrainData(voc,batch)\n",
    "\n",
    "print(\"Input length: \"+str(input_lengths)+\" Size: \"+str(input_lengths.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Tokenised Input: \"+str(tokenised_input)+\" Size: \"+str(tokenised_input.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Max out length: \"+str(max_out_length)+\" Size: \"+str(max_out_length.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Mask: \"+str(mask)+\" Size: \"+str(mask.shape))\n",
    "print(\"-\"*80)\n",
    "print(\"Tokenised Output: \"+str(tokenised_output)+\" Size: \"+str(tokenised_output.shape))\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    A standard Encoder-Decoder architecture. Base for this and many \n",
    "    other models.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "        \n",
    "    def forward(self, src, tgt, src_mask, tgt_mask):\n",
    "        \"Take in and process masked src and target sequences.\"\n",
    "        return self.decode(self.encode(src, src_mask), src_mask,\n",
    "                            tgt, tgt_mask)\n",
    "    \n",
    "    def encode(self, src, src_mask):\n",
    "        return self.encoder(self.src_embed(src), src_mask)\n",
    "    \n",
    "    def decode(self, memory, src_mask, tgt, tgt_mask):\n",
    "        return self.decoder(self.tgt_embed(tgt), memory, src_mask, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \"Define standard linear + softmax generation step.\"\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Generator, self).__init__()\n",
    "        self.proj = nn.Linear(d_model, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return F.log_softmax(self.proj(x), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"Core encoder is a stack of N layers\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        \"Pass the input (and mask) through each layer in turn.\"\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "    def __init__(self, features, eps=1e-6):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "    def __init__(self, size, dropout):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = LayerNorm(size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"Encoder is made up of self-attn and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, feed_forward, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = self_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 2)\n",
    "        self.size = size\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        \"Follow Figure 1 (left) for connections.\"\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, mask))\n",
    "        return self.sublayer[1](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"Generic N layer decoder with masking.\"\n",
    "    def __init__(self, layer, N):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = clones(layer, N)\n",
    "        self.norm = LayerNorm(layer.size)\n",
    "        \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, memory, src_mask, tgt_mask)\n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"Decoder is made of self-attn, src-attn, and feed forward (defined below)\"\n",
    "    def __init__(self, size, self_attn, src_attn, feed_forward, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.size = size\n",
    "        self.self_attn = self_attn\n",
    "        self.src_attn = src_attn\n",
    "        self.feed_forward = feed_forward\n",
    "        self.sublayer = clones(SublayerConnection(size, dropout), 3)\n",
    " \n",
    "    def forward(self, x, memory, src_mask, tgt_mask):\n",
    "        \"Follow Figure 1 (right) for connections.\"\n",
    "        m = memory\n",
    "        x = self.sublayer[0](x, lambda x: self.self_attn(x, x, x, tgt_mask))\n",
    "        x = self.sublayer[1](x, lambda x: self.src_attn(x, m, m, src_mask))\n",
    "        return self.sublayer[2](x, self.feed_forward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.triu(np.ones(attn_shape), k=1).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query, key, value, mask=None, dropout=None):\n",
    "    \"Compute 'Scaled Dot Product Attention'\"\n",
    "    d_k = query.size(-1)\n",
    "    scores = torch.matmul(query, key.transpose(-2, -1)) \\\n",
    "             / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    p_attn = F.softmax(scores, dim = -1)\n",
    "    if dropout is not None:\n",
    "        p_attn = dropout(p_attn)\n",
    "    return torch.matmul(p_attn, value), p_attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout=0.1):\n",
    "        \"Take in model size and number of heads.\"\n",
    "        super(MultiHeadedAttention, self).__init__()\n",
    "        assert d_model % h == 0\n",
    "        # We assume d_v always equals d_k\n",
    "        self.d_k = d_model // h\n",
    "        self.h = h\n",
    "        self.linears = clones(nn.Linear(d_model, d_model), 4)\n",
    "        self.attn = None\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"Implements Figure 2\"\n",
    "        if mask is not None:\n",
    "            # Same mask applied to all h heads.\n",
    "            mask = mask.unsqueeze(1)\n",
    "        nbatches = query.size(0)\n",
    "        \n",
    "        # 1) Do all the linear projections in batch from d_model => h x d_k \n",
    "        query, key, value = \\\n",
    "            [l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n",
    "             for l, x in zip(self.linears, (query, key, value))]\n",
    "        \n",
    "        # 2) Apply attention on all the projected vectors in batch. \n",
    "        x, self.attn = attention(query, key, value, mask=mask, \n",
    "                                 dropout=self.dropout)\n",
    "        \n",
    "        # 3) \"Concat\" using a view and apply a final linear. \n",
    "        x = x.transpose(1, 2).contiguous() \\\n",
    "             .view(nbatches, -1, self.h * self.d_k)\n",
    "        return self.linears[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \"Implements FFN equation.\"\n",
    "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
    "        super(PositionwiseFeedForward, self).__init__()\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    def __init__(self, d_model, vocab):\n",
    "        super(Embeddings, self).__init__()\n",
    "        self.lut = nn.Embedding(vocab, d_model)\n",
    "        self.d_model = d_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.lut(x) * math.sqrt(self.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \"Implement the PE function.\"\n",
    "    def __init__(self, d_model, dropout, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        \n",
    "        # Compute the positional encodings once in log space.\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) *\n",
    "                             -(math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + Variable(self.pe[:, :x.size(1)], \n",
    "                         requires_grad=False)\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(src_vocab, tgt_vocab, N=6, \n",
    "               d_model=512, d_ff=2048, h=8, dropout=0.1):\n",
    "    \"Helper: Construct a model from hyperparameters.\"\n",
    "    c = copy.deepcopy\n",
    "    attn = MultiHeadedAttention(h, d_model)\n",
    "    ff = PositionwiseFeedForward(d_model, d_ff, dropout)\n",
    "    position = PositionalEncoding(d_model, dropout)\n",
    "    model = EncoderDecoder(\n",
    "        Encoder(EncoderLayer(d_model, c(attn), c(ff), dropout), N),\n",
    "        Decoder(DecoderLayer(d_model, c(attn), c(attn), \n",
    "                             c(ff), dropout), N),\n",
    "        nn.Sequential(Embeddings(d_model, src_vocab), c(position)),\n",
    "        nn.Sequential(Embeddings(d_model, tgt_vocab), c(position)),\n",
    "        Generator(d_model, tgt_vocab))\n",
    "    \n",
    "    # This was important from their code. \n",
    "    # Initialize parameters with Glorot / fan_avg.\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,encoder,decoder,source_embed,target_embed,generator):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        \n",
    "        self.source_embed=source_embed\n",
    "        self.target_embed=target_embed\n",
    "        \n",
    "        self.generator=generator # Linear + Log_softmax\n",
    "        \n",
    "    def forward(self,source,target,source_mask,target_mask):\n",
    "        return self.decode(self.encode(source,source_mask),source_mask,target,target_mask)\n",
    "    \n",
    "    def encode(self,source,source_mask):\n",
    "        return self.encoder(self.source_embed(source),source_mask)\n",
    "    \n",
    "    def decode(self,memory, source_mask,target,target_mask):\n",
    "        return self.decoder(self.target_embed(target),memory,source_mask,target_mask)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,vocab_size):\n",
    "        super().__init__()\n",
    "        self.projection=nn.Linear(d_model,vocab_size)\n",
    "        \n",
    "    def forward(self,decoder_output):\n",
    "        return F.log_softmax(self.projection(decoder_output),dim=-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clones(module,N):\n",
    "    return nn.ModuleList([copy.deepcopy(module) for _ in range(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,layer,N):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers=clones(layer,N)\n",
    "        self.norm=LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self,x,mask):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x=layer(x,mask)\n",
    "        \n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \n",
    "    def __init__(self,features,eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.a_2=nn.Parameter(torch.ones(features))\n",
    "        self.b_2=nn.Parameter(torch.zeros(features))\n",
    "        self.eps=eps\n",
    "        \n",
    "    def forward(self,x):\n",
    "        mean=x.mean(-1,keepdim=True)\n",
    "        std=x.std(-1,keepdim=True)\n",
    "        return self.a_2*(x-mean)/(std+self.eps)+self.b_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \n",
    "    def __init__(self,size,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        self.norm=LayerNorm(size)\n",
    "        \n",
    "    def forward(self,x,sublayer):\n",
    "        return x+self.dropout(sublayer(self.norm(x)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self,size,self_attn,feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn=self_attn\n",
    "        self.feed_forward=feed_forward\n",
    "        self.sublayer=clones(SublayerConnection(size,dropout),2)\n",
    "        self.size=size\n",
    "        \n",
    "    def forward(self,x,mask):\n",
    "        \n",
    "        x=self.sublayer[0](x,lambda x: self.attn(x,x,x,mask))\n",
    "        return self.sublayer[1](x,self.feed_forward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,layer,N):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.layers=clones(layer,N)\n",
    "        self.norm=LayerNorm(layer.size)\n",
    "    \n",
    "    def forward(self,x,memory,curr_mask,tgt_mask):\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x=layer(x,memory,curr_mask,tgt_mask)\n",
    "            \n",
    "        return self.norm(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self,size,self_attn,src_attn,feed_forward,dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.size=size\n",
    "        self.self_attn=self_attn\n",
    "        self.src_attn=src_attn\n",
    "        self.feed_forward=feed_forward\n",
    "        \n",
    "        self.sublayer=clones(SublayerConnection(size,dropout),3)\n",
    "        \n",
    "    def forward(self,x,memory,src_mask,tgt_mask):\n",
    "        \n",
    "        m=memory\n",
    "        x=self.sublayer[0](x,lambda x:self.self_attn(x,x,x,tgt_mask))\n",
    "        x=self.sublayer[1](x,lambda x: self.src_attn(x,m,m,src_mask))\n",
    "        return self.sublayer[2](x,self.feed_forward)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(query,key,value,mask=None,dropout=None):\n",
    "    \n",
    "    d_k=query.size(-1)\n",
    "\n",
    "    scores=torch.matmul(query,key.transpose(-2,-1))/math.sqrt(d_k)\n",
    "    \n",
    "    if mask is not None:\n",
    "        scores=scores.masked_fill(mask==0,-1e9)\n",
    "        \n",
    "    p_attn=F.softmax(scores,dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        p_attn=dropout(p_attn)\n",
    "        \n",
    "    return torch.matmul(p_attn,value),p_attn\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    \n",
    "    def __init__(self,h,d_model,dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert d_model%h==0\n",
    "        \n",
    "        self.d_k=d_model//h\n",
    "        self.h=h\n",
    "        self.linears=clones(nn.Linear(d_model,d_model),4)\n",
    "        self.attn=None\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,query,key,values,mask=None):\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask=mask.unsqueeze(1)\n",
    "            \n",
    "        nbatches=query.size(0)\n",
    "        \n",
    "        query,key,values=[l(x).view(nbatches,-1,self.h,self.d_k).transpose(1,2) for l, x in zip(self.linears,(query,key,values))]\n",
    "        \n",
    "        x,self.attn=attention(query,key,values,mask=mask,dropout=self.dropout)\n",
    "        \n",
    "        x=x.transpose(1,2).contiguous().view(nbatches,-1,self.h*self.d_k)\n",
    "        \n",
    "        return self.linears[-1](x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,d_ff,dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.w_1=nn.Linear(d_model,d_ff)\n",
    "        self.w_2=nn.Linear(d_ff,d_model)\n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        return self.w_2(self.dropout(F.relu(self.w_1(x))))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embeddings(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,vocab):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embed=nn.Embedding(vocab,d_model)\n",
    "        self.d_model=d_model\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.embed(x)*math.sqrt(self.d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    \n",
    "    def __init__(self,d_model,dropout,max_len=5000):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dropout=nn.Dropout(dropout)\n",
    "        pe=torch.zeros(max_len,d_model,dtype=torch.float)\n",
    "        position=torch.arange(0.,max_len).unsqueeze(1)\n",
    "        div_term=torch.exp(torch.arange(0.,d_model,2)*-(math.log(10000.0)/d_model))\n",
    "        \n",
    "        pe[:,0::2]=torch.sin(position*div_term)\n",
    "        pe[:,1::2]=torch.cos(position*div_term)\n",
    "        \n",
    "        pe=pe.unsqueeze(0)\n",
    "        self.register_buffer('pe',pe)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        x=x+Variable(self.pe[:,:x.size(1)],requires_grad=False)\n",
    "        return self.dropout(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model2(src_vocab,tgt_vocab,N=6,d_model=512,d_ff=2048,h=8,dropout=0.1):\n",
    "    \n",
    "    c=copy.deepcopy\n",
    "    attn=MultiHeadedAttention(h,d_model)\n",
    "    ff=PositionwiseFeedForward(d_model,d_ff,dropout)\n",
    "    position=PositionalEncoding(d_model,dropout)\n",
    "    model=EncoderDecoder(Encoder(EncoderLayer(d_model,c(attn),c(ff),dropout),N),\n",
    "                        Decoder(DecoderLayer(d_model,c(attn),c(attn),c(ff),dropout),N),\n",
    "                        nn.Sequential(Embeddings(d_model,src_vocab),c(position)),\n",
    "                        nn.Sequential(Embeddings(d_model,tgt_vocab),c(position)),\n",
    "                        Generator(d_model,tgt_vocab))\n",
    "    \n",
    "    for p in model.parameters():\n",
    "        if p.dim()>1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-53a31e2dc57a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msample_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# print(sample_model)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_model' is not defined"
     ]
    }
   ],
   "source": [
    "sample_model=make_model(voc.num_words,voc.num_words,1,512,2048,8,0.1)\n",
    "# print(sample_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Output size: torch.Size([5, 12, 512])\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#Sample Run\n",
    "source=torch.ones(5,12,dtype=torch.long)\n",
    "target=torch.ones(5,12,dtype=torch.long)\n",
    "source_mask=None\n",
    "target_mask=torch.ones(5,12,12,dtype=torch.long)\n",
    "out=sample_model(source,target,source_mask,target_mask)\n",
    "print(\"-\"*80)\n",
    "print(\"Output size: \"+str(out.shape))\n",
    "print(\"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "triu function generates a copy of matrix with elemens below kth diagonal zeroed.\n",
    "The main diagonal is zeroeth diagonal above is first(k=1) and so on.\n",
    "\n",
    "Eg:\n",
    "A=[[1,2,3],[4,5,6],[7,8,9]]\n",
    "for above matrix:\n",
    "triu(A,k=1)\n",
    "will give [[0,2,3],[0,0,6],[0,0,0]]\n",
    "\"\"\"\n",
    "\n",
    "def subsequent_mask(size):\n",
    "    attn_shape=(1,size,size)\n",
    "    mask=np.triu(np.ones(attn_shape),k=1).astype('uint8')\n",
    "    \n",
    "    return torch.from_numpy(mask)==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generation(pairs,batch_size,n_batches):\n",
    "    \n",
    "    sample_batches=[batch2TrainData(voc,[random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_batches)]\n",
    "    batches=[]\n",
    "    \n",
    "    for i in range(n_batches):\n",
    "        batches.append(Batch(sample_batches[i][1],sample_batches[i][-1]))\n",
    "#     batches=[]\n",
    "#     for i in range(n_batches):\n",
    "#         data = torch.from_numpy(np.random.randint(1, 11, size=(batch_size, 10)))\n",
    "#         data[:,0]=1\n",
    "        \n",
    "#         batches.append(Batch(data,data))\n",
    "    \n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Batch:\n",
    "    \n",
    "#     def __init__(self,sample_batch,pad):\n",
    "        \n",
    "#         self.src=sample_batch[1]\n",
    "#         self.src_mask=self.make_src_mask(self.src,pad)\n",
    "#         self.trg=sample_batch[-1][:,:-1]\n",
    "#         self.trg_mask=self.make_trg_mask(self.trg,pad)\n",
    "#         self.trg_y=sample_batch[-1][:,1:]\n",
    "#         self.ntokens=(self.trg_y!=pad).data.sum()\n",
    "        \n",
    "#     @staticmethod\n",
    "#     def make_src_mask(src,pad):\n",
    "#         return (src!=pad).unsqueeze(-2)\n",
    "#     @staticmethod    \n",
    "#     def make_trg_mask(trg,pad):\n",
    "#         trg_mask=(trg!=pad).unsqueeze(-2)\n",
    "# #         trg_mask=trg_mask&Variable(subsequent_mask(trg.size(-1)).type_as(trg_mask.data))\n",
    "#         return trg_mask\n",
    "class Batch:\n",
    "    \"Object for holding a batch of data with mask during training.\"\n",
    "    def __init__(self, src, trg=None, pad=0):\n",
    "        src=torch.tensor(src).to(torch.int64)\n",
    "        trg=torch.tensor(trg).to(torch.int64)\n",
    "        self.src = src\n",
    "        self.src_mask = (src != pad).unsqueeze(-2)\n",
    "        if trg is not None:\n",
    "            self.trg = trg[:, :-1]\n",
    "            self.trg_y = trg[:, 1:]\n",
    "            self.trg_mask = \\\n",
    "                self.make_std_mask(self.trg, pad)\n",
    "            self.ntokens = (self.trg_y != pad).data.sum()\n",
    "    \n",
    "    @staticmethod\n",
    "    def make_std_mask(tgt, pad):\n",
    "        \"Create a mask to hide padding and future words.\"\n",
    "        tgt_mask = (tgt != pad).unsqueeze(-2)\n",
    "        tgt_mask = tgt_mask & Variable(\n",
    "            subsequent_mask(tgt.size(-1)).type_as(tgt_mask.data))\n",
    "        return tgt_mask        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_epoch(data,model,loss_compute):\n",
    "    \n",
    "    start_time=time.time()\n",
    "    total_tokens=0\n",
    "    total_loss=0\n",
    "    tokens=0\n",
    "    \n",
    "    out=model(data.src,data.trg,data.src_mask,data.trg_mask)\n",
    "#     print(\"Model output: \"+str(out.size()))\n",
    "    loss=loss_compute(out,data.trg_y,data.ntokens)\n",
    "    \n",
    "    return loss\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customLossFunction(outputs,target):\n",
    "    batch_size=outputs.size()[0]\n",
    "    numberOfWords=outputs.size()[1]\n",
    "    outputs=F.softmax(outputs,dim=-1)\n",
    "    loss=0\n",
    "    normalisingVal=0\n",
    "#     print(outputs)\n",
    "#     print(target)\n",
    "    for i in range(batch_size):\n",
    "        for j in range(numberOfWords):\n",
    "            trg=target[i][j]\n",
    "            if trg!=0:\n",
    "                \n",
    "                currLoss=-(outputs[i][j][trg]+5)\n",
    "                loss+=currLoss\n",
    "                normalisingVal+=1\n",
    "    return loss/normalisingVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LabelSmoothing(nn.Module):\n",
    "    \n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "#         self.criteria=customLossFunction()\n",
    "#     def forward(self,x,target):\n",
    "#         return self.criteria(x,target)\n",
    "class LabelSmoothing(nn.Module):\n",
    "    \"Implement label smoothing.\"\n",
    "    def __init__(self, size, padding_idx, smoothing=0.0):\n",
    "        super(LabelSmoothing, self).__init__()\n",
    "        self.criterion = nn.KLDivLoss(size_average=False)\n",
    "        self.padding_idx = padding_idx\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.size = size\n",
    "        self.true_dist = None\n",
    "        \n",
    "    def forward(self, x, target):\n",
    "#         print(\"Before assertion: \"+str(x.size())+str(self.size))\n",
    "        assert x.size(1) == self.size\n",
    "        true_dist = x.data.clone()\n",
    "        true_dist.fill_(self.smoothing / (self.size - 2))\n",
    "        true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        true_dist[:, self.padding_idx] = 0\n",
    "        mask = torch.nonzero(target.data == self.padding_idx)\n",
    "        if mask.dim() > 0:\n",
    "            true_dist.index_fill_(0, mask.squeeze(), 0.0)\n",
    "        self.true_dist = true_dist\n",
    "        return self.criterion(x, Variable(true_dist, requires_grad=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LossCompute:\n",
    "    \n",
    "#     def __init__(self,model,opt):\n",
    "        \n",
    "#         self.opt=opt\n",
    "#         self.model=model\n",
    "    \n",
    "#     def __call__(self,x,y,norm):\n",
    "        \n",
    "#         x=self.model.generator(x)\n",
    "#         loss=customLossFunction(x,y)\n",
    "        \n",
    "    \n",
    "       \n",
    "\n",
    "#         loss.backward()\n",
    "        \n",
    "# #         _=nn.utils.clip_grad_norm_(model.parameters(),50.0)\n",
    "        \n",
    "#         plot_grad_flow(self.model.named_parameters())\n",
    "        \n",
    "#         self.opt.step()\n",
    "#         self.opt.optimizer.zero_grad()\n",
    "        \n",
    "#         return loss.item()\n",
    "\n",
    "class SimpleLossCompute:\n",
    "    \"A simple loss compute and train function.\"\n",
    "    def __init__(self, generator, criterion, opt=None):\n",
    "        self.generator = generator\n",
    "        self.criterion = criterion\n",
    "        self.opt = opt\n",
    "        \n",
    "    def __call__(self, x, y, norm):\n",
    "        x = self.generator(x)\n",
    "#         print(str(x.size())+\" \"+str(y.size()))\n",
    "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)), \n",
    "                              y.contiguous().view(-1)) / norm\n",
    "        loss.backward()\n",
    "        plot_grad_flow(model.named_parameters())\n",
    "        if self.opt is not None:\n",
    "            self.opt.step()\n",
    "            self.opt.optimizer.zero_grad()\n",
    "        return loss.item()* norm\n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoamOpt:\n",
    "    \"Optim wrapper that implements rate.\"\n",
    "    def __init__(self, model_size, factor, warmup, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        self._step = 0\n",
    "        self.warmup = warmup\n",
    "        self.factor = factor\n",
    "        self.model_size = model_size\n",
    "        self._rate = 0\n",
    "        \n",
    "    def step(self):\n",
    "        \"Update parameters and rate\"\n",
    "        self._step += 1\n",
    "        rate = self.rate()\n",
    "        for p in self.optimizer.param_groups:\n",
    "            p['lr'] = rate\n",
    "        self._rate = rate\n",
    "        self.optimizer.step()\n",
    "        \n",
    "    def rate(self, step = None):\n",
    "        \"Implement `lrate` above\"\n",
    "        if step is None:\n",
    "            step = self._step\n",
    "        return self.factor * \\\n",
    "            (self.model_size ** (-0.5) *\n",
    "            min(step ** (-0.5), step * self.warmup ** (-1.5)))\n",
    "        \n",
    "def get_std_opt(model):\n",
    "    return NoamOpt(model.src_embed[0].d_model, 2, 4000,\n",
    "            torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:23: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\deepa\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    }
   ],
   "source": [
    "batches=data_generation(pairs,30,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialising and creating models....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deepa\\anaconda3\\lib\\site-packages\\torch\\nn\\_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "Creating Models took: 0.5954074859619141\n",
      "Epoch: 0 Loss Value: tensor(1536.6416)\n",
      "Epoch: 1 Loss Value: tensor(1790.1869)\n",
      "Epoch: 2 Loss Value: tensor(1586.7611)\n",
      "Epoch: 3 Loss Value: tensor(1528.5505)\n",
      "Epoch: 4 Loss Value: tensor(1664.4194)\n",
      "Epoch: 5 Loss Value: tensor(1619.6715)\n",
      "Epoch: 6 Loss Value: tensor(1607.6332)\n",
      "Epoch: 7 Loss Value: tensor(1519.7192)\n",
      "Epoch: 8 Loss Value: tensor(1427.0681)\n",
      "Epoch: 9 Loss Value: tensor(1580.1553)\n",
      "Epoch: 10 Loss Value: tensor(1333.3229)\n",
      "Epoch: 11 Loss Value: tensor(1536.3188)\n",
      "Epoch: 12 Loss Value: tensor(1243.4146)\n",
      "Epoch: 13 Loss Value: tensor(1327.2306)\n",
      "Epoch: 14 Loss Value: tensor(1414.9442)\n",
      "Epoch: 15 Loss Value: tensor(1429.8977)\n",
      "Epoch: 16 Loss Value: tensor(1292.5555)\n",
      "Epoch: 17 Loss Value: tensor(1415.8280)\n",
      "Epoch: 18 Loss Value: tensor(1228.5615)\n",
      "Epoch: 19 Loss Value: tensor(1201.9990)\n",
      "Epoch: 20 Loss Value: tensor(1358.1099)\n",
      "Epoch: 21 Loss Value: tensor(1237.9722)\n",
      "Epoch: 22 Loss Value: tensor(1175.8314)\n",
      "Epoch: 23 Loss Value: tensor(1187.8713)\n",
      "Epoch: 24 Loss Value: tensor(1138.8715)\n",
      "Epoch: 25 Loss Value: tensor(1165.8766)\n",
      "Epoch: 26 Loss Value: tensor(1326.8809)\n",
      "Epoch: 27 Loss Value: tensor(1305.4807)\n",
      "Epoch: 28 Loss Value: tensor(1174.5015)\n",
      "Epoch: 29 Loss Value: tensor(1204.1228)\n",
      "Epoch: 30 Loss Value: tensor(1104.2386)\n",
      "Epoch: 31 Loss Value: tensor(1085.7656)\n",
      "Epoch: 32 Loss Value: tensor(1120.0115)\n",
      "Epoch: 33 Loss Value: tensor(1109.1941)\n",
      "Epoch: 34 Loss Value: tensor(978.1554)\n",
      "Epoch: 35 Loss Value: tensor(907.4009)\n",
      "Epoch: 36 Loss Value: tensor(1117.1047)\n",
      "Epoch: 37 Loss Value: tensor(1250.4330)\n",
      "Epoch: 38 Loss Value: tensor(922.6210)\n",
      "Epoch: 39 Loss Value: tensor(993.5139)\n",
      "Epoch: 40 Loss Value: tensor(932.5040)\n",
      "Epoch: 41 Loss Value: tensor(911.7834)\n",
      "Epoch: 42 Loss Value: tensor(881.2893)\n",
      "Epoch: 43 Loss Value: tensor(943.8298)\n",
      "Epoch: 44 Loss Value: tensor(775.3512)\n",
      "Epoch: 45 Loss Value: tensor(880.8804)\n",
      "Epoch: 46 Loss Value: tensor(1092.9346)\n",
      "Epoch: 47 Loss Value: tensor(1163.6707)\n",
      "Epoch: 48 Loss Value: tensor(972.7108)\n",
      "Epoch: 49 Loss Value: tensor(937.0085)\n",
      "Epoch: 50 Loss Value: tensor(902.4061)\n",
      "Epoch: 51 Loss Value: tensor(939.4232)\n",
      "Epoch: 52 Loss Value: tensor(836.4681)\n",
      "Epoch: 53 Loss Value: tensor(871.2400)\n",
      "Epoch: 54 Loss Value: tensor(887.5364)\n",
      "Epoch: 55 Loss Value: tensor(847.3321)\n",
      "Epoch: 56 Loss Value: tensor(994.8901)\n",
      "Epoch: 57 Loss Value: tensor(941.7184)\n",
      "Epoch: 58 Loss Value: tensor(882.1567)\n",
      "Epoch: 59 Loss Value: tensor(891.2762)\n",
      "Epoch: 60 Loss Value: tensor(941.9729)\n",
      "Epoch: 61 Loss Value: tensor(1083.3564)\n",
      "Epoch: 62 Loss Value: tensor(954.2729)\n",
      "Epoch: 63 Loss Value: tensor(940.8692)\n",
      "Epoch: 64 Loss Value: tensor(831.4434)\n",
      "Epoch: 65 Loss Value: tensor(815.2385)\n",
      "Epoch: 66 Loss Value: tensor(914.6151)\n",
      "Epoch: 67 Loss Value: tensor(957.7446)\n",
      "Epoch: 68 Loss Value: tensor(863.8582)\n",
      "Epoch: 69 Loss Value: tensor(799.0065)\n",
      "Epoch: 70 Loss Value: tensor(904.1786)\n",
      "Epoch: 71 Loss Value: tensor(950.2194)\n",
      "Epoch: 72 Loss Value: tensor(737.8895)\n",
      "Epoch: 73 Loss Value: tensor(866.1757)\n",
      "Epoch: 74 Loss Value: tensor(806.3085)\n",
      "Epoch: 75 Loss Value: tensor(852.9050)\n",
      "Epoch: 76 Loss Value: tensor(858.1949)\n",
      "Epoch: 77 Loss Value: tensor(892.9939)\n",
      "Epoch: 78 Loss Value: tensor(864.8073)\n",
      "Epoch: 79 Loss Value: tensor(867.7804)\n",
      "Epoch: 80 Loss Value: tensor(858.2134)\n",
      "Epoch: 81 Loss Value: tensor(803.6094)\n",
      "Epoch: 82 Loss Value: tensor(828.4183)\n",
      "Epoch: 83 Loss Value: tensor(861.3209)\n",
      "Epoch: 84 Loss Value: tensor(996.0182)\n",
      "Epoch: 85 Loss Value: tensor(801.0375)\n",
      "Epoch: 86 Loss Value: tensor(912.8405)\n",
      "Epoch: 87 Loss Value: tensor(854.0576)\n",
      "Epoch: 88 Loss Value: tensor(945.6992)\n",
      "Epoch: 89 Loss Value: tensor(899.9310)\n",
      "Epoch: 90 Loss Value: tensor(815.0797)\n",
      "Epoch: 91 Loss Value: tensor(844.9952)\n",
      "Epoch: 92 Loss Value: tensor(919.8529)\n",
      "Epoch: 93 Loss Value: tensor(794.2927)\n",
      "Epoch: 94 Loss Value: tensor(772.6539)\n",
      "Epoch: 95 Loss Value: tensor(807.2195)\n",
      "Epoch: 96 Loss Value: tensor(953.7983)\n",
      "Epoch: 97 Loss Value: tensor(795.9250)\n",
      "Epoch: 98 Loss Value: tensor(875.0276)\n",
      "Epoch: 99 Loss Value: tensor(854.3010)\n",
      "Epoch: 100 Loss Value: tensor(896.8380)\n",
      "Epoch: 101 Loss Value: tensor(743.7285)\n",
      "Epoch: 102 Loss Value: tensor(800.3751)\n",
      "Epoch: 103 Loss Value: tensor(849.7110)\n",
      "Epoch: 104 Loss Value: tensor(883.6914)\n",
      "Epoch: 105 Loss Value: tensor(921.4812)\n",
      "Epoch: 106 Loss Value: tensor(818.0193)\n",
      "Epoch: 107 Loss Value: tensor(820.5671)\n",
      "Epoch: 108 Loss Value: tensor(968.9313)\n",
      "Epoch: 109 Loss Value: tensor(802.0908)\n",
      "Epoch: 110 Loss Value: tensor(780.5286)\n",
      "Epoch: 111 Loss Value: tensor(827.3734)\n",
      "Epoch: 112 Loss Value: tensor(866.5927)\n",
      "Epoch: 113 Loss Value: tensor(801.2287)\n",
      "Epoch: 114 Loss Value: tensor(825.6110)\n",
      "Epoch: 115 Loss Value: tensor(706.0753)\n",
      "Epoch: 116 Loss Value: tensor(861.0932)\n",
      "Epoch: 117 Loss Value: tensor(763.7842)\n",
      "Epoch: 118 Loss Value: tensor(759.9956)\n",
      "Epoch: 119 Loss Value: tensor(700.3444)\n",
      "Epoch: 120 Loss Value: tensor(885.0164)\n",
      "Epoch: 121 Loss Value: tensor(773.1837)\n",
      "Epoch: 122 Loss Value: tensor(753.2745)\n",
      "Epoch: 123 Loss Value: tensor(808.6271)\n",
      "Epoch: 124 Loss Value: tensor(882.3441)\n",
      "Epoch: 125 Loss Value: tensor(872.5560)\n",
      "Epoch: 126 Loss Value: tensor(741.6014)\n",
      "Epoch: 127 Loss Value: tensor(852.5839)\n",
      "Epoch: 128 Loss Value: tensor(702.3215)\n",
      "Epoch: 129 Loss Value: tensor(784.7510)\n",
      "Epoch: 130 Loss Value: tensor(835.6219)\n",
      "Epoch: 131 Loss Value: tensor(716.8372)\n",
      "Epoch: 132 Loss Value: tensor(886.3283)\n",
      "Epoch: 133 Loss Value: tensor(819.2326)\n",
      "Epoch: 134 Loss Value: tensor(743.1559)\n",
      "Epoch: 135 Loss Value: tensor(884.3636)\n",
      "Epoch: 136 Loss Value: tensor(845.9505)\n",
      "Epoch: 137 Loss Value: tensor(694.1865)\n",
      "Epoch: 138 Loss Value: tensor(872.6706)\n",
      "Epoch: 139 Loss Value: tensor(954.2073)\n",
      "Epoch: 140 Loss Value: tensor(774.0544)\n",
      "Epoch: 141 Loss Value: tensor(804.1176)\n",
      "Epoch: 142 Loss Value: tensor(850.4396)\n",
      "Epoch: 143 Loss Value: tensor(789.8976)\n",
      "Epoch: 144 Loss Value: tensor(815.1431)\n",
      "Epoch: 145 Loss Value: tensor(868.0703)\n",
      "Epoch: 146 Loss Value: tensor(883.0535)\n",
      "Epoch: 147 Loss Value: tensor(827.5519)\n",
      "Epoch: 148 Loss Value: tensor(862.7357)\n",
      "Epoch: 149 Loss Value: tensor(703.0063)\n",
      "Epoch: 150 Loss Value: tensor(841.2842)\n",
      "Epoch: 151 Loss Value: tensor(887.7803)\n",
      "Epoch: 152 Loss Value: tensor(817.6944)\n",
      "Epoch: 153 Loss Value: tensor(798.3775)\n",
      "Epoch: 154 Loss Value: tensor(962.6022)\n",
      "Epoch: 155 Loss Value: tensor(971.4839)\n",
      "Epoch: 156 Loss Value: tensor(842.8372)\n",
      "Epoch: 157 Loss Value: tensor(871.1155)\n",
      "Epoch: 158 Loss Value: tensor(854.6577)\n",
      "Epoch: 159 Loss Value: tensor(967.6161)\n",
      "Epoch: 160 Loss Value: tensor(878.6544)\n",
      "Epoch: 161 Loss Value: tensor(762.9871)\n",
      "Epoch: 162 Loss Value: tensor(770.1887)\n",
      "Epoch: 163 Loss Value: tensor(885.6176)\n",
      "Epoch: 164 Loss Value: tensor(793.6710)\n",
      "Epoch: 165 Loss Value: tensor(756.7147)\n",
      "Epoch: 166 Loss Value: tensor(905.2807)\n",
      "Epoch: 167 Loss Value: tensor(847.9842)\n",
      "Epoch: 168 Loss Value: tensor(773.4654)\n",
      "Epoch: 169 Loss Value: tensor(835.0539)\n",
      "Epoch: 170 Loss Value: tensor(1023.5783)\n",
      "Epoch: 171 Loss Value: tensor(850.1349)\n",
      "Epoch: 172 Loss Value: tensor(748.3052)\n",
      "Epoch: 173 Loss Value: tensor(952.8793)\n",
      "Epoch: 174 Loss Value: tensor(745.9869)\n",
      "Epoch: 175 Loss Value: tensor(833.0150)\n",
      "Epoch: 176 Loss Value: tensor(819.3600)\n",
      "Epoch: 177 Loss Value: tensor(747.3351)\n",
      "Epoch: 178 Loss Value: tensor(812.0853)\n",
      "Epoch: 179 Loss Value: tensor(749.1738)\n",
      "Epoch: 180 Loss Value: tensor(762.5491)\n",
      "Epoch: 181 Loss Value: tensor(719.0540)\n",
      "Epoch: 182 Loss Value: tensor(840.7859)\n",
      "Epoch: 183 Loss Value: tensor(765.7979)\n",
      "Epoch: 184 Loss Value: tensor(778.8529)\n",
      "Epoch: 185 Loss Value: tensor(728.8218)\n",
      "Epoch: 186 Loss Value: tensor(869.7450)\n",
      "Epoch: 187 Loss Value: tensor(872.0406)\n",
      "Epoch: 188 Loss Value: tensor(647.0826)\n",
      "Epoch: 189 Loss Value: tensor(721.5860)\n",
      "Epoch: 190 Loss Value: tensor(877.9062)\n",
      "Epoch: 191 Loss Value: tensor(776.9797)\n",
      "Epoch: 192 Loss Value: tensor(770.7874)\n",
      "Epoch: 193 Loss Value: tensor(721.5255)\n",
      "Epoch: 194 Loss Value: tensor(875.6198)\n",
      "Epoch: 195 Loss Value: tensor(783.3442)\n",
      "Epoch: 196 Loss Value: tensor(833.6189)\n",
      "Epoch: 197 Loss Value: tensor(834.7750)\n",
      "Epoch: 198 Loss Value: tensor(742.4785)\n",
      "Epoch: 199 Loss Value: tensor(1004.9009)\n",
      "Epoch: 200 Loss Value: tensor(755.9924)\n",
      "Epoch: 201 Loss Value: tensor(863.2195)\n",
      "Epoch: 202 Loss Value: tensor(767.6741)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 203 Loss Value: tensor(681.0964)\n",
      "Epoch: 204 Loss Value: tensor(835.8606)\n",
      "Epoch: 205 Loss Value: tensor(892.0494)\n",
      "Epoch: 206 Loss Value: tensor(878.7153)\n",
      "Epoch: 207 Loss Value: tensor(796.1321)\n",
      "Epoch: 208 Loss Value: tensor(693.0840)\n",
      "Epoch: 209 Loss Value: tensor(893.6315)\n",
      "Epoch: 210 Loss Value: tensor(741.3635)\n",
      "Epoch: 211 Loss Value: tensor(862.7386)\n",
      "Epoch: 212 Loss Value: tensor(687.2993)\n",
      "Epoch: 213 Loss Value: tensor(776.1106)\n",
      "Epoch: 214 Loss Value: tensor(838.0479)\n",
      "Epoch: 215 Loss Value: tensor(847.9116)\n",
      "Epoch: 216 Loss Value: tensor(780.7756)\n",
      "Epoch: 217 Loss Value: tensor(840.8981)\n",
      "Epoch: 218 Loss Value: tensor(766.2485)\n",
      "Epoch: 219 Loss Value: tensor(799.3009)\n",
      "Epoch: 220 Loss Value: tensor(811.2761)\n",
      "Epoch: 221 Loss Value: tensor(734.2018)\n",
      "Epoch: 222 Loss Value: tensor(715.4817)\n",
      "Epoch: 223 Loss Value: tensor(709.0097)\n",
      "Epoch: 224 Loss Value: tensor(754.8917)\n",
      "Epoch: 225 Loss Value: tensor(745.2973)\n",
      "Epoch: 226 Loss Value: tensor(822.1791)\n",
      "Epoch: 227 Loss Value: tensor(872.7117)\n",
      "Epoch: 228 Loss Value: tensor(779.8558)\n",
      "Epoch: 229 Loss Value: tensor(765.6397)\n",
      "Epoch: 230 Loss Value: tensor(739.1336)\n",
      "Epoch: 231 Loss Value: tensor(746.3694)\n",
      "Epoch: 232 Loss Value: tensor(781.3524)\n",
      "Epoch: 233 Loss Value: tensor(769.1523)\n",
      "Epoch: 234 Loss Value: tensor(669.9733)\n",
      "Epoch: 235 Loss Value: tensor(663.3585)\n",
      "Epoch: 236 Loss Value: tensor(832.6558)\n",
      "Epoch: 237 Loss Value: tensor(895.5068)\n",
      "Epoch: 238 Loss Value: tensor(619.1871)\n",
      "Epoch: 239 Loss Value: tensor(739.5284)\n",
      "Epoch: 240 Loss Value: tensor(708.4740)\n",
      "Epoch: 241 Loss Value: tensor(674.6641)\n",
      "Epoch: 242 Loss Value: tensor(704.8375)\n",
      "Epoch: 243 Loss Value: tensor(752.6852)\n",
      "Epoch: 244 Loss Value: tensor(615.0859)\n",
      "Epoch: 245 Loss Value: tensor(708.1481)\n",
      "Epoch: 246 Loss Value: tensor(857.0812)\n",
      "Epoch: 247 Loss Value: tensor(988.5145)\n",
      "Epoch: 248 Loss Value: tensor(790.8819)\n",
      "Epoch: 249 Loss Value: tensor(767.7053)\n",
      "Epoch: 250 Loss Value: tensor(707.7819)\n",
      "Epoch: 251 Loss Value: tensor(769.6882)\n",
      "Epoch: 252 Loss Value: tensor(729.9683)\n",
      "Epoch: 253 Loss Value: tensor(725.9122)\n",
      "Epoch: 254 Loss Value: tensor(755.9495)\n",
      "Epoch: 255 Loss Value: tensor(694.5052)\n",
      "Epoch: 256 Loss Value: tensor(869.0246)\n",
      "Epoch: 257 Loss Value: tensor(806.4022)\n",
      "Epoch: 258 Loss Value: tensor(755.0461)\n",
      "Epoch: 259 Loss Value: tensor(733.7568)\n",
      "Epoch: 260 Loss Value: tensor(770.6489)\n",
      "Epoch: 261 Loss Value: tensor(928.6248)\n",
      "Epoch: 262 Loss Value: tensor(839.7104)\n",
      "Epoch: 263 Loss Value: tensor(790.7681)\n",
      "Epoch: 264 Loss Value: tensor(731.0005)\n",
      "Epoch: 265 Loss Value: tensor(683.9506)\n",
      "Epoch: 266 Loss Value: tensor(775.4930)\n",
      "Epoch: 267 Loss Value: tensor(798.7329)\n",
      "Epoch: 268 Loss Value: tensor(758.2922)\n",
      "Epoch: 269 Loss Value: tensor(682.1021)\n",
      "Epoch: 270 Loss Value: tensor(753.3627)\n",
      "Epoch: 271 Loss Value: tensor(814.3243)\n",
      "Epoch: 272 Loss Value: tensor(593.6346)\n",
      "Epoch: 273 Loss Value: tensor(732.5883)\n",
      "Epoch: 274 Loss Value: tensor(676.3590)\n",
      "Epoch: 275 Loss Value: tensor(752.7683)\n",
      "Epoch: 276 Loss Value: tensor(705.9326)\n",
      "Epoch: 277 Loss Value: tensor(733.3064)\n",
      "Epoch: 278 Loss Value: tensor(731.1561)\n",
      "Epoch: 279 Loss Value: tensor(729.1600)\n",
      "Epoch: 280 Loss Value: tensor(735.6255)\n",
      "Epoch: 281 Loss Value: tensor(681.7898)\n",
      "Epoch: 282 Loss Value: tensor(730.2408)\n",
      "Epoch: 283 Loss Value: tensor(743.2522)\n",
      "Epoch: 284 Loss Value: tensor(837.2846)\n",
      "Epoch: 285 Loss Value: tensor(697.7303)\n",
      "Epoch: 286 Loss Value: tensor(793.6589)\n",
      "Epoch: 287 Loss Value: tensor(724.5654)\n",
      "Epoch: 288 Loss Value: tensor(838.3888)\n",
      "Epoch: 289 Loss Value: tensor(777.1772)\n",
      "Epoch: 290 Loss Value: tensor(708.7200)\n",
      "Epoch: 291 Loss Value: tensor(729.0051)\n",
      "Epoch: 292 Loss Value: tensor(817.1335)\n",
      "Epoch: 293 Loss Value: tensor(668.0019)\n",
      "Epoch: 294 Loss Value: tensor(655.9210)\n",
      "Epoch: 295 Loss Value: tensor(697.7121)\n",
      "Epoch: 296 Loss Value: tensor(854.6487)\n",
      "Epoch: 297 Loss Value: tensor(700.9204)\n",
      "Epoch: 298 Loss Value: tensor(749.4606)\n",
      "Epoch: 299 Loss Value: tensor(758.3768)\n",
      "Epoch: 300 Loss Value: tensor(776.5501)\n",
      "Epoch: 301 Loss Value: tensor(669.3282)\n",
      "Epoch: 302 Loss Value: tensor(701.9639)\n",
      "Epoch: 303 Loss Value: tensor(752.5412)\n",
      "Epoch: 304 Loss Value: tensor(775.0800)\n",
      "Epoch: 305 Loss Value: tensor(785.3507)\n",
      "Epoch: 306 Loss Value: tensor(734.8342)\n",
      "Epoch: 307 Loss Value: tensor(732.1921)\n",
      "Epoch: 308 Loss Value: tensor(847.9614)\n",
      "Epoch: 309 Loss Value: tensor(694.1512)\n",
      "Epoch: 310 Loss Value: tensor(666.3303)\n",
      "Epoch: 311 Loss Value: tensor(711.0509)\n",
      "Epoch: 312 Loss Value: tensor(762.6595)\n",
      "Epoch: 313 Loss Value: tensor(711.8810)\n",
      "Epoch: 314 Loss Value: tensor(732.4631)\n",
      "Epoch: 315 Loss Value: tensor(607.8483)\n",
      "Epoch: 316 Loss Value: tensor(762.8680)\n",
      "Epoch: 317 Loss Value: tensor(683.3524)\n",
      "Epoch: 318 Loss Value: tensor(662.8361)\n",
      "Epoch: 319 Loss Value: tensor(608.4429)\n",
      "Epoch: 320 Loss Value: tensor(769.7745)\n",
      "Epoch: 321 Loss Value: tensor(689.2875)\n",
      "Epoch: 322 Loss Value: tensor(642.2336)\n",
      "Epoch: 323 Loss Value: tensor(709.5787)\n",
      "Epoch: 324 Loss Value: tensor(792.1501)\n",
      "Epoch: 325 Loss Value: tensor(769.4437)\n",
      "Epoch: 326 Loss Value: tensor(670.0670)\n",
      "Epoch: 327 Loss Value: tensor(752.0701)\n",
      "Epoch: 328 Loss Value: tensor(624.1820)\n",
      "Epoch: 329 Loss Value: tensor(695.3453)\n",
      "Epoch: 330 Loss Value: tensor(739.6230)\n",
      "Epoch: 331 Loss Value: tensor(628.3337)\n",
      "Epoch: 332 Loss Value: tensor(786.9269)\n",
      "Epoch: 333 Loss Value: tensor(728.6860)\n",
      "Epoch: 334 Loss Value: tensor(642.0273)\n",
      "Epoch: 335 Loss Value: tensor(773.0024)\n",
      "Epoch: 336 Loss Value: tensor(740.4705)\n",
      "Epoch: 337 Loss Value: tensor(610.7054)\n",
      "Epoch: 338 Loss Value: tensor(791.9581)\n",
      "Epoch: 339 Loss Value: tensor(829.1780)\n",
      "Epoch: 340 Loss Value: tensor(688.8889)\n",
      "Epoch: 341 Loss Value: tensor(715.7759)\n",
      "Epoch: 342 Loss Value: tensor(773.3682)\n",
      "Epoch: 343 Loss Value: tensor(713.8264)\n",
      "Epoch: 344 Loss Value: tensor(710.6547)\n",
      "Epoch: 345 Loss Value: tensor(759.4062)\n",
      "Epoch: 346 Loss Value: tensor(747.2533)\n",
      "Epoch: 347 Loss Value: tensor(719.2740)\n",
      "Epoch: 348 Loss Value: tensor(790.0864)\n",
      "Epoch: 349 Loss Value: tensor(619.6974)\n",
      "Epoch: 350 Loss Value: tensor(785.7572)\n",
      "Epoch: 351 Loss Value: tensor(790.7527)\n",
      "Epoch: 352 Loss Value: tensor(713.6718)\n",
      "Epoch: 353 Loss Value: tensor(715.0170)\n",
      "Epoch: 354 Loss Value: tensor(844.1161)\n",
      "Epoch: 355 Loss Value: tensor(881.5277)\n",
      "Epoch: 356 Loss Value: tensor(755.3242)\n",
      "Epoch: 357 Loss Value: tensor(773.6662)\n",
      "Epoch: 358 Loss Value: tensor(761.5093)\n",
      "Epoch: 359 Loss Value: tensor(846.6793)\n",
      "Epoch: 360 Loss Value: tensor(778.3923)\n",
      "Epoch: 361 Loss Value: tensor(696.9966)\n",
      "Epoch: 362 Loss Value: tensor(689.4556)\n",
      "Epoch: 363 Loss Value: tensor(775.5799)\n",
      "Epoch: 364 Loss Value: tensor(717.9244)\n",
      "Epoch: 365 Loss Value: tensor(691.9550)\n",
      "Epoch: 366 Loss Value: tensor(835.5823)\n",
      "Epoch: 367 Loss Value: tensor(766.3741)\n",
      "Epoch: 368 Loss Value: tensor(685.2299)\n",
      "Epoch: 369 Loss Value: tensor(744.7112)\n",
      "Epoch: 370 Loss Value: tensor(885.3430)\n",
      "Epoch: 371 Loss Value: tensor(762.7446)\n",
      "Epoch: 372 Loss Value: tensor(661.2758)\n",
      "Epoch: 373 Loss Value: tensor(829.7147)\n",
      "Epoch: 374 Loss Value: tensor(681.9475)\n",
      "Epoch: 375 Loss Value: tensor(761.4100)\n",
      "Epoch: 376 Loss Value: tensor(735.4955)\n",
      "Epoch: 377 Loss Value: tensor(705.2791)\n",
      "Epoch: 378 Loss Value: tensor(724.4462)\n",
      "Epoch: 379 Loss Value: tensor(660.7734)\n",
      "Epoch: 380 Loss Value: tensor(693.3196)\n",
      "Epoch: 381 Loss Value: tensor(681.0520)\n",
      "Epoch: 382 Loss Value: tensor(756.3999)\n",
      "Epoch: 383 Loss Value: tensor(685.2344)\n",
      "Epoch: 384 Loss Value: tensor(688.0548)\n",
      "Epoch: 385 Loss Value: tensor(662.0321)\n",
      "Epoch: 386 Loss Value: tensor(783.6045)\n",
      "Epoch: 387 Loss Value: tensor(800.0624)\n",
      "Epoch: 388 Loss Value: tensor(565.4169)\n",
      "Epoch: 389 Loss Value: tensor(669.1318)\n",
      "Epoch: 390 Loss Value: tensor(795.8554)\n",
      "Epoch: 391 Loss Value: tensor(678.2496)\n",
      "Epoch: 392 Loss Value: tensor(721.6071)\n",
      "Epoch: 393 Loss Value: tensor(655.9111)\n",
      "Epoch: 394 Loss Value: tensor(809.8001)\n",
      "Epoch: 395 Loss Value: tensor(701.9663)\n",
      "Epoch: 396 Loss Value: tensor(767.2603)\n",
      "Epoch: 397 Loss Value: tensor(759.1213)\n",
      "Epoch: 398 Loss Value: tensor(661.6562)\n",
      "Epoch: 399 Loss Value: tensor(857.5817)\n",
      "Epoch: 400 Loss Value: tensor(690.6620)\n",
      "Epoch: 401 Loss Value: tensor(794.8441)\n",
      "Epoch: 402 Loss Value: tensor(690.4241)\n",
      "Epoch: 403 Loss Value: tensor(633.6191)\n",
      "Epoch: 404 Loss Value: tensor(774.1540)\n",
      "Epoch: 405 Loss Value: tensor(807.5392)\n",
      "Epoch: 406 Loss Value: tensor(821.3356)\n",
      "Epoch: 407 Loss Value: tensor(775.7554)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 408 Loss Value: tensor(662.4994)\n",
      "Epoch: 409 Loss Value: tensor(831.6558)\n",
      "Epoch: 410 Loss Value: tensor(688.8000)\n",
      "Epoch: 411 Loss Value: tensor(817.6851)\n",
      "Epoch: 412 Loss Value: tensor(631.8937)\n",
      "Epoch: 413 Loss Value: tensor(734.9788)\n",
      "Epoch: 414 Loss Value: tensor(754.5248)\n",
      "Epoch: 415 Loss Value: tensor(786.4851)\n",
      "Epoch: 416 Loss Value: tensor(726.5203)\n",
      "Epoch: 417 Loss Value: tensor(796.4897)\n",
      "Epoch: 418 Loss Value: tensor(708.7584)\n",
      "Epoch: 419 Loss Value: tensor(740.9841)\n",
      "Epoch: 420 Loss Value: tensor(763.4619)\n",
      "Epoch: 421 Loss Value: tensor(685.0720)\n",
      "Epoch: 422 Loss Value: tensor(649.8909)\n",
      "Epoch: 423 Loss Value: tensor(656.8367)\n",
      "Epoch: 424 Loss Value: tensor(699.5670)\n",
      "Epoch: 425 Loss Value: tensor(679.0283)\n",
      "Epoch: 426 Loss Value: tensor(776.7959)\n",
      "Epoch: 427 Loss Value: tensor(809.6401)\n",
      "Epoch: 428 Loss Value: tensor(706.5737)\n",
      "Epoch: 429 Loss Value: tensor(698.5643)\n",
      "Epoch: 430 Loss Value: tensor(680.8474)\n",
      "Epoch: 431 Loss Value: tensor(696.8506)\n",
      "Epoch: 432 Loss Value: tensor(737.9314)\n",
      "Epoch: 433 Loss Value: tensor(721.1310)\n",
      "Epoch: 434 Loss Value: tensor(607.7910)\n",
      "Epoch: 435 Loss Value: tensor(610.4142)\n",
      "Epoch: 436 Loss Value: tensor(771.2687)\n",
      "Epoch: 437 Loss Value: tensor(859.9547)\n",
      "Epoch: 438 Loss Value: tensor(583.8284)\n",
      "Epoch: 439 Loss Value: tensor(682.5450)\n",
      "Epoch: 440 Loss Value: tensor(659.7360)\n",
      "Epoch: 441 Loss Value: tensor(633.3904)\n",
      "Epoch: 442 Loss Value: tensor(658.6588)\n",
      "Epoch: 443 Loss Value: tensor(681.0356)\n",
      "Epoch: 444 Loss Value: tensor(571.0533)\n",
      "Epoch: 445 Loss Value: tensor(653.0002)\n",
      "Epoch: 446 Loss Value: tensor(804.2042)\n",
      "Epoch: 447 Loss Value: tensor(944.6700)\n",
      "Epoch: 448 Loss Value: tensor(749.7045)\n",
      "Epoch: 449 Loss Value: tensor(697.1924)\n",
      "Epoch: 450 Loss Value: tensor(657.2000)\n",
      "Epoch: 451 Loss Value: tensor(718.7772)\n",
      "Epoch: 452 Loss Value: tensor(689.1332)\n",
      "Epoch: 453 Loss Value: tensor(679.5900)\n",
      "Epoch: 454 Loss Value: tensor(696.1164)\n",
      "Epoch: 455 Loss Value: tensor(677.2198)\n",
      "Epoch: 456 Loss Value: tensor(825.7650)\n",
      "Epoch: 457 Loss Value: tensor(747.6606)\n",
      "Epoch: 458 Loss Value: tensor(718.4447)\n",
      "Epoch: 459 Loss Value: tensor(682.3605)\n",
      "Epoch: 460 Loss Value: tensor(732.0273)\n",
      "Epoch: 461 Loss Value: tensor(863.1881)\n",
      "Epoch: 462 Loss Value: tensor(763.1974)\n",
      "Epoch: 463 Loss Value: tensor(721.8550)\n",
      "Epoch: 464 Loss Value: tensor(664.1780)\n",
      "Epoch: 465 Loss Value: tensor(631.7543)\n",
      "Epoch: 466 Loss Value: tensor(720.3189)\n",
      "Epoch: 467 Loss Value: tensor(745.0808)\n",
      "Epoch: 468 Loss Value: tensor(702.1475)\n",
      "Epoch: 469 Loss Value: tensor(628.7616)\n",
      "Epoch: 470 Loss Value: tensor(723.9564)\n",
      "Epoch: 471 Loss Value: tensor(765.9771)\n",
      "Epoch: 472 Loss Value: tensor(570.3311)\n",
      "Epoch: 473 Loss Value: tensor(670.1604)\n",
      "Epoch: 474 Loss Value: tensor(624.9965)\n",
      "Epoch: 475 Loss Value: tensor(707.6403)\n",
      "Epoch: 476 Loss Value: tensor(671.9510)\n",
      "Epoch: 477 Loss Value: tensor(687.1183)\n",
      "Epoch: 478 Loss Value: tensor(686.3481)\n",
      "Epoch: 479 Loss Value: tensor(686.5071)\n",
      "Epoch: 480 Loss Value: tensor(693.4005)\n",
      "Epoch: 481 Loss Value: tensor(649.0112)\n",
      "Epoch: 482 Loss Value: tensor(701.2789)\n",
      "Epoch: 483 Loss Value: tensor(711.9188)\n",
      "Epoch: 484 Loss Value: tensor(780.6827)\n",
      "Epoch: 485 Loss Value: tensor(637.6960)\n",
      "Epoch: 486 Loss Value: tensor(749.1664)\n",
      "Epoch: 487 Loss Value: tensor(674.1514)\n",
      "Epoch: 488 Loss Value: tensor(765.1055)\n",
      "Epoch: 489 Loss Value: tensor(751.1191)\n",
      "Epoch: 490 Loss Value: tensor(667.6803)\n",
      "Epoch: 491 Loss Value: tensor(649.4169)\n",
      "Epoch: 492 Loss Value: tensor(758.6206)\n",
      "Epoch: 493 Loss Value: tensor(628.9047)\n",
      "Epoch: 494 Loss Value: tensor(604.3293)\n",
      "Epoch: 495 Loss Value: tensor(658.6411)\n",
      "Epoch: 496 Loss Value: tensor(791.6094)\n",
      "Epoch: 497 Loss Value: tensor(665.7638)\n",
      "Epoch: 498 Loss Value: tensor(706.8385)\n",
      "Epoch: 499 Loss Value: tensor(718.0624)\n",
      "Epoch: 500 Loss Value: tensor(727.8323)\n",
      "Epoch: 501 Loss Value: tensor(650.0535)\n",
      "Epoch: 502 Loss Value: tensor(670.7544)\n",
      "Epoch: 503 Loss Value: tensor(682.4196)\n",
      "Epoch: 504 Loss Value: tensor(717.7648)\n",
      "Epoch: 505 Loss Value: tensor(729.7720)\n",
      "Epoch: 506 Loss Value: tensor(686.9670)\n",
      "Epoch: 507 Loss Value: tensor(680.1012)\n",
      "Epoch: 508 Loss Value: tensor(776.8064)\n",
      "Epoch: 509 Loss Value: tensor(640.9041)\n",
      "Epoch: 510 Loss Value: tensor(640.7781)\n",
      "Epoch: 511 Loss Value: tensor(649.9836)\n",
      "Epoch: 512 Loss Value: tensor(713.6299)\n",
      "Epoch: 513 Loss Value: tensor(673.2653)\n",
      "Epoch: 514 Loss Value: tensor(702.3243)\n",
      "Epoch: 515 Loss Value: tensor(559.7399)\n",
      "Epoch: 516 Loss Value: tensor(707.5040)\n",
      "Epoch: 517 Loss Value: tensor(626.9220)\n",
      "Epoch: 518 Loss Value: tensor(624.2173)\n",
      "Epoch: 519 Loss Value: tensor(560.9381)\n",
      "Epoch: 520 Loss Value: tensor(721.2859)\n",
      "Epoch: 521 Loss Value: tensor(624.4866)\n",
      "Epoch: 522 Loss Value: tensor(604.5760)\n",
      "Epoch: 523 Loss Value: tensor(668.0035)\n",
      "Epoch: 524 Loss Value: tensor(731.6282)\n",
      "Epoch: 525 Loss Value: tensor(728.7535)\n",
      "Epoch: 526 Loss Value: tensor(618.5665)\n",
      "Epoch: 527 Loss Value: tensor(703.1487)\n",
      "Epoch: 528 Loss Value: tensor(599.9324)\n",
      "Epoch: 529 Loss Value: tensor(662.8894)\n",
      "Epoch: 530 Loss Value: tensor(693.3288)\n",
      "Epoch: 531 Loss Value: tensor(578.2106)\n",
      "Epoch: 532 Loss Value: tensor(752.5845)\n",
      "Epoch: 533 Loss Value: tensor(681.2439)\n",
      "Epoch: 534 Loss Value: tensor(598.1067)\n",
      "Epoch: 535 Loss Value: tensor(732.1970)\n",
      "Epoch: 536 Loss Value: tensor(676.8724)\n",
      "Epoch: 537 Loss Value: tensor(559.7717)\n",
      "Epoch: 538 Loss Value: tensor(707.5788)\n",
      "Epoch: 539 Loss Value: tensor(778.9144)\n",
      "Epoch: 540 Loss Value: tensor(626.3912)\n",
      "Epoch: 541 Loss Value: tensor(648.8312)\n",
      "Epoch: 542 Loss Value: tensor(727.4190)\n",
      "Epoch: 543 Loss Value: tensor(643.5074)\n",
      "Epoch: 544 Loss Value: tensor(663.8878)\n",
      "Epoch: 545 Loss Value: tensor(687.0447)\n",
      "Epoch: 546 Loss Value: tensor(671.9436)\n",
      "Epoch: 547 Loss Value: tensor(668.6797)\n",
      "Epoch: 548 Loss Value: tensor(730.6826)\n",
      "Epoch: 549 Loss Value: tensor(595.6888)\n",
      "Epoch: 550 Loss Value: tensor(738.5018)\n",
      "Epoch: 551 Loss Value: tensor(752.3936)\n",
      "Epoch: 552 Loss Value: tensor(670.2941)\n",
      "Epoch: 553 Loss Value: tensor(638.9448)\n",
      "Epoch: 554 Loss Value: tensor(766.6271)\n",
      "Epoch: 555 Loss Value: tensor(806.3132)\n",
      "Epoch: 556 Loss Value: tensor(689.5055)\n",
      "Epoch: 557 Loss Value: tensor(716.4911)\n",
      "Epoch: 558 Loss Value: tensor(697.8017)\n",
      "Epoch: 559 Loss Value: tensor(775.5466)\n",
      "Epoch: 560 Loss Value: tensor(697.8542)\n",
      "Epoch: 561 Loss Value: tensor(627.5984)\n",
      "Epoch: 562 Loss Value: tensor(647.6532)\n",
      "Epoch: 563 Loss Value: tensor(744.4861)\n",
      "Epoch: 564 Loss Value: tensor(669.1786)\n",
      "Epoch: 565 Loss Value: tensor(628.9427)\n",
      "Epoch: 566 Loss Value: tensor(770.0264)\n",
      "Epoch: 567 Loss Value: tensor(705.0146)\n",
      "Epoch: 568 Loss Value: tensor(658.4738)\n",
      "Epoch: 569 Loss Value: tensor(705.5544)\n",
      "Epoch: 570 Loss Value: tensor(836.7396)\n",
      "Epoch: 571 Loss Value: tensor(700.5949)\n",
      "Epoch: 572 Loss Value: tensor(623.7012)\n",
      "Epoch: 573 Loss Value: tensor(800.6803)\n",
      "Epoch: 574 Loss Value: tensor(634.7465)\n",
      "Epoch: 575 Loss Value: tensor(706.4017)\n",
      "Epoch: 576 Loss Value: tensor(701.5972)\n",
      "Epoch: 577 Loss Value: tensor(648.2334)\n",
      "Epoch: 578 Loss Value: tensor(663.8204)\n",
      "Epoch: 579 Loss Value: tensor(606.0840)\n",
      "Epoch: 580 Loss Value: tensor(645.2834)\n",
      "Epoch: 581 Loss Value: tensor(642.6930)\n",
      "Epoch: 582 Loss Value: tensor(709.1403)\n",
      "Epoch: 583 Loss Value: tensor(652.4395)\n",
      "Epoch: 584 Loss Value: tensor(640.3505)\n",
      "Epoch: 585 Loss Value: tensor(616.5503)\n",
      "Epoch: 586 Loss Value: tensor(717.7697)\n",
      "Epoch: 587 Loss Value: tensor(748.0157)\n",
      "Epoch: 588 Loss Value: tensor(528.7574)\n",
      "Epoch: 589 Loss Value: tensor(634.7043)\n",
      "Epoch: 590 Loss Value: tensor(766.0354)\n",
      "Epoch: 591 Loss Value: tensor(624.6165)\n",
      "Epoch: 592 Loss Value: tensor(687.5559)\n",
      "Epoch: 593 Loss Value: tensor(596.7196)\n",
      "Epoch: 594 Loss Value: tensor(751.6688)\n",
      "Epoch: 595 Loss Value: tensor(635.0364)\n",
      "Epoch: 596 Loss Value: tensor(766.0809)\n",
      "Epoch: 597 Loss Value: tensor(716.3510)\n",
      "Epoch: 598 Loss Value: tensor(621.5892)\n",
      "Epoch: 599 Loss Value: tensor(808.5513)\n",
      "Epoch: 600 Loss Value: tensor(642.8044)\n",
      "Epoch: 601 Loss Value: tensor(741.2197)\n",
      "Epoch: 602 Loss Value: tensor(649.7982)\n",
      "Epoch: 603 Loss Value: tensor(583.5129)\n",
      "Epoch: 604 Loss Value: tensor(730.9216)\n",
      "Epoch: 605 Loss Value: tensor(758.4988)\n",
      "Epoch: 606 Loss Value: tensor(758.6422)\n",
      "Epoch: 607 Loss Value: tensor(705.3987)\n",
      "Epoch: 608 Loss Value: tensor(621.5566)\n",
      "Epoch: 609 Loss Value: tensor(787.4617)\n",
      "Epoch: 610 Loss Value: tensor(639.2261)\n",
      "Epoch: 611 Loss Value: tensor(747.0157)\n",
      "Epoch: 612 Loss Value: tensor(606.3059)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 613 Loss Value: tensor(674.2598)\n",
      "Epoch: 614 Loss Value: tensor(693.3301)\n",
      "Epoch: 615 Loss Value: tensor(722.1578)\n",
      "Epoch: 616 Loss Value: tensor(667.7405)\n",
      "Epoch: 617 Loss Value: tensor(729.8625)\n",
      "Epoch: 618 Loss Value: tensor(670.1808)\n",
      "Epoch: 619 Loss Value: tensor(679.3998)\n",
      "Epoch: 620 Loss Value: tensor(707.5817)\n",
      "Epoch: 621 Loss Value: tensor(651.3519)\n",
      "Epoch: 622 Loss Value: tensor(619.7169)\n",
      "Epoch: 623 Loss Value: tensor(627.6108)\n",
      "Epoch: 624 Loss Value: tensor(675.7376)\n",
      "Epoch: 625 Loss Value: tensor(652.1686)\n",
      "Epoch: 626 Loss Value: tensor(732.8105)\n",
      "Epoch: 627 Loss Value: tensor(782.0482)\n",
      "Epoch: 628 Loss Value: tensor(691.8762)\n",
      "Epoch: 629 Loss Value: tensor(670.0233)\n",
      "Epoch: 630 Loss Value: tensor(649.7013)\n",
      "Epoch: 631 Loss Value: tensor(646.5648)\n",
      "Epoch: 632 Loss Value: tensor(698.1451)\n",
      "Epoch: 633 Loss Value: tensor(670.8772)\n",
      "Epoch: 634 Loss Value: tensor(564.8656)\n",
      "Epoch: 635 Loss Value: tensor(570.1173)\n",
      "Epoch: 636 Loss Value: tensor(740.4938)\n",
      "Epoch: 637 Loss Value: tensor(808.6784)\n",
      "Epoch: 638 Loss Value: tensor(551.6632)\n",
      "Epoch: 639 Loss Value: tensor(637.0495)\n",
      "Epoch: 640 Loss Value: tensor(605.2594)\n",
      "Epoch: 641 Loss Value: tensor(591.9835)\n",
      "Epoch: 642 Loss Value: tensor(597.8649)\n",
      "Epoch: 643 Loss Value: tensor(653.4973)\n",
      "Epoch: 644 Loss Value: tensor(531.1725)\n",
      "Epoch: 645 Loss Value: tensor(655.3336)\n",
      "Epoch: 646 Loss Value: tensor(760.3658)\n",
      "Epoch: 647 Loss Value: tensor(877.3245)\n",
      "Epoch: 648 Loss Value: tensor(688.3495)\n",
      "Epoch: 649 Loss Value: tensor(638.3395)\n",
      "Epoch: 650 Loss Value: tensor(644.5920)\n",
      "Epoch: 651 Loss Value: tensor(685.1360)\n",
      "Epoch: 652 Loss Value: tensor(669.1502)\n",
      "Epoch: 653 Loss Value: tensor(645.7772)\n",
      "Epoch: 654 Loss Value: tensor(668.2279)\n",
      "Epoch: 655 Loss Value: tensor(615.8085)\n",
      "Epoch: 656 Loss Value: tensor(785.2122)\n",
      "Epoch: 657 Loss Value: tensor(716.2826)\n",
      "Epoch: 658 Loss Value: tensor(680.3990)\n",
      "Epoch: 659 Loss Value: tensor(648.3093)\n",
      "Epoch: 660 Loss Value: tensor(680.9634)\n",
      "Epoch: 661 Loss Value: tensor(823.9599)\n",
      "Epoch: 662 Loss Value: tensor(729.8658)\n",
      "Epoch: 663 Loss Value: tensor(688.6898)\n",
      "Epoch: 664 Loss Value: tensor(610.1857)\n",
      "Epoch: 665 Loss Value: tensor(602.4180)\n",
      "Epoch: 666 Loss Value: tensor(671.9514)\n",
      "Epoch: 667 Loss Value: tensor(693.3792)\n",
      "Epoch: 668 Loss Value: tensor(663.2992)\n",
      "Epoch: 669 Loss Value: tensor(597.4636)\n",
      "Epoch: 670 Loss Value: tensor(668.6622)\n",
      "Epoch: 671 Loss Value: tensor(724.3923)\n",
      "Epoch: 672 Loss Value: tensor(529.0835)\n",
      "Epoch: 673 Loss Value: tensor(648.1636)\n",
      "Epoch: 674 Loss Value: tensor(586.4435)\n",
      "Epoch: 675 Loss Value: tensor(656.4396)\n",
      "Epoch: 676 Loss Value: tensor(620.0367)\n",
      "Epoch: 677 Loss Value: tensor(644.0461)\n",
      "Epoch: 678 Loss Value: tensor(650.4084)\n",
      "Epoch: 679 Loss Value: tensor(660.2793)\n",
      "Epoch: 680 Loss Value: tensor(661.6119)\n",
      "Epoch: 681 Loss Value: tensor(598.0499)\n",
      "Epoch: 682 Loss Value: tensor(650.1548)\n",
      "Epoch: 683 Loss Value: tensor(648.2808)\n",
      "Epoch: 684 Loss Value: tensor(718.5539)\n",
      "Epoch: 685 Loss Value: tensor(603.2560)\n",
      "Epoch: 686 Loss Value: tensor(704.8285)\n",
      "Epoch: 687 Loss Value: tensor(644.9891)\n",
      "Epoch: 688 Loss Value: tensor(718.8420)\n",
      "Epoch: 689 Loss Value: tensor(738.5842)\n",
      "Epoch: 690 Loss Value: tensor(633.2737)\n",
      "Epoch: 691 Loss Value: tensor(615.4056)\n",
      "Epoch: 692 Loss Value: tensor(721.0662)\n",
      "Epoch: 693 Loss Value: tensor(599.3221)\n",
      "Epoch: 694 Loss Value: tensor(565.0677)\n",
      "Epoch: 695 Loss Value: tensor(622.4337)\n",
      "Epoch: 696 Loss Value: tensor(731.9041)\n",
      "Epoch: 697 Loss Value: tensor(611.7249)\n",
      "Epoch: 698 Loss Value: tensor(676.7876)\n",
      "Epoch: 699 Loss Value: tensor(676.6773)\n",
      "Epoch: 700 Loss Value: tensor(693.0571)\n",
      "Epoch: 701 Loss Value: tensor(616.8779)\n",
      "Epoch: 702 Loss Value: tensor(622.5518)\n",
      "Epoch: 703 Loss Value: tensor(632.5901)\n",
      "Epoch: 704 Loss Value: tensor(659.1823)\n",
      "Epoch: 705 Loss Value: tensor(696.1138)\n",
      "Epoch: 706 Loss Value: tensor(645.7638)\n",
      "Epoch: 707 Loss Value: tensor(618.2189)\n",
      "Epoch: 708 Loss Value: tensor(737.3110)\n",
      "Epoch: 709 Loss Value: tensor(613.0796)\n",
      "Epoch: 710 Loss Value: tensor(627.3344)\n",
      "Epoch: 711 Loss Value: tensor(650.3751)\n",
      "Epoch: 712 Loss Value: tensor(692.1738)\n",
      "Epoch: 713 Loss Value: tensor(654.2935)\n",
      "Epoch: 714 Loss Value: tensor(668.7782)\n",
      "Epoch: 715 Loss Value: tensor(544.5738)\n",
      "Epoch: 716 Loss Value: tensor(704.3441)\n",
      "Epoch: 717 Loss Value: tensor(589.1803)\n",
      "Epoch: 718 Loss Value: tensor(605.0433)\n",
      "Epoch: 719 Loss Value: tensor(528.0925)\n",
      "Epoch: 720 Loss Value: tensor(690.9610)\n",
      "Epoch: 721 Loss Value: tensor(598.0538)\n",
      "Epoch: 722 Loss Value: tensor(589.9321)\n",
      "Epoch: 723 Loss Value: tensor(628.7811)\n",
      "Epoch: 724 Loss Value: tensor(700.7352)\n",
      "Epoch: 725 Loss Value: tensor(692.4558)\n",
      "Epoch: 726 Loss Value: tensor(596.7275)\n",
      "Epoch: 727 Loss Value: tensor(684.2732)\n",
      "Epoch: 728 Loss Value: tensor(546.6591)\n",
      "Epoch: 729 Loss Value: tensor(626.1084)\n",
      "Epoch: 730 Loss Value: tensor(647.0846)\n",
      "Epoch: 731 Loss Value: tensor(553.6930)\n",
      "Epoch: 732 Loss Value: tensor(725.0548)\n",
      "Epoch: 733 Loss Value: tensor(661.1851)\n",
      "Epoch: 734 Loss Value: tensor(558.3803)\n",
      "Epoch: 735 Loss Value: tensor(692.9590)\n",
      "Epoch: 736 Loss Value: tensor(633.8603)\n",
      "Epoch: 737 Loss Value: tensor(545.8164)\n",
      "Epoch: 738 Loss Value: tensor(676.6657)\n",
      "Epoch: 739 Loss Value: tensor(732.3925)\n",
      "Epoch: 740 Loss Value: tensor(614.8102)\n",
      "Epoch: 741 Loss Value: tensor(613.5403)\n",
      "Epoch: 742 Loss Value: tensor(683.1219)\n",
      "Epoch: 743 Loss Value: tensor(618.4430)\n",
      "Epoch: 744 Loss Value: tensor(632.9986)\n",
      "Epoch: 745 Loss Value: tensor(662.5562)\n",
      "Epoch: 746 Loss Value: tensor(638.7908)\n",
      "Epoch: 747 Loss Value: tensor(662.2472)\n",
      "Epoch: 748 Loss Value: tensor(722.7101)\n",
      "Epoch: 749 Loss Value: tensor(574.4492)\n",
      "Epoch: 750 Loss Value: tensor(695.4819)\n",
      "Epoch: 751 Loss Value: tensor(727.9547)\n",
      "Epoch: 752 Loss Value: tensor(633.3299)\n",
      "Epoch: 753 Loss Value: tensor(619.6505)\n",
      "Epoch: 754 Loss Value: tensor(755.2690)\n",
      "Epoch: 755 Loss Value: tensor(773.2616)\n",
      "Epoch: 756 Loss Value: tensor(662.2808)\n",
      "Epoch: 757 Loss Value: tensor(701.7385)\n",
      "Epoch: 758 Loss Value: tensor(680.9022)\n",
      "Epoch: 759 Loss Value: tensor(749.8680)\n",
      "Epoch: 760 Loss Value: tensor(672.5210)\n",
      "Epoch: 761 Loss Value: tensor(598.7708)\n",
      "Epoch: 762 Loss Value: tensor(617.4073)\n",
      "Epoch: 763 Loss Value: tensor(686.9067)\n",
      "Epoch: 764 Loss Value: tensor(623.2648)\n",
      "Epoch: 765 Loss Value: tensor(617.2057)\n",
      "Epoch: 766 Loss Value: tensor(744.6783)\n",
      "Epoch: 767 Loss Value: tensor(680.1517)\n",
      "Epoch: 768 Loss Value: tensor(646.0959)\n",
      "Epoch: 769 Loss Value: tensor(670.8872)\n",
      "Epoch: 770 Loss Value: tensor(806.4453)\n",
      "Epoch: 771 Loss Value: tensor(658.9829)\n",
      "Epoch: 772 Loss Value: tensor(570.4814)\n",
      "Epoch: 773 Loss Value: tensor(762.1506)\n",
      "Epoch: 774 Loss Value: tensor(588.8921)\n",
      "Epoch: 775 Loss Value: tensor(658.2698)\n",
      "Epoch: 776 Loss Value: tensor(656.8477)\n",
      "Epoch: 777 Loss Value: tensor(602.3500)\n",
      "Epoch: 778 Loss Value: tensor(659.5171)\n",
      "Epoch: 779 Loss Value: tensor(582.8462)\n",
      "Epoch: 780 Loss Value: tensor(632.4445)\n",
      "Epoch: 781 Loss Value: tensor(592.2176)\n",
      "Epoch: 782 Loss Value: tensor(675.4349)\n",
      "Epoch: 783 Loss Value: tensor(629.9599)\n",
      "Epoch: 784 Loss Value: tensor(606.2968)\n",
      "Epoch: 785 Loss Value: tensor(590.3394)\n",
      "Epoch: 786 Loss Value: tensor(697.4413)\n",
      "Epoch: 787 Loss Value: tensor(710.1898)\n",
      "Epoch: 788 Loss Value: tensor(512.4973)\n",
      "Epoch: 789 Loss Value: tensor(616.8227)\n",
      "Epoch: 790 Loss Value: tensor(737.3837)\n",
      "Epoch: 791 Loss Value: tensor(649.5512)\n",
      "Epoch: 792 Loss Value: tensor(669.2607)\n",
      "Epoch: 793 Loss Value: tensor(597.6113)\n",
      "Epoch: 794 Loss Value: tensor(707.1221)\n",
      "Epoch: 795 Loss Value: tensor(592.2917)\n",
      "Epoch: 796 Loss Value: tensor(690.1785)\n",
      "Epoch: 797 Loss Value: tensor(681.6179)\n",
      "Epoch: 798 Loss Value: tensor(607.2056)\n",
      "Epoch: 799 Loss Value: tensor(772.1038)\n",
      "Epoch: 800 Loss Value: tensor(631.6704)\n",
      "Epoch: 801 Loss Value: tensor(745.9163)\n",
      "Epoch: 802 Loss Value: tensor(640.9594)\n",
      "Epoch: 803 Loss Value: tensor(567.7794)\n",
      "Epoch: 804 Loss Value: tensor(690.6180)\n",
      "Epoch: 805 Loss Value: tensor(730.5739)\n",
      "Epoch: 806 Loss Value: tensor(746.1674)\n",
      "Epoch: 807 Loss Value: tensor(663.8488)\n",
      "Epoch: 808 Loss Value: tensor(603.1688)\n",
      "Epoch: 809 Loss Value: tensor(760.4752)\n",
      "Epoch: 810 Loss Value: tensor(609.5474)\n",
      "Epoch: 811 Loss Value: tensor(723.6115)\n",
      "Epoch: 812 Loss Value: tensor(587.6160)\n",
      "Epoch: 813 Loss Value: tensor(651.0966)\n",
      "Epoch: 814 Loss Value: tensor(689.3698)\n",
      "Epoch: 815 Loss Value: tensor(706.5563)\n",
      "Epoch: 816 Loss Value: tensor(648.5537)\n",
      "Epoch: 817 Loss Value: tensor(703.3090)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 818 Loss Value: tensor(649.8696)\n",
      "Epoch: 819 Loss Value: tensor(659.8196)\n",
      "Epoch: 820 Loss Value: tensor(660.7679)\n",
      "Epoch: 821 Loss Value: tensor(612.8576)\n",
      "Epoch: 822 Loss Value: tensor(586.5786)\n",
      "Epoch: 823 Loss Value: tensor(584.6374)\n",
      "Epoch: 824 Loss Value: tensor(634.8307)\n",
      "Epoch: 825 Loss Value: tensor(619.0660)\n",
      "Epoch: 826 Loss Value: tensor(709.6814)\n",
      "Epoch: 827 Loss Value: tensor(728.1398)\n",
      "Epoch: 828 Loss Value: tensor(629.3221)\n",
      "Epoch: 829 Loss Value: tensor(629.6547)\n",
      "Epoch: 830 Loss Value: tensor(617.6124)\n",
      "Epoch: 831 Loss Value: tensor(627.1702)\n",
      "Epoch: 832 Loss Value: tensor(669.0418)\n",
      "Epoch: 833 Loss Value: tensor(641.4303)\n",
      "Epoch: 834 Loss Value: tensor(545.6451)\n",
      "Epoch: 835 Loss Value: tensor(556.0389)\n",
      "Epoch: 836 Loss Value: tensor(709.2994)\n",
      "Epoch: 837 Loss Value: tensor(760.2838)\n",
      "Epoch: 838 Loss Value: tensor(517.9813)\n",
      "Epoch: 839 Loss Value: tensor(613.6146)\n",
      "Epoch: 840 Loss Value: tensor(585.8438)\n",
      "Epoch: 841 Loss Value: tensor(577.8060)\n",
      "Epoch: 842 Loss Value: tensor(577.1006)\n",
      "Epoch: 843 Loss Value: tensor(652.0397)\n",
      "Epoch: 844 Loss Value: tensor(528.6117)\n",
      "Epoch: 845 Loss Value: tensor(596.0668)\n",
      "Epoch: 846 Loss Value: tensor(718.4137)\n",
      "Epoch: 847 Loss Value: tensor(858.6365)\n",
      "Epoch: 848 Loss Value: tensor(689.4432)\n",
      "Epoch: 849 Loss Value: tensor(606.8088)\n",
      "Epoch: 850 Loss Value: tensor(600.3405)\n",
      "Epoch: 851 Loss Value: tensor(643.0913)\n",
      "Epoch: 852 Loss Value: tensor(611.8275)\n",
      "Epoch: 853 Loss Value: tensor(613.0784)\n",
      "Epoch: 854 Loss Value: tensor(625.5237)\n",
      "Epoch: 855 Loss Value: tensor(606.8978)\n",
      "Epoch: 856 Loss Value: tensor(747.6223)\n",
      "Epoch: 857 Loss Value: tensor(688.0475)\n",
      "Epoch: 858 Loss Value: tensor(661.9289)\n",
      "Epoch: 859 Loss Value: tensor(622.0547)\n",
      "Epoch: 860 Loss Value: tensor(681.3399)\n",
      "Epoch: 861 Loss Value: tensor(803.1421)\n",
      "Epoch: 862 Loss Value: tensor(708.7139)\n",
      "Epoch: 863 Loss Value: tensor(668.5959)\n",
      "Epoch: 864 Loss Value: tensor(621.5349)\n",
      "Epoch: 865 Loss Value: tensor(586.0734)\n",
      "Epoch: 866 Loss Value: tensor(642.3967)\n",
      "Epoch: 867 Loss Value: tensor(670.8866)\n",
      "Epoch: 868 Loss Value: tensor(643.1697)\n",
      "Epoch: 869 Loss Value: tensor(576.4955)\n",
      "Epoch: 870 Loss Value: tensor(642.4567)\n",
      "Epoch: 871 Loss Value: tensor(702.1227)\n",
      "Epoch: 872 Loss Value: tensor(503.8716)\n",
      "Epoch: 873 Loss Value: tensor(632.3856)\n",
      "Epoch: 874 Loss Value: tensor(584.3969)\n",
      "Epoch: 875 Loss Value: tensor(653.0584)\n",
      "Epoch: 876 Loss Value: tensor(614.3760)\n",
      "Epoch: 877 Loss Value: tensor(623.3282)\n",
      "Epoch: 878 Loss Value: tensor(635.0110)\n",
      "Epoch: 879 Loss Value: tensor(629.2990)\n",
      "Epoch: 880 Loss Value: tensor(648.7947)\n",
      "Epoch: 881 Loss Value: tensor(579.6033)\n",
      "Epoch: 882 Loss Value: tensor(618.4700)\n",
      "Epoch: 883 Loss Value: tensor(628.6166)\n",
      "Epoch: 884 Loss Value: tensor(706.7536)\n",
      "Epoch: 885 Loss Value: tensor(556.5180)\n",
      "Epoch: 886 Loss Value: tensor(671.2418)\n",
      "Epoch: 887 Loss Value: tensor(599.7139)\n",
      "Epoch: 888 Loss Value: tensor(709.0460)\n",
      "Epoch: 889 Loss Value: tensor(693.0492)\n",
      "Epoch: 890 Loss Value: tensor(608.3264)\n",
      "Epoch: 891 Loss Value: tensor(604.6382)\n",
      "Epoch: 892 Loss Value: tensor(719.7515)\n",
      "Epoch: 893 Loss Value: tensor(591.4211)\n",
      "Epoch: 894 Loss Value: tensor(566.2737)\n",
      "Epoch: 895 Loss Value: tensor(608.6901)\n",
      "Epoch: 896 Loss Value: tensor(708.5211)\n",
      "Epoch: 897 Loss Value: tensor(600.4939)\n",
      "Epoch: 898 Loss Value: tensor(655.2626)\n",
      "Epoch: 899 Loss Value: tensor(647.4979)\n",
      "Epoch: 900 Loss Value: tensor(659.3202)\n",
      "Epoch: 901 Loss Value: tensor(587.2542)\n",
      "Epoch: 902 Loss Value: tensor(611.9354)\n",
      "Epoch: 903 Loss Value: tensor(619.1796)\n",
      "Epoch: 904 Loss Value: tensor(633.6604)\n",
      "Epoch: 905 Loss Value: tensor(658.0500)\n",
      "Epoch: 906 Loss Value: tensor(618.3040)\n",
      "Epoch: 907 Loss Value: tensor(620.8146)\n",
      "Epoch: 908 Loss Value: tensor(734.9642)\n",
      "Epoch: 909 Loss Value: tensor(595.8809)\n",
      "Epoch: 910 Loss Value: tensor(601.0942)\n",
      "Epoch: 911 Loss Value: tensor(610.2412)\n",
      "Epoch: 912 Loss Value: tensor(657.0072)\n",
      "Epoch: 913 Loss Value: tensor(618.0291)\n",
      "Epoch: 914 Loss Value: tensor(667.5756)\n",
      "Epoch: 915 Loss Value: tensor(521.6223)\n",
      "Epoch: 916 Loss Value: tensor(665.7699)\n",
      "Epoch: 917 Loss Value: tensor(566.1072)\n",
      "Epoch: 918 Loss Value: tensor(574.3185)\n",
      "Epoch: 919 Loss Value: tensor(526.1215)\n",
      "Epoch: 920 Loss Value: tensor(678.8223)\n",
      "Epoch: 921 Loss Value: tensor(590.3718)\n",
      "Epoch: 922 Loss Value: tensor(577.4388)\n",
      "Epoch: 923 Loss Value: tensor(611.2964)\n",
      "Epoch: 924 Loss Value: tensor(696.5559)\n",
      "Epoch: 925 Loss Value: tensor(665.3405)\n",
      "Epoch: 926 Loss Value: tensor(577.4261)\n",
      "Epoch: 927 Loss Value: tensor(666.0812)\n",
      "Epoch: 928 Loss Value: tensor(540.3182)\n",
      "Epoch: 929 Loss Value: tensor(613.2282)\n",
      "Epoch: 930 Loss Value: tensor(634.9575)\n",
      "Epoch: 931 Loss Value: tensor(538.2578)\n",
      "Epoch: 932 Loss Value: tensor(702.8613)\n",
      "Epoch: 933 Loss Value: tensor(633.1039)\n",
      "Epoch: 934 Loss Value: tensor(549.9680)\n",
      "Epoch: 935 Loss Value: tensor(682.8431)\n",
      "Epoch: 936 Loss Value: tensor(606.4404)\n",
      "Epoch: 937 Loss Value: tensor(550.0364)\n",
      "Epoch: 938 Loss Value: tensor(655.8696)\n",
      "Epoch: 939 Loss Value: tensor(723.5944)\n",
      "Epoch: 940 Loss Value: tensor(586.0674)\n",
      "Epoch: 941 Loss Value: tensor(599.5603)\n",
      "Epoch: 942 Loss Value: tensor(664.9037)\n",
      "Epoch: 943 Loss Value: tensor(599.9984)\n",
      "Epoch: 944 Loss Value: tensor(618.5774)\n",
      "Epoch: 945 Loss Value: tensor(625.4453)\n",
      "Epoch: 946 Loss Value: tensor(605.2139)\n",
      "Epoch: 947 Loss Value: tensor(630.2208)\n",
      "Epoch: 948 Loss Value: tensor(696.0042)\n",
      "Epoch: 949 Loss Value: tensor(539.0521)\n",
      "Epoch: 950 Loss Value: tensor(661.5730)\n",
      "Epoch: 951 Loss Value: tensor(725.0414)\n",
      "Epoch: 952 Loss Value: tensor(610.4369)\n",
      "Epoch: 953 Loss Value: tensor(601.9560)\n",
      "Epoch: 954 Loss Value: tensor(738.9650)\n",
      "Epoch: 955 Loss Value: tensor(750.5380)\n",
      "Epoch: 956 Loss Value: tensor(648.9465)\n",
      "Epoch: 957 Loss Value: tensor(675.0068)\n",
      "Epoch: 958 Loss Value: tensor(634.5423)\n",
      "Epoch: 959 Loss Value: tensor(730.3943)\n",
      "Epoch: 960 Loss Value: tensor(650.9825)\n",
      "Epoch: 961 Loss Value: tensor(577.7830)\n",
      "Epoch: 962 Loss Value: tensor(595.1878)\n",
      "Epoch: 963 Loss Value: tensor(661.0149)\n",
      "Epoch: 964 Loss Value: tensor(604.5778)\n",
      "Epoch: 965 Loss Value: tensor(601.2098)\n",
      "Epoch: 966 Loss Value: tensor(712.2297)\n",
      "Epoch: 967 Loss Value: tensor(652.4835)\n",
      "Epoch: 968 Loss Value: tensor(609.4490)\n",
      "Epoch: 969 Loss Value: tensor(658.6848)\n",
      "Epoch: 970 Loss Value: tensor(767.0977)\n",
      "Epoch: 971 Loss Value: tensor(626.0471)\n",
      "Epoch: 972 Loss Value: tensor(568.1995)\n",
      "Epoch: 973 Loss Value: tensor(761.1128)\n",
      "Epoch: 974 Loss Value: tensor(565.2772)\n",
      "Epoch: 975 Loss Value: tensor(647.5238)\n",
      "Epoch: 976 Loss Value: tensor(648.9049)\n",
      "Epoch: 977 Loss Value: tensor(618.1356)\n",
      "Epoch: 978 Loss Value: tensor(631.6451)\n",
      "Epoch: 979 Loss Value: tensor(561.0227)\n",
      "Epoch: 980 Loss Value: tensor(624.3741)\n",
      "Epoch: 981 Loss Value: tensor(594.6577)\n",
      "Epoch: 982 Loss Value: tensor(670.9036)\n",
      "Epoch: 983 Loss Value: tensor(608.3857)\n",
      "Epoch: 984 Loss Value: tensor(582.3501)\n",
      "Epoch: 985 Loss Value: tensor(584.4985)\n",
      "Epoch: 986 Loss Value: tensor(675.7640)\n",
      "Epoch: 987 Loss Value: tensor(688.0775)\n",
      "Epoch: 988 Loss Value: tensor(495.5986)\n",
      "Epoch: 989 Loss Value: tensor(614.5292)\n",
      "Epoch: 990 Loss Value: tensor(702.1633)\n",
      "Epoch: 991 Loss Value: tensor(621.3414)\n",
      "Epoch: 992 Loss Value: tensor(651.5465)\n",
      "Epoch: 993 Loss Value: tensor(608.8501)\n",
      "Epoch: 994 Loss Value: tensor(696.9830)\n",
      "Epoch: 995 Loss Value: tensor(573.6669)\n",
      "Epoch: 996 Loss Value: tensor(672.8445)\n",
      "Epoch: 997 Loss Value: tensor(663.2025)\n",
      "Epoch: 998 Loss Value: tensor(598.8556)\n",
      "Epoch: 999 Loss Value: tensor(720.3134)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Initialising and creating models....\")\n",
    "V=voc.num_words\n",
    "t1=time.time()\n",
    "# criterion=LabelSmoothing()\n",
    "criterion = LabelSmoothing(size=V, padding_idx=0, smoothing=0.0)\n",
    "\n",
    "model=make_model2(V,V)\n",
    "# model_opt=torch.optim.Adam(model.parameters(),lr=0.0001,betas=(0.9,0.988),eps=1e-9)\n",
    "model_opt = NoamOpt(model.source_embed[0].d_model, 1, 400,\n",
    "        torch.optim.Adam(model.parameters(), lr=0, betas=(0.9, 0.98), eps=1e-9))\n",
    "print(\"=\"*100)\n",
    "print(\"Creating Models took: \"+str(time.time()-t1))\n",
    "\n",
    "\n",
    "\n",
    "model.train()\n",
    "for epoch in range(1000):\n",
    "    \n",
    "    current_batch=batches[epoch%200]\n",
    "    loss_val=run_epoch(current_batch,model,SimpleLossCompute(model.generator, criterion, model_opt))\n",
    "    print(\"Epoch: \"+str(epoch)+\" Loss Value: \"+str(loss_val))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type_as(src.data)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, \n",
    "                           Variable(ys), \n",
    "                           Variable(subsequent_mask(ys.size(1))\n",
    "                                    .type_as(src.data)))\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.data[0]\n",
    "        ys = torch.cat([ys, \n",
    "                        torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=1)\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderDecoder(\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (self_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (src_attn): MultiHeadedAttention(\n",
       "          (linears): ModuleList(\n",
       "            (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (1): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (3): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (feed_forward): PositionwiseFeedForward(\n",
       "          (w_1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (w_2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (sublayer): ModuleList(\n",
       "          (0): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (1): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "          (2): SublayerConnection(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (norm): LayerNorm()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm()\n",
       "  )\n",
       "  (source_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (embed): Embedding(7816, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (target_embed): Sequential(\n",
       "    (0): Embeddings(\n",
       "      (embed): Embedding(7816, 512)\n",
       "    )\n",
       "    (1): PositionalEncoding(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (projection): Linear(in_features=512, out_features=7816, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(318)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'yes', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'your', 'studies', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(37)\n",
      "tensor(111)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 's', 'up', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'chase', 'you', 'd', 'better', 'come', 'home', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(200)\n",
      "tensor(5901)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'm', 'intruding', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'can', 'you', 'mix', 'a', 'martini', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(842)\n",
      "tensor(247)\n",
      "tensor(117)\n",
      "tensor(118)\n",
      "tensor(76)\n",
      "tensor(587)\n",
      "tensor(4)\n",
      "tensor(1034)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'ma', 'didn', 't', 'want', 'it', 'around', '.', 'after', '.', 'EOS', 'PAD']\n",
      "['SOS', 'oh', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(14)\n",
      "tensor(64)\n",
      "tensor(1483)\n",
      "tensor(56)\n",
      "tensor(601)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 're', 'so', 'full', 'of', 'shit', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'robbed', 'the', 'office', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(601)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'shit', '.', '.', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'check', 'your', 'read', 'out', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(200)\n",
      "tensor(192)\n",
      "tensor(76)\n",
      "tensor(37)\n",
      "tensor(1479)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'm', 'sure', 'it', 's', 'lovely', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'but', 'you', 'don', 't', 'want', 'to', 'hear', 'it', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(64)\n",
      "tensor(50)\n",
      "tensor(7)\n",
      "tensor(74)\n",
      "tensor(56)\n",
      "tensor(83)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'so', 'what', 'you', 'think', 'of', 'me', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'look', 'good', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(450)\n",
      "tensor(380)\n",
      "tensor(492)\n",
      "tensor(800)\n",
      "tensor(479)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'must', 'be', 'some', 'mess', 'back', 'there', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'well', 'ain', 't', 'no', 'use', 'hanging', 'around', 'here', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(239)\n",
      "tensor(4)\n",
      "tensor(23)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'uh', '.', 'huh', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'really', 'sorry', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(148)\n",
      "tensor(101)\n",
      "tensor(424)\n",
      "tensor(40)\n",
      "tensor(7)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'd', 'he', 'give', 'to', 'you', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'nothing', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(53)\n",
      "tensor(817)\n",
      "tensor(37)\n",
      "tensor(177)\n",
      "tensor(538)\n",
      "tensor(66)\n",
      "tensor(359)\n",
      "tensor(6)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'the', 'floor', 's', 'on', 'fire', '!', 'see', '?', '!', 'EOS', 'PAD']\n",
      "['SOS', 'what', '?', '?', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(14)\n",
      "tensor(692)\n",
      "tensor(12)\n",
      "tensor(164)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 're', 'quite', 'a', 'girl', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'think', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(197)\n",
      "tensor(117)\n",
      "tensor(25)\n",
      "tensor(158)\n",
      "tensor(208)\n",
      "tensor(41)\n",
      "tensor(96)\n",
      "tensor(45)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'don', 't', 'i', 'get', 'any', 'say', 'in', 'this', '?', 'EOS', 'PAD']\n",
      "['SOS', 'no', '!', 'because', 'i', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(597)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'whatever', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'not', 'whatever', '.', 'it', 's', 'two', 'different', 'things', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(1343)\n",
      "tensor(56)\n",
      "tensor(7)\n",
      "tensor(40)\n",
      "tensor(746)\n",
      "tensor(45)\n",
      "tensor(1679)\n",
      "tensor(5302)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'clever', 'of', 'you', 'to', 'find', 'this', 'spot', 'betty', '.', 'EOS', 'PAD']\n",
      "['SOS', 'it', 'pays', 'to', 'know', 'your', 'way', 'around', 'oliver', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(381)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'gone', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'must', 'have', 'frightened', 'her', 'away', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(122)\n",
      "tensor(101)\n",
      "tensor(3377)\n",
      "tensor(76)\n",
      "tensor(96)\n",
      "tensor(253)\n",
      "tensor(1558)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'and', 'he', 'keeps', 'it', 'in', 'his', 'apartment', '?', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'yes', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(477)\n",
      "tensor(111)\n",
      "tensor(45)\n",
      "tensor(2414)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'turn', 'up', 'this', 'road', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'where', 'we', 'headed', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(124)\n",
      "tensor(115)\n",
      "tensor(36)\n",
      "tensor(64)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'oh', 'is', 'that', 'so', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'afraid', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(34)\n",
      "tensor(61)\n",
      "tensor(37)\n",
      "tensor(82)\n",
      "tensor(467)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'no', 'she', 's', 'getting', 'married', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'to', 'you', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(3925)\n",
      "tensor(401)\n",
      "tensor(159)\n",
      "tensor(4)\n",
      "tensor(48)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'anne', 'come', 'here', '.', 'listen', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'look', 'out', 'for', 'my', 'lipstick', 'stewart', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(5)\n",
      "tensor(37)\n",
      "tensor(70)\n",
      "tensor(3089)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'where', 's', 'your', 'master', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'what', 's', 'it', 'to', 'you', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(33)\n",
      "tensor(98)\n",
      "tensor(53)\n",
      "tensor(1002)\n",
      "tensor(659)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'well', 'for', 'the', 'baby', 'really', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'thank', 'you', 'billy', 'from', 'the', 'baby', 'and', 'me', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(68)\n",
      "tensor(7)\n",
      "tensor(41)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'did', 'you', 'say', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'said', 'you', 'were', 'a', 'loser', '!', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(14)\n",
      "tensor(107)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 're', 'beautiful', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'wanna', 'change', 'my', 'hair', 'my', 'clothes', 'my', 'face', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(5501)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(5504)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'ash', '.', '.', '.', 'ashley', '.', '.', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'no', 'man', '!', 'no', 'no', 'no', '!', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(42)\n",
      "tensor(25)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'but', 'i', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'll', 'handle', 'it', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(45)\n",
      "tensor(115)\n",
      "tensor(147)\n",
      "tensor(27)\n",
      "tensor(89)\n",
      "tensor(7098)\n",
      "tensor(40)\n",
      "tensor(108)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'this', 'is', 'how', 'we', 've', 'managed', 'to', 'last', '.', 'EOS', 'PAD']\n",
      "['SOS', 'we', 're', 'able', 'to', 'surprise', 'each', 'other', '.', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(51)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'good', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'night', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(92)\n",
      "tensor(7)\n",
      "tensor(5407)\n",
      "tensor(188)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'are', 'you', 'staring', 'at', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'uh', '.', '.', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(387)\n",
      "tensor(4)\n",
      "tensor(59)\n",
      "tensor(83)\n",
      "tensor(158)\n",
      "tensor(53)\n",
      "tensor(2493)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'am', '.', 'let', 'me', 'get', 'the', 'cards', '.', 'EOS', 'PAD']\n",
      "['SOS', 'you', 'don', 't', 'have', 'to', 'entertain', 'me', '.', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(53)\n",
      "tensor(654)\n",
      "tensor(102)\n",
      "tensor(36)\n",
      "tensor(6)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'the', 'hell', 'was', 'that', '?', '!', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'dude', 'they', 'cut', 'out', 'minutes', '!', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(59)\n",
      "tensor(83)\n",
      "tensor(21)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'let', 'me', 'out', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'do', 'you', 'understand', 'what', 'i', 'said', '?', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(4992)\n",
      "tensor(129)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 'flew', 'before', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'no', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(124)\n",
      "tensor(125)\n",
      "tensor(34)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'oh', 'god', 'no', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'so', 'not', 'over', 'her', 'in', 'fact', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(1528)\n",
      "tensor(1664)\n",
      "tensor(4)\n",
      "tensor(92)\n",
      "tensor(3)\n",
      "tensor(208)\n",
      "tensor(2768)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'sounds', 'boring', '.', 'are', 'there', 'any', 'songs', '?', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'nothing', 'but', 'acting', 'to', 'hide', 'behind', 'buddy', 'boy', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(318)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'yes', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'yes', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(51)\n",
      "tensor(40)\n",
      "tensor(359)\n",
      "tensor(7)\n",
      "tensor(637)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'good', 'to', 'see', 'you', 'again', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'should', 'a', 'remembered', 'the', 'eggs', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(2155)\n",
      "tensor(21)\n",
      "tensor(159)\n",
      "tensor(1796)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'comin', 'out', 'here', 'boss', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'yeah', '.', 'come', 'on', 'out', 'luke', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(393)\n",
      "tensor(7144)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 'remember', 'junie', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'of', 'course', '.', 'hi', 'junie', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(3696)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'shhhh', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'what', 'is', 'this', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(383)\n",
      "tensor(7)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'thank', 'you', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'he', 's', 'my', 'brother', '.', '.', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(780)\n",
      "tensor(2143)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'nice', 'dress', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'thank', 'you', 'peter', '.', 'thank', 'you', 'so', 'much', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(5228)\n",
      "tensor(5243)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'comrade', 'kopalski', '.', '.', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'comrade', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(198)\n",
      "tensor(29)\n",
      "tensor(822)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'make', 'an', 'exception', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'there', 's', 'one', 'to', 'every', 'rule', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(697)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'understand', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'okay', '.', 'frankie', 'you', 're', 'a', 'good', 'boy', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'would', 'you', 'think', 'of', 'me', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(74)\n",
      "tensor(25)\n",
      "tensor(24)\n",
      "tensor(120)\n",
      "tensor(50)\n",
      "tensor(7)\n",
      "tensor(260)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'think', 'i', 'know', 'exactly', 'what', 'you', 'mean', '.', 'EOS', 'PAD']\n",
      "['SOS', 'you', 'do', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(1733)\n",
      "tensor(276)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 'calm', 'down', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'u', 'calm', 'u', 'u', 'down', 'u', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(88)\n",
      "tensor(147)\n",
      "tensor(575)\n",
      "tensor(92)\n",
      "tensor(27)\n",
      "tensor(621)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'hey', 'how', 'much', 'are', 'we', 'ahead', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'approximately', '?', 'one', 'thousand', 'bucks', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(101)\n",
      "tensor(102)\n",
      "tensor(631)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'he', 'was', 'killed', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'right', '.', 'when', 'he', 'was', 'killed', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(288)\n",
      "tensor(117)\n",
      "tensor(480)\n",
      "tensor(4)\n",
      "tensor(18)\n",
      "tensor(43)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 'weren', 't', 'home', '.', 'like', 'always', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'left', 'me', 'a', 'message', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(601)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'shit', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'what', 'is', 'it', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(51)\n",
      "tensor(109)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'good', 'night', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'night', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(36)\n",
      "tensor(37)\n",
      "tensor(1444)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'that', 's', 'incredible', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'yes', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(80)\n",
      "tensor(307)\n",
      "tensor(98)\n",
      "tensor(134)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'would', 'try', 'for', 'them', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'barely', 'know', 'them', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(92)\n",
      "tensor(7)\n",
      "tensor(2377)\n",
      "tensor(40)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'are', 'you', 'supposed', 'to', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'in', 'this', 'house', 'you', 're', 'supposed', 'to', '.', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(488)\n",
      "tensor(67)\n",
      "tensor(401)\n",
      "tensor(96)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'better', 'not', 'come', 'in', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'ain', 't', 'stupid', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(35)\n",
      "tensor(7)\n",
      "tensor(132)\n",
      "tensor(18)\n",
      "tensor(83)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'then', 'you', 'll', 'like', 'me', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'do', 'like', 'you', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(36)\n",
      "tensor(37)\n",
      "tensor(76)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'that', 's', 'it', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'but', 'that', 'wasn', 't', 'johnny', 's', 'fault', '.', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(318)\n",
      "tensor(200)\n",
      "tensor(7731)\n",
      "tensor(4)\n",
      "tensor(200)\n",
      "tensor(7731)\n",
      "tensor(7734)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'yes', 'm', 'sieu', '.', 'm', 'sieu', 'giron', '!', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'what', 'is', 'it', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(92)\n",
      "tensor(27)\n",
      "tensor(123)\n",
      "tensor(40)\n",
      "tensor(47)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'are', 'we', 'going', 'to', 'do', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'don', 't', 'know', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(3566)\n",
      "tensor(3567)\n",
      "tensor(2508)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'headache', 'nausea', 'lights', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'lights', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(14)\n",
      "tensor(7)\n",
      "tensor(278)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 're', 'you', 'doing', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'going', 'out', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(34)\n",
      "tensor(50)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'no', 'what', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'no', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(326)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'else', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'nothing', 'else', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(42)\n",
      "tensor(45)\n",
      "tensor(115)\n",
      "tensor(9)\n",
      "tensor(705)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'but', 'this', 'is', 'my', 'car', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'your', 'hearse', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(882)\n",
      "tensor(83)\n",
      "tensor(12)\n",
      "tensor(1728)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 'left', 'me', 'a', 'message', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'out', 'of', 'here', '.', 'jenny', '.', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(147)\n",
      "tensor(1322)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'how', 'different', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'as', 'different', 'as', 'it', 's', 'possible', 'to', 'be', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(115)\n",
      "tensor(45)\n",
      "tensor(70)\n",
      "tensor(403)\n",
      "tensor(227)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'is', 'this', 'your', 'first', 'time', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'yes', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(219)\n",
      "tensor(92)\n",
      "tensor(7)\n",
      "tensor(509)\n",
      "tensor(380)\n",
      "tensor(479)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'when', 'are', 'you', 'gonna', 'be', 'back', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'not', 'too', 'late', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(2986)\n",
      "tensor(122)\n",
      "tensor(3326)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'beth', 'and', 'harry', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'they', 're', 'in', 'the', 'sub', 'sir', '.', 'waiting', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(315)\n",
      "tensor(53)\n",
      "tensor(228)\n",
      "tensor(4)\n",
      "tensor(34)\n",
      "tensor(984)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 'knew', 'the', 'deal', '.', 'no', 'contact', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'who', 'was', 'that', 'other', 'guy', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(197)\n",
      "tensor(117)\n",
      "tensor(222)\n",
      "tensor(7)\n",
      "tensor(40)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'don', 't', 'expect', 'you', 'to', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'are', 'you', 'threatening', 'me', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(861)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', '.', '.', '.shit', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'to', 'tell', 'you', 'the', 'truth', 'you', 'didn', 't', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(39)\n",
      "tensor(40)\n",
      "tensor(380)\n",
      "tensor(1095)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'had', 'to', 'be', 'done', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'no', 'good', 'options', 'left', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(27)\n",
      "tensor(132)\n",
      "tensor(218)\n",
      "tensor(76)\n",
      "tensor(144)\n",
      "tensor(159)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'we', 'll', 'take', 'it', 'from', 'here', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'what', '?', 'who', 'the', 'hell', 'are', 'you', '?', 'EOS', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(47)\n",
      "tensor(7)\n",
      "tensor(24)\n",
      "tensor(50)\n",
      "tensor(45)\n",
      "tensor(115)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'do', 'you', 'know', 'what', 'this', 'is', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'presume', 'it', 's', 'a', 'sword', '.', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(4094)\n",
      "tensor(66)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'hildy', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'huh', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(53)\n",
      "tensor(654)\n",
      "tensor(92)\n",
      "tensor(7)\n",
      "tensor(206)\n",
      "tensor(75)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 'the', 'hell', 'are', 'you', 'talking', 'about', '?', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'watch', 'it', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(1924)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'knowledge', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'of', 'what', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(25)\n",
      "tensor(604)\n",
      "tensor(174)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'i', 'shot', 'him', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'killed', 'him', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(965)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 'american', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'no', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(124)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'oh', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'goodbye', 'folks', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(51)\n",
      "tensor(559)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'good', 'luck', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'you', 'too', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7344)\n",
      "tensor(76)\n",
      "tensor(37)\n",
      "tensor(83)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'tubbs', 'it', 's', 'me', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'well', 'where', 'are', 'ya', 'what', 'are', 'ya', 'drunk', '?', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(7)\n",
      "tensor(24)\n",
      "tensor(5335)\n",
      "tensor(4870)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'you', 'know', 'sid', 'fletcher', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'what', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(122)\n",
      "tensor(1596)\n",
      "tensor(37)\n",
      "tensor(96)\n",
      "tensor(76)\n",
      "tensor(266)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'and', 'jimmy', 's', 'in', 'it', 'right', '?', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'will', 'you', 'stop', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(50)\n",
      "tensor(37)\n",
      "tensor(36)\n",
      "tensor(6)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'what', 's', 'that', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'they', 'll', 'know', 'about', 'it', 'in', 'the', 'morning', '.', 'EOS']\n",
      "['SOS', 'i', 'm', 'not', 'not', '.', 'EOS', '.', 'EOS', '.']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(38)\n",
      "tensor(9)\n",
      "tensor(493)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'all', 'my', 'clothes', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'that', 's', 'right', 'worry', 'about', 'your', 'clothes', 'EOS', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(2413)\n",
      "tensor(53)\n",
      "tensor(2414)\n",
      "tensor(1807)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'during', 'the', 'road', 'test', '.', '.', '.', 'EOS', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'yeah', '?', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(2604)\n",
      "tensor(4)\n",
      "tensor(218)\n",
      "tensor(76)\n",
      "tensor(611)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'dignan', '.', 'take', 'it', 'easy', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'bob', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(48)\n",
      "tensor(40)\n",
      "tensor(45)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'listen', 'to', 'this', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'not', 'now', 'jonah', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n",
      "torch.Size([12])\n",
      "tensor(1)\n",
      "tensor(98)\n",
      "tensor(22)\n",
      "tensor(4)\n",
      "tensor(2)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "['SOS', 'for', 'tonight', '.', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'oh', '!', 'EOS', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD', 'PAD']\n",
      "['SOS', 'i', 'm', 'not', 'not', 'not', '.', 'EOS', '.', 'EOS']\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for batch in batches:\n",
    "    for i in range(5):\n",
    "        output=greedy_decode(model,batch.src[i].view(-1,12),batch.src_mask[i].view(1,-1,12),10,1)\n",
    "        src=batch.src[i].view(-1)\n",
    "        trg=batch.trg[i].view(-1)\n",
    "        pred=output.view(-1)\n",
    "        print(src.size())\n",
    "        for id in src:\n",
    "            print(id)\n",
    "        src_sentence=[voc.index2word[id.item()] for id in src]\n",
    "        trg_sentence=[voc.index2word[id.item()] for id in trg]\n",
    "        pred_sentence=[voc.index2word[id.item()] for id in pred]\n",
    "        print(src_sentence)\n",
    "        print(trg_sentence)\n",
    "        print(pred_sentence)\n",
    "        print(\"-\"*80)\n",
    "#         print(\"-\"*80)\n",
    "#         print(str(output)+\" \"+str(batch.src[i])+\" \"+str(batch.trg[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2, 10, 10,  9,  5,  3,  2,  9,  5]])\n"
     ]
    }
   ],
   "source": [
    "src = Variable(torch.LongTensor([[1,2,3,4,5,6,7,8,9,10]]) )\n",
    "src_mask = Variable(torch.ones(1, 1, 10) )\n",
    "print(greedy_decode(model, src, src_mask, max_len=10, start_symbol=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model,sentence,max_length):\n",
    "    input_tokens=[indexesFromSentence(voc,sentence)]\n",
    "    input_tokens=torch.LongTensor(input_tokens)\n",
    "    input_mask=(input_tokens!=0)\n",
    "    input_tokens=input_tokens.view(1,-1,12)\n",
    "    input_mask=input_mask.view(-1,12)\n",
    "    \n",
    "    output_tokens=greedy_decode(model,input_tokens,input_mask,max_length,1)\n",
    "    output_tokens=output_tokens.view(-1)\n",
    "    decoded_words=[voc.index2word[id.item()] for id in output_tokens]\n",
    "    return decoded_words\n",
    "\n",
    "def evaluateInput(model,voc,max_length):\n",
    "    \n",
    "    input_sentence=''\n",
    "    \n",
    "    while(1):\n",
    "        try:\n",
    "            input_sentence=input('<')\n",
    "            if(input_sentence=='q' or input_sentence=='quit'):\n",
    "                break\n",
    "            input_sentence=normalizeString(input_sentence)\n",
    "            output_words=evaluate(model,input_sentence,max_length)\n",
    "            output_words=[x for x in output_words if not(x=='EOS' or x=='PAD')]\n",
    "            print('Bot: ',' '.join(output_words))\n",
    "\n",
    "        except KeyError:\n",
    "            print(\"Unknown Words\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<hello\n",
      "Bot:  SOS i m waiting for your mother . .\n",
      "<how do you do\n",
      "Bot:  SOS i just want to know that s on your\n",
      "<i am good\n",
      "Bot:  SOS is that right ? ? ?\n",
      "<yes\n",
      "Bot:  SOS and she wanted to talk . .\n",
      "<q\n"
     ]
    }
   ],
   "source": [
    "evaluateInput(model,voc,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
