{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskNLLLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    print(inp.size())\n",
    "    print(target.size())\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    loss = loss.to(device)\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH=10\n",
    "def train(input_variable,lengths,target_variable,mask,max_target_len,encoder,decoder,embedding,\n",
    "          encoder_optimizer,decoder_optimizer,batch_size,clip,max_length=MAX_LENGTH):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_variable=input_variable.to(device)\n",
    "    lengths=lengths.to(device)\n",
    "    target_variable=target_variable.to(device)\n",
    "    mask=mask.to(device)\n",
    "    \n",
    "    loss=0\n",
    "    print_losses=[]\n",
    "    n_totals=0\n",
    "    \n",
    "    encoder_outputs, encoder_hidden=encoder(input_variable,lengths)\n",
    "    \n",
    "    decoder_input=torch.LongTensor([[START_Token for _ in range(batch_size)]])\n",
    "    decoder_input=decoder_input.to(device)\n",
    "    use_teacher_forcing=True if random.random<teacher_forcing_ration else False\n",
    "    \n",
    "    decoder_hidden=encoder_hidden[:decoder.n_layers]\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        \n",
    "        for t in range(max_target_len):\n",
    "            decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            \n",
    "            decoder_input=target_variable[t].view(1,-1)\n",
    "            \n",
    "            mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n",
    "            loss+=mask_loss\n",
    "            print_losses.append(mask_loss.item()*nTotal)\n",
    "            n_totals+=nTotal\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        for t in range(max_target_len):\n",
    "            decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            \n",
    "            _,topi=decoder_output.topk(1)\n",
    "            decoder_input=torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n",
    "            decoder_input=decoder_input.to(device)\n",
    "            \n",
    "            mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n",
    "            loss+=mask_loss\n",
    "            print_losses.append(mask_loss.item()*nTotal)\n",
    "            n_totals+=nTotal\n",
    "            \n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    _=nn.utils.clip_grad_norm(encoder.parameters(),clip)\n",
    "    _=nn.utils.clip_grad_norm(decoder.parameters(),clip)\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return sum(print_losses)/n_totals\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainiters(model_name,voc,pairs,encoder,decoder,encoder_optimizer,decoder_optimizer,\n",
    "               embedding,encoder_n_layers,decoder_n_layers,save_dir,n_iteration,batch_size,print_every,\n",
    "               save_every,corpus_name,loadFileName):\n",
    "    \n",
    "    training_batches=[batch2TrainData(voc,[random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_iterations)]\n",
    "    \n",
    "    start_iteration=1\n",
    "    print_loss=0\n",
    "    \n",
    "    if loadFileName:\n",
    "        start_iteration=checkpoint['iteration']+1\n",
    "        \n",
    "    for iteration in range(start_iteration,n_iteration):\n",
    "        training_batch=training_batches[iteration-1]\n",
    "        \n",
    "        input_variable,lengths,target_variable,mask,max_target_len=training_batch\n",
    "        \n",
    "        loss=train(input_variable,lengths,target_variable,mask,max_target_len,encoder,decoder,embedding,\n",
    "                   encoder_optimizer,decoder_optimizer,batch_size,clip)\n",
    "        \n",
    "        print_loss+=loss\n",
    "        \n",
    "        if iteration%print_every==0:\n",
    "            print_loss_avg=print_loss/print_every\n",
    "            print(\"Iteration: \"+str(iteration)+\"Loss: \"+str(print_loss_avg))\n",
    "            print_loss=0\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([])\n"
     ]
    }
   ],
   "source": [
    "x=torch.zeros([0])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,encoder,decoder):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder=encoder\n",
    "        self.decoder=decoder\n",
    "        \n",
    "    def forward(self,input_seq,input_length,max_length):\n",
    "        \n",
    "        encoder_outputs,encoder_hidden=self.encoder(input_seq,seq_length)\n",
    "        \n",
    "        decoder_hidden=encoder_hidden[:self.decoder.n_layers]\n",
    "        decoder_input=torch.ones(1,1,device=device,dtype=torch.long)*Start_Token\n",
    "        \n",
    "        all_tokens=torch.zeros([0],device=device,dtype=torch.long)\n",
    "        all_scores=torch.zeros([0],device=device)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            \n",
    "            decoder_output,decoder_hidden=self.decoder(decoder_input,decoder_hidden,encoder_outputs)\n",
    "            \n",
    "            decoder_scores,decoder_input=torch.max(decoder_output,dim=1)\n",
    "            all_scores=torch.cat((all_scores,decoder_scores),dim=0)\n",
    "            all_tokens=torch.cat((all_tokrns,decoder_input),dim=0)\n",
    "            \n",
    "            torch.unsqueeze(decoder_input,0)\n",
    "            \n",
    "        return all_tokens, all_scores\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher,voc,sentence,max_length=MAX_LENGTH):\n",
    "    \n",
    "    index_batch=[indexesFromSentence(voc,sentence)]\n",
    "    lengths=torch.tensor([len(index) for index in index_batch])\n",
    "    input_batch=torch.LongTensor(index_batch).transpose(0,1)\n",
    "    \n",
    "    input_batch=input_batch.to(device)\n",
    "    lengths=lengths.to(device)\n",
    "    \n",
    "    tokens, scores=searcher(input_batch,lengths,max_length)\n",
    "    decoded_words=[voc.index2word[token.item()] for token in tokens]\n",
    "    return decoder_words\n",
    "\n",
    "def evaluateInput(encoder,decoder,searcher,voc):\n",
    "    input_sentence=''\n",
    "    while True:\n",
    "        try:\n",
    "            input_sentence=input('Human> ')\n",
    "            \n",
    "            if input_sentence=='q' or input_sentence=='quit':\n",
    "                break\n",
    "            input_sentence=normalizeString(input_sentence)\n",
    "            output_words=evaluate(encoder,decoder,searcher,voc,input_sentence)\n",
    "            output_words[:]=[x for x in output_words if not(x==\"PAD\" or x==\"EOS\")]\n",
    "            print(\"Bot:\",\" \".join(output_words))\n",
    "            \n",
    "        except KeyError:\n",
    "            print(\"Unknown Word\")\n",
    "            \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
