{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"transformer_cornell.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMX1yUUjR8AnRzNJcCl3XFA"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8i8or0mWcKPL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b50d5268-3c91-4a06-8515-68c1e4f8d6ed","executionInfo":{"status":"ok","timestamp":1586265402371,"user_tz":-330,"elapsed":2922,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"R-KwziUccUv9","colab_type":"code","colab":{}},"source":["#Pre-Processing\n","import os\n","import re\n","import torch\n","import random\n","import itertools\n","\n","#Model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","import numpy as np\n","\n","# For visualising metrics\n","# from visdom import Visdom\n","\n","# For visualising gradients plot\n","import matplotlib.pyplot as plt\n","from matplotlib.lines import Line2D\n","\n","import copy\n","import math\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bzOQagtOdqyn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"718bd55b-2cc8-4aab-d690-29a60a595a9a","executionInfo":{"status":"ok","timestamp":1586265410181,"user_tz":-330,"elapsed":2780,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device=torch.device(\"cpu\")\n","print(\"The device found: \"+str(device))"],"execution_count":10,"outputs":[{"output_type":"stream","text":["The device found: cpu\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"19BVL5GNdtbi","colab_type":"code","colab":{}},"source":["def plot_grad_flow(named_parameters):\n","    \"\"\"\n","        Plotting gradient flow across various layers\n","        Thanks to: https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/2\n","    \"\"\"   \n","    ave_grads = []\n","    layers = []\n","    for n, p in named_parameters:\n","        if(p.requires_grad) and (\"bias\" not in n):\n","            layers.append(n)\n","            ave_grads.append(p.grad.abs().mean())\n","    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n","    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n","    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n","    plt.xlim(xmin=0, xmax=len(ave_grads))\n","    plt.xlabel(\"Layers\")\n","    plt.ylabel(\"average gradient\")\n","    plt.title(\"Gradient flow\")\n","    plt.grid(True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XyVbmpGw26_v","colab_type":"text"},"source":["# Preprocessing\n"]},{"cell_type":"code","metadata":{"id":"qz7CbxS4dwh3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"b0e4a30f-ab12-46c9-8cb2-957606252deb","executionInfo":{"status":"ok","timestamp":1586265420153,"user_tz":-330,"elapsed":3278,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["path='/content/drive/My Drive/Data'\n","dataset='cornell movie-dialogs corpus'\n","\n","data_folder=os.path.join(path,dataset)\n","\n","print(\"The final data corpus folder: \"+str(data_folder))"],"execution_count":12,"outputs":[{"output_type":"stream","text":["The final data corpus folder: /content/drive/My Drive/Data/cornell movie-dialogs corpus\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dDKqcO2de7RM","colab_type":"code","colab":{}},"source":["def get_lines_conversations():\n","    \"\"\"\n","    Loads movie lines and conversations from the dataset.\n","    \n","    data_folder: Destination where conversations and lines are stored.\n","    \n","    movie_lines: Consist of movie lines as given by the dataset.\n","    movie_conversations: Consist of movie conversations as given by the dataset.\n","    \n","    \"\"\"\n","    movie_lines=[]\n","    movie_conversations=[]\n","\n","    with open(os.path.join(data_folder,'movie_lines.txt'),'r',encoding='iso-8859-1') as f:\n","        for line in f:\n","            movie_lines.append(line)\n","    \n","    with open(os.path.join(data_folder,'movie_conversations.txt'),'r', encoding='iso-8859-1') as f:\n","        for line in f:\n","            movie_conversations.append(line)\n","                                       \n","\n","    return movie_lines,movie_conversations"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-txSMOjQfEnx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":173},"outputId":"2651d951-f118-4229-bc2b-9ea3ed2d2abb","executionInfo":{"status":"ok","timestamp":1586266402105,"user_tz":-330,"elapsed":990,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["t1=time.time()\n","print(\"Extracting movie lines and movie conversations...\")\n","movie_lines,movie_conversations=get_lines_conversations()\n","\n","print(\"Number of distinct lines: \"+str(len(movie_lines)))\n","print(\"Number of conversations: \"+str(len(movie_conversations)))\n","print(\"Average Number of lines per conversations: \"+str(len(movie_lines)/len(movie_conversations)))\n","\n","print(movie_lines[0])\n","print(movie_conversations[0])\n","\n","print(\"Extracting took place in: \"+str(time.time()-t1))"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Extracting movie lines and movie conversations...\n","Number of distinct lines: 304713\n","Number of conversations: 83097\n","Average Number of lines per conversations: 3.6669554857576085\n","L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n","\n","u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n","\n","Extracting took place in: 0.32279515266418457\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3LXCFv_qfMsN","colab_type":"code","colab":{}},"source":["exceptions=[]\n","def loadLines(movie_lines,fields):\n","    lines={}\n","    for lineid in range(len(movie_lines)):\n","        \n","        line=movie_lines[lineid]\n","        values=line.split(\" +++$+++ \")\n","        \n","        \n","        lineVals={}\n","        \n","        # print(\"values\"+str(len(values)))\n","        # print(\"fields\"+str(len(fields)))\n","              \n","        for i,field in enumerate(fields):\n","            try:\n","                lineVals[field]=values[i]\n","            except:\n","                print(\"Exception: \"+str(len(values)))\n","                exceptions.append(lineid)\n","        \n","        lines[lineVals['lineID']]=lineVals\n","    \n","    return lines\n","\n","def loadConversations(movie_conversations,lines,fields):\n","    conversations=[]\n","    \n","    for convo in movie_conversations:\n","        values=convo.split(\" +++$+++ \")\n","        conVals={}\n","       \n","        for i,field in enumerate(fields):\n","            conVals[field]=values[i]\n","        \n","        lineIDs=eval(conVals[\"utteranceIDs\"])\n","        \n","        conVals[\"lines\"]=[]\n","        \n","        for lineID in lineIDs:\n","            conVals[\"lines\"].append(lines[lineID])\n","        conversations.append(conVals)\n","        \n","    return conversations\n","\n","def sentencePairs(conversations):\n","    qr_pairs=[]\n","    \n","    for conversation in conversations:\n","        for i in range(len(conversation[\"lines\"])-1):\n","            query=conversation[\"lines\"][i][\"text\"].strip()\n","            response=conversation[\"lines\"][i+1][\"text\"].strip()\n","            \n","            if query and response:\n","                qr_pairs.append([query,response])\n","        \n","    return qr_pairs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"J2dngu2Xyvzt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"c1826d62-4eaa-4144-c006-030060bf1874","executionInfo":{"status":"ok","timestamp":1586266413238,"user_tz":-330,"elapsed":3752,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["t1=time.time()\n","print(\"Separating meaningfull information for our model...\")\n","\n","lines={}\n","conversations=[]\n","qr_pairs=[]\n","\n","movie_lines_fields=[\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"]\n","movie_convo_fields=[\"charcaterID\",\"character2ID\",\"movieID\",\"utteranceIDs\"]\n","\n","lines=loadLines(movie_lines,movie_lines_fields)\n","conversations=loadConversations(movie_conversations,lines,movie_convo_fields)\n","qr_pairs=sentencePairs(conversations)\n","\n","print(\"The number of query-response pairs are: \"+str(len(qr_pairs)))\n","print(\"Separation took place in: \"+str(time.time()-t1))"],"execution_count":27,"outputs":[{"output_type":"stream","text":["Separating meaningfull information for our model...\n","The number of query-response pairs are: 221282\n","Separation took place in: 2.552631139755249\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NFMCnpuO2jpr","colab_type":"code","colab":{}},"source":["PAD_Token=0\n","START_Token=1\n","END_Token=2\n","\n","class Vocabulary:\n","    def __init__(self):\n","        self.trimmed=False\n","        self.word2count={}\n","        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n","        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n","        self.num_words=3\n","        \n","    def addSentence(self,sentence):\n","        for word in sentence.split(\" \"):\n","            self.addWord(word)\n","    def addWord(self,word):\n","        if word not in self.word2index:\n","            self.word2index[word]=self.num_words\n","            self.index2word[self.num_words]=word\n","            self.word2count[word]=1\n","            self.num_words=self.num_words+1\n","        else:\n","            self.word2count[word]+=1\n","            \n","    def trim(self,min_count):\n","        \n","        if self.trimmed:\n","            return\n","        self.trimmed=True\n","        \n","        keep_words=[]\n","        \n","        for word,freq in self.word2count.items():\n","            if freq>=min_count:\n","                keep_words.append(word)\n","        \n","        self.word2count={}\n","        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n","        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n","        self.num_words=3\n","        \n","        for word in keep_words:\n","            self.addWord(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"GeScbB7iy0AC","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"81ed78c2-4267-476b-dab0-9e43e5c933ec","executionInfo":{"status":"ok","timestamp":1586266538134,"user_tz":-330,"elapsed":12117,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["Max_Length=10\n","\n","def normalizeString(s):\n","    s=s.lower().strip()\n","    s=re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s=re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    s=re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","\n","def readVocs(qr_pairs):\n","    \n","    for qr_pair in qr_pairs:\n","        qr_pair[0]=normalizeString(qr_pair[0])\n","        qr_pair[1]=normalizeString(qr_pair[1])\n","    \n","    voc=Vocabulary()\n","    return voc,qr_pairs\n","\n","def filterPair(pair):\n","    return len(pair[0].split(\" \"))<Max_Length and len(pair[1].split(\" \"))<Max_Length\n","\n","def filterPairs(qr_pairs):\n","    return [pair for pair in qr_pairs if filterPair(pair)]\n","\n","def prepareDataset(qr_pairs):\n","    voc, qr_pairs=readVocs(qr_pairs)\n","    qr_pairs=filterPairs(qr_pairs)\n","       \n","    for pair in qr_pairs:\n","        voc.addSentence(pair[0])\n","        voc.addSentence(pair[1])\n","#     print(\"Number\"+str(voc.num_words))\n","    return voc,qr_pairs\n","\n","t1=time.time()\n","print(\"Preparing dataset and corresponding vocabulary...\")\n","voc, pairs=prepareDataset(qr_pairs)\n","print(\"Preparation took place in: \"+str(time.time()-t1))"],"execution_count":30,"outputs":[{"output_type":"stream","text":["Preparing dataset and corresponding vocabulary...\n","Preparation took place in: 11.142396211624146\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UUBpnFjQ2SCS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"b7a66784-497b-451f-9aa2-c98514527b35","executionInfo":{"status":"ok","timestamp":1586266557151,"user_tz":-330,"elapsed":885,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["Min_Count=3\n","\n","def trimRareWords(voc,qr_pairs):\n","    \n","    voc.trim(Min_Count)\n","    keep_pairs=[]\n","    \n","    for pair in qr_pairs:\n","        input_sentence=pair[0]\n","        output_sentence=pair[1]\n","        \n","        keep_input=True\n","        keep_output=True\n","        \n","        for word in input_sentence.split(\" \"):\n","            if word not in voc.word2index:\n","                keep_input=False\n","                break\n","        \n","        for word in output_sentence.split(\" \"):\n","            if word not in voc.word2index:\n","                keep_output=False\n","                break\n","                \n","        if keep_input and keep_output:\n","            keep_pairs.append(pair)\n","            \n","    return keep_pairs\n","\n","t1=time.time()\n","print(\"Trimming rare words from vocabulary and dataset..\")\n","\n","pairs=trimRareWords(voc,pairs)\n","\n","print(\"Trimming took place in: \"+str(time.time()-t1))"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Trimming rare words from vocabulary and dataset..\n","Trimming took place in: 0.14473986625671387\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VjOEe2nx2sbZ","colab_type":"code","colab":{}},"source":["def indexesFromSentence(voc,sentence):\n","    tokenised_sentence=[]\n","    tokenised_sentence.append(START_Token)\n","    \n","    for word in sentence.split(\" \"):\n","        tokenised_sentence.append(voc.word2index[word])\n","        \n","    tokenised_sentence.append(END_Token)\n","    \n","    assert len(tokenised_sentence)<=Max_Length+2\n","    for _ in range(Max_Length+2-len(tokenised_sentence)):\n","        tokenised_sentence.append(PAD_Token)\n","        \n","    return tokenised_sentence\n","\n","def binaryMatrix(l,value=PAD_Token):\n","    m=[]\n","    for i,seq in enumerate(l):\n","        m.append([])\n","        for token in seq:\n","            if token==value:\n","                m[i].append(0)\n","            else:\n","                m[i].append(1)\n","        \n","    return m\n","\n","def inputVar(voc,l):\n","    \n","    indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n","    input_lengths=torch.tensor([len(index) for index in indexes_batch])\n","    padVar=torch.LongTensor(indexes_batch)\n","    return input_lengths,padVar\n","\n","def outputVar(voc,l):\n","    indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n","    max_target_len=torch.tensor([len(index) for index in indexes_batch])\n","    mask=binaryMatrix(indexes_batch)\n","    mask=torch.ByteTensor(mask)\n","    padVar=torch.LongTensor(indexes_batch)\n","    return max_target_len, mask, padVar\n","\n","def batch2TrainData(voc,pair_batch):\n","    #sort function see \n","    input_batch=[]\n","    output_batch=[]\n","\n","    for pair in pair_batch:\n","        input_batch.append(pair[0])\n","        output_batch.append(pair[1])\n","                                  \n","    \n","    input_lengths,tokenised_input=inputVar(voc,input_batch)\n","    max_out_length,mask,tokenised_output=outputVar(voc,output_batch)\n","    return input_lengths,tokenised_input,max_out_length,mask,tokenised_output"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-wd2hB-2y4b","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":416},"outputId":"26957c45-a730-4fa8-fe06-a113f163bf58","executionInfo":{"status":"ok","timestamp":1586266598910,"user_tz":-330,"elapsed":879,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["print(\"Number of query-response pairs after all the preprocessing: \"+str(len(pairs)))\n","\n","#Sample batch\n","batch=[random.choice(pairs) for _ in range(5)]\n","input_lengths,tokenised_input,max_out_length,mask,tokenised_output=batch2TrainData(voc,batch)\n","\n","print(\"Input length: \"+str(input_lengths)+\" Size: \"+str(input_lengths.shape))\n","print(\"-\"*80)\n","print(\"Tokenised Input: \"+str(tokenised_input)+\" Size: \"+str(tokenised_input.shape))\n","print(\"-\"*80)\n","print(\"Max out length: \"+str(max_out_length)+\" Size: \"+str(max_out_length.shape))\n","print(\"-\"*80)\n","print(\"Mask: \"+str(mask)+\" Size: \"+str(mask.shape))\n","print(\"-\"*80)\n","print(\"Tokenised Output: \"+str(tokenised_output)+\" Size: \"+str(tokenised_output.shape))\n","print(\"-\"*80)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["Number of query-response pairs after all the preprocessing: 53113\n","Input length: tensor([12, 12, 12, 12, 12]) Size: torch.Size([5])\n","--------------------------------------------------------------------------------\n","Tokenised Input: tensor([[   1,   25,  200,  483,    4,    2,    0,    0,    0,    0,    0,    0],\n","        [   1,   67,  266,   95,    4,    2,    0,    0,    0,    0,    0,    0],\n","        [   1,   25,  247,  117,  236,    7,    4,    2,    0,    0,    0,    0],\n","        [   1,   77,  115,   45,    6,    2,    0,    0,    0,    0,    0,    0],\n","        [   1, 1769,    6,    2,    0,    0,    0,    0,    0,    0,    0,    0]]) Size: torch.Size([5, 12])\n","--------------------------------------------------------------------------------\n","Max out length: tensor([12, 12, 12, 12, 12]) Size: torch.Size([5])\n","--------------------------------------------------------------------------------\n","Mask: tensor([[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n","        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8) Size: torch.Size([5, 12])\n","--------------------------------------------------------------------------------\n","Tokenised Output: tensor([[  1,  83, 349,   4,   2,   0,   0,   0,   0,   0,   0,   0],\n","        [  1,  67, 266,  95,   6,  62, 219,   6,   2,   0,   0,   0],\n","        [  1,  33,  36,  37,  50,  25, 215,   4,   2,   0,   0,   0],\n","        [  1,  83, 122,   9, 997,   4,   2,   0,   0,   0,   0,   0],\n","        [  1,   7, 809,   4,   2,   0,   0,   0,   0,   0,   0,   0]]) Size: torch.Size([5, 12])\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DpR-1oMt3HA4","colab_type":"text"},"source":["# Model 1"]},{"cell_type":"code","metadata":{"id":"RJnnpKgt3Nyg","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}