{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"seq2seq_withattn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNhdd3AvFQ9Y1ETbrnrZbFt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"3JqhjAnVSaCY","colab_type":"code","outputId":"9c09a507-586f-451c-bda7-15f7620930b8","executionInfo":{"status":"ok","timestamp":1586965633545,"user_tz":-330,"elapsed":1892,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":116,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8LceekfUUWxL","colab_type":"code","outputId":"f030234e-e2c8-45de-eac5-1ce4f304d44b","executionInfo":{"status":"ok","timestamp":1586965640917,"user_tz":-330,"elapsed":6320,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["!nvidia-smi \n"],"execution_count":117,"outputs":[{"output_type":"stream","text":["Wed Apr 15 15:47:17 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|===============================+======================+======================|\n","|   0  Tesla P4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   69C    P0    26W /  75W |   2325MiB /  7611MiB |      0%      Default |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                       GPU Memory |\n","|  GPU       PID   Type   Process name                             Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CRbeP6r1VmTD","colab_type":"code","colab":{}},"source":["#Pre-Processing\n","import os\n","import re\n","import torch\n","import random\n","import itertools\n","\n","#Model\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.autograd import Variable\n","\n","import numpy as np\n","\n","# For visualising metrics\n","# from visdom import Visdom\n","\n","# For visualising gradients plot\n","import matplotlib.pyplot as plt\n","from matplotlib.lines import Line2D\n","\n","import copy\n","import math\n","import time"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5i5yWtmBH7LU","colab_type":"code","outputId":"61f0f2d0-d14a-492a-c9d6-5f103b1d6c65","executionInfo":{"status":"ok","timestamp":1586965645359,"user_tz":-330,"elapsed":2393,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","# device=torch.device(\"cpu\")\n","print(\"The device found: \"+str(device))"],"execution_count":119,"outputs":[{"output_type":"stream","text":["The device found: cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9D390QjbICa9","colab_type":"code","colab":{}},"source":["def plot_grad_flow(named_parameters):\n","    \"\"\"\n","        Plotting gradient flow across various layers\n","        Thanks to: https://discuss.pytorch.org/t/check-gradient-flow-in-network/15063/2\n","    \"\"\"   \n","    ave_grads = []\n","    layers = []\n","    for n, p in named_parameters:\n","        if(p.requires_grad) and (\"bias\" not in n):\n","            layers.append(n)\n","            ave_grads.append(p.grad.abs().mean())\n","    plt.plot(ave_grads, alpha=0.3, color=\"b\")\n","    plt.hlines(0, 0, len(ave_grads)+1, linewidth=1, color=\"k\" )\n","    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n","    plt.xlim(xmin=0, xmax=len(ave_grads))\n","    plt.xlabel(\"Layers\")\n","    plt.ylabel(\"average gradient\")\n","    plt.title(\"Gradient flow\")\n","    plt.grid(True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z565czS1IFdU","colab_type":"text"},"source":["# Preprocessing\n"]},{"cell_type":"code","metadata":{"id":"c9AkyMgfWetG","colab_type":"code","outputId":"70972a97-80c6-4ee8-d018-e7f044561d01","executionInfo":{"status":"ok","timestamp":1586965645361,"user_tz":-330,"elapsed":1220,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["path='/content/drive/My Drive/Data'\n","dataset='cornell movie-dialogs corpus'\n","\n","data_folder=os.path.join(path,dataset)\n","\n","print(\"The final data corpus folder: \"+str(data_folder))"],"execution_count":121,"outputs":[{"output_type":"stream","text":["The final data corpus folder: /content/drive/My Drive/Data/cornell movie-dialogs corpus\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sNFBnhpYWhB4","colab_type":"code","colab":{}},"source":["def get_lines_conversations():\n","    \"\"\"\n","    Loads movie lines and conversations from the dataset.\n","    \n","    data_folder: Destination where conversations and lines are stored.\n","    \n","    movie_lines: Consist of movie lines as given by the dataset.\n","    movie_conversations: Consist of movie conversations as given by the dataset.\n","    \n","    \"\"\"\n","    movie_lines=[]\n","    movie_conversations=[]\n","\n","    with open(os.path.join(data_folder,'movie_lines.txt'),'r',encoding='iso-8859-1') as f:\n","        for line in f:\n","            movie_lines.append(line)\n","    \n","    with open(os.path.join(data_folder,'movie_conversations.txt'),'r', encoding='iso-8859-1') as f:\n","        for line in f:\n","            movie_conversations.append(line)\n","                                       \n","\n","    return movie_lines,movie_conversations"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_j92fLQrW1pq","colab_type":"code","outputId":"ea6575ff-6bc8-4d81-af86-433c69f56ebb","executionInfo":{"status":"ok","timestamp":1586965647005,"user_tz":-330,"elapsed":1884,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["t1=time.time()\n","print(\"Extracting movie lines and movie conversations...\")\n","movie_lines,movie_conversations=get_lines_conversations()\n","\n","print(\"Number of distinct lines: \"+str(len(movie_lines)))\n","print(\"Number of conversations: \"+str(len(movie_conversations)))\n","print(\"Average Number of lines per conversations: \"+str(len(movie_lines)/len(movie_conversations)))\n","\n","print(movie_lines[0])\n","print(movie_conversations[0])\n","\n","print(\"Extracting took place in: \"+str(time.time()-t1))"],"execution_count":123,"outputs":[{"output_type":"stream","text":["Extracting movie lines and movie conversations...\n","Number of distinct lines: 304713\n","Number of conversations: 83097\n","Average Number of lines per conversations: 3.6669554857576085\n","L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\n","\n","u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\n","\n","Extracting took place in: 0.17156624794006348\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eG0A5czeXz9H","colab_type":"code","colab":{}},"source":["exceptions=[]\n","def loadLines(movie_lines,fields):\n","    lines={}\n","    for lineid in range(len(movie_lines)):\n","        \n","        line=movie_lines[lineid]\n","        values=line.split(\" +++$+++ \")\n","        \n","        \n","        lineVals={}\n","        \n","        # print(\"values\"+str(len(values)))\n","        # print(\"fields\"+str(len(fields)))\n","              \n","        for i,field in enumerate(fields):\n","            try:\n","                lineVals[field]=values[i]\n","            except:\n","                print(\"Exception: \"+str(len(values)))\n","                exceptions.append(lineid)\n","        \n","        lines[lineVals['lineID']]=lineVals\n","    \n","    return lines\n","\n","def loadConversations(movie_conversations,lines,fields):\n","    conversations=[]\n","    \n","    for convo in movie_conversations:\n","        values=convo.split(\" +++$+++ \")\n","        conVals={}\n","       \n","        for i,field in enumerate(fields):\n","            conVals[field]=values[i]\n","        \n","        lineIDs=eval(conVals[\"utteranceIDs\"])\n","        \n","        conVals[\"lines\"]=[]\n","        \n","        for lineID in lineIDs:\n","            conVals[\"lines\"].append(lines[lineID])\n","        conversations.append(conVals)\n","        \n","    return conversations\n","\n","def sentencePairs(conversations):\n","    qr_pairs=[]\n","    \n","    for conversation in conversations:\n","        for i in range(len(conversation[\"lines\"])-1):\n","            query=conversation[\"lines\"][i][\"text\"].strip()\n","            response=conversation[\"lines\"][i+1][\"text\"].strip()\n","            \n","            if query and response:\n","                qr_pairs.append([query,response])\n","        \n","    return qr_pairs"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bh37EXhxYQAJ","colab_type":"code","outputId":"bc1a216f-e93c-4654-c7b7-35821d129e9f","executionInfo":{"status":"ok","timestamp":1586965650869,"user_tz":-330,"elapsed":4005,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["t1=time.time()\n","print(\"Separating meaningfull information for our model...\")\n","\n","lines={}\n","conversations=[]\n","qr_pairs=[]\n","\n","movie_lines_fields=[\"lineID\",\"characterID\",\"movieID\",\"character\",\"text\"]\n","movie_convo_fields=[\"charcaterID\",\"character2ID\",\"movieID\",\"utteranceIDs\"]\n","\n","lines=loadLines(movie_lines,movie_lines_fields)\n","conversations=loadConversations(movie_conversations,lines,movie_convo_fields)\n","qr_pairs=sentencePairs(conversations)\n","\n","print(\"The number of query-response pairs are: \"+str(len(qr_pairs)))\n","print(\"Separation took place in: \"+str(time.time()-t1))"],"execution_count":125,"outputs":[{"output_type":"stream","text":["Separating meaningfull information for our model...\n","The number of query-response pairs are: 221282\n","Separation took place in: 1.8351614475250244\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"p5vYOofuzsaP","colab_type":"code","colab":{}},"source":["PAD_Token=0\n","START_Token=1\n","END_Token=2\n","\n","class Vocabulary:\n","    def __init__(self):\n","        self.trimmed=False\n","        self.word2count={}\n","        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n","        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n","        self.num_words=3\n","        \n","    def addSentence(self,sentence):\n","        for word in sentence.split(\" \"):\n","            self.addWord(word)\n","    def addWord(self,word):\n","        if word not in self.word2index:\n","            self.word2index[word]=self.num_words\n","            self.index2word[self.num_words]=word\n","            self.word2count[word]=1\n","            self.num_words=self.num_words+1\n","        else:\n","            self.word2count[word]+=1\n","            \n","    def trim(self,min_count):\n","        \n","        if self.trimmed:\n","            return\n","        self.trimmed=True\n","        \n","        keep_words=[]\n","        \n","        for word,freq in self.word2count.items():\n","            if freq>=min_count:\n","                keep_words.append(word)\n","        \n","        self.word2count={}\n","        self.index2word={PAD_Token:\"PAD\",START_Token:\"SOS\",END_Token:\"EOS\"}\n","        self.word2index={\"PAD\":PAD_Token,\"SOS\":START_Token,\"EOS\":END_Token}\n","        self.num_words=3\n","        \n","        for word in keep_words:\n","            self.addWord(word)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"MEPrFn1h4sFp","colab_type":"code","outputId":"84a2fc6b-c1f7-4a05-aa1e-4107996f0a2d","executionInfo":{"status":"ok","timestamp":1586965657599,"user_tz":-330,"elapsed":9298,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["Max_Length=10\n","\n","def normalizeString(s):\n","    s=s.lower().strip()\n","    s=re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s=re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    s=re.sub(r\"\\s+\", r\" \", s).strip()\n","    return s\n","\n","def readVocs(qr_pairs):\n","    \n","    for qr_pair in qr_pairs:\n","        qr_pair[0]=normalizeString(qr_pair[0])\n","        qr_pair[1]=normalizeString(qr_pair[1])\n","    \n","    voc=Vocabulary()\n","    return voc,qr_pairs\n","\n","def filterPair(pair):\n","    return len(pair[0].split(\" \"))<Max_Length and len(pair[1].split(\" \"))<Max_Length\n","\n","def filterPairs(qr_pairs):\n","    return [pair for pair in qr_pairs if filterPair(pair)]\n","\n","def prepareDataset(qr_pairs):\n","    voc, qr_pairs=readVocs(qr_pairs)\n","    qr_pairs=filterPairs(qr_pairs)\n","       \n","    for pair in qr_pairs:\n","        voc.addSentence(pair[0])\n","        voc.addSentence(pair[1])\n","#     print(\"Number\"+str(voc.num_words))\n","    return voc,qr_pairs\n","\n","t1=time.time()\n","print(\"Preparing dataset and corresponding vocabulary...\")\n","voc, pairs=prepareDataset(qr_pairs)\n","print(\"Preparation took place in: \"+str(time.time()-t1))"],"execution_count":127,"outputs":[{"output_type":"stream","text":["Preparing dataset and corresponding vocabulary...\n","Preparation took place in: 6.100830078125\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"wv1ruAcB4wxK","colab_type":"code","outputId":"acc5310a-6031-4080-b893-c652b110d1b3","executionInfo":{"status":"ok","timestamp":1586965657601,"user_tz":-330,"elapsed":8651,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["Min_Count=3\n","\n","def trimRareWords(voc,qr_pairs):\n","    \n","    voc.trim(Min_Count)\n","    keep_pairs=[]\n","    \n","    for pair in qr_pairs:\n","        input_sentence=pair[0]\n","        output_sentence=pair[1]\n","        \n","        keep_input=True\n","        keep_output=True\n","        \n","        for word in input_sentence.split(\" \"):\n","            if word not in voc.word2index:\n","                keep_input=False\n","                break\n","        \n","        for word in output_sentence.split(\" \"):\n","            if word not in voc.word2index:\n","                keep_output=False\n","                break\n","                \n","        if keep_input and keep_output:\n","            keep_pairs.append(pair)\n","            \n","    return keep_pairs\n","\n","t1=time.time()\n","print(\"Trimming rare words from vocabulary and dataset..\")\n","\n","pairs=trimRareWords(voc,pairs)\n","\n","print(\"Trimming took place in: \"+str(time.time()-t1))"],"execution_count":128,"outputs":[{"output_type":"stream","text":["Trimming rare words from vocabulary and dataset..\n","Trimming took place in: 0.12550735473632812\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YVoU5avw4zay","colab_type":"code","colab":{}},"source":["# def indexesFromSentence(voc,sentence):\n","#     tokenised_sentence=[]\n","#     tokenised_sentence.append(START_Token)\n","    \n","#     for word in sentence.split(\" \"):\n","#         tokenised_sentence.append(voc.word2index[word])\n","        \n","#     tokenised_sentence.append(END_Token)\n","    \n","#     assert len(tokenised_sentence)<=Max_Length+2\n","#     for _ in range(Max_Length+2-len(tokenised_sentence)):\n","#         tokenised_sentence.append(PAD_Token)\n","        \n","#     return tokenised_sentence\n","\n","# def binaryMatrix(l,value=PAD_Token):\n","#     m=[]\n","#     for i,seq in enumerate(l):\n","#         m.append([])\n","#         for token in seq:\n","#             if token==value:\n","#                 m[i].append(0)\n","#             else:\n","#                 m[i].append(1)\n","        \n","#     return m\n","\n","# def inputVar(voc,l):\n","    \n","#     indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n","#     input_lengths=torch.tensor([len(index) for index in indexes_batch])\n","#     padVar=torch.LongTensor(indexes_batch)\n","#     return input_lengths,padVar\n","\n","# def outputVar(voc,l):\n","#     indexes_batch=[indexesFromSentence(voc,sentence) for sentence in l]\n","#     max_target_len=torch.tensor([len(index) for index in indexes_batch])\n","#     mask=binaryMatrix(indexes_batch)\n","#     mask=torch.ByteTensor(mask)\n","#     padVar=torch.LongTensor(indexes_batch)\n","#     return max_target_len, mask, padVar\n","\n","# def batch2TrainData(voc,pair_batch):\n","#     #sort function see \n","#     input_batch=[]\n","#     output_batch=[]\n","\n","#     for pair in pair_batch:\n","#         input_batch.append(pair[0])\n","#         output_batch.append(pair[1])\n","                                  \n","    \n","#     input_lengths,tokenised_input=inputVar(voc,input_batch)\n","#     max_out_length,mask,tokenised_output=outputVar(voc,output_batch)\n","#     return input_lengths,tokenised_input,max_out_length,mask,tokenised_output\n","\n","def indexesFromSentence(voc, sentence):\n","    return [voc.word2index[word] for word in sentence.split(' ')] + [END_Token]\n","\n","\n","def zeroPadding(l, fillvalue=PAD_Token):\n","    return list(itertools.zip_longest(*l, fillvalue=fillvalue))\n","\n","def binaryMatrix(l, value=PAD_Token):\n","    m = []\n","    for i, seq in enumerate(l):\n","        m.append([])\n","        for token in seq:\n","            if token == PAD_Token:\n","                m[i].append(0)\n","            else:\n","                m[i].append(1)\n","    return m\n","\n","# Returns padded input sequence tensor and lengths\n","def inputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, lengths\n","\n","# Returns padded target sequence tensor, padding mask, and max target length\n","def outputVar(l, voc):\n","    indexes_batch = [indexesFromSentence(voc, sentence) for sentence in l]\n","    max_target_len = max([len(indexes) for indexes in indexes_batch])\n","    padList = zeroPadding(indexes_batch)\n","    mask = binaryMatrix(padList)\n","    mask = torch.BoolTensor(mask)\n","    padVar = torch.LongTensor(padList)\n","    return padVar, mask, max_target_len\n","\n","# Returns all items for a given batch of pairs\n","def batch2TrainData(voc, pair_batch):\n","    pair_batch.sort(key=lambda x: len(x[0].split(\" \")), reverse=True)\n","    input_batch, output_batch = [], []\n","    for pair in pair_batch:\n","        input_batch.append(pair[0])\n","        output_batch.append(pair[1])\n","    inp, lengths = inputVar(input_batch, voc)\n","    output, mask, max_target_len = outputVar(output_batch, voc)\n","    return inp, lengths, output, mask, max_target_len\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"d8-18tBuMZMx","colab_type":"code","outputId":"de7e9fae-19fc-41a7-83c9-a66315eb56b3","executionInfo":{"status":"ok","timestamp":1586965657603,"user_tz":-330,"elapsed":7480,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":537}},"source":["print(\"Number of query-response pairs after all the preprocessing: \"+str(len(pairs)))\n","\n","#Sample batch\n","batch=[random.choice(pairs) for _ in range(5)]\n","tokenised_input,input_lengths,tokenised_output,mask,max_out_length=batch2TrainData(voc,batch)\n","\n","print(\"Input length: \"+str(input_lengths)+\" Size: \"+str(input_lengths.shape))\n","print(\"-\"*80)\n","print(\"Tokenised Input: \"+str(tokenised_input)+\" Size: \"+str(tokenised_input.shape))\n","print(\"-\"*80)\n","print(\"Max out length: \"+str(max_out_length)+\" Size: \")\n","print(\"-\"*80)\n","print(\"Mask: \"+str(mask)+\" Size: \"+str(mask.shape))\n","print(\"-\"*80)\n","print(\"Tokenised Output: \"+str(tokenised_output)+\" Size: \"+str(tokenised_output.shape))\n","print(\"-\"*80)"],"execution_count":130,"outputs":[{"output_type":"stream","text":["Number of query-response pairs after all the preprocessing: 53113\n","Input length: tensor([6, 5, 3, 3, 3]) Size: torch.Size([5])\n","--------------------------------------------------------------------------------\n","Tokenised Input: tensor([[ 50,  77, 124, 167,  16],\n","        [ 47, 115,   4,   4,   4],\n","        [  7,  45,   2,   2,   2],\n","        [118,   6,   0,   0,   0],\n","        [  6,   2,   0,   0,   0],\n","        [  2,   0,   0,   0,   0]]) Size: torch.Size([6, 5])\n","--------------------------------------------------------------------------------\n","Max out length: 8 Size: \n","--------------------------------------------------------------------------------\n","Mask: tensor([[ True,  True,  True,  True,  True],\n","        [ True,  True,  True,  True,  True],\n","        [ True,  True,  True,  True,  True],\n","        [False,  True,  True,  True,  True],\n","        [False,  True,  True, False,  True],\n","        [False, False,  True, False,  True],\n","        [False, False,  True, False,  True],\n","        [False, False,  True, False, False]]) Size: torch.Size([8, 5])\n","--------------------------------------------------------------------------------\n","Tokenised Output: tensor([[2704,   77,   50,   15,  124],\n","        [   4,  115,   37,  562,    4],\n","        [   2,   45,  774,    4,    4],\n","        [   0,    6,  169,    2,    4],\n","        [   0,    2,   53,    0,   16],\n","        [   0,    0,  789,    0,    4],\n","        [   0,    0,    6,    0,    2],\n","        [   0,    0,    2,    0,    0]]) Size: torch.Size([8, 5])\n","--------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Oppo7HKtKMxW","colab_type":"text"},"source":["# Model"]},{"cell_type":"code","metadata":{"id":"ra7_TfQv42Ra","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","    \n","    def __init__(self,hidden_size,embedding,n_layers=1,dropout=0):\n","        \"\"\"\n","        Encoder module for seq2seq architechture.\n","        \"\"\"\n","    \n","        super().__init__()\n","        \n","        self.n_layers=n_layers\n","        self.hidden_size=hidden_size\n","        \n","        self.embedding=embedding\n","        self.gru=nn.GRU(hidden_size,hidden_size,n_layers,dropout=(0 if n_layers==1 else dropout),bidirectional=True)\n","        \n","    def forward(self,input_seq,input_lengths,hidden=None):\n","        \n","        embedded_input=self.embedding(input_seq)\n","        packed=nn.utils.rnn.pack_padded_sequence(embedded_input,input_lengths)\n","        outputs,hidden=self.gru(packed,hidden)\n","        \n","        outputs,_=nn.utils.rnn.pad_packed_sequence(outputs)\n","        \n","        outputs = outputs[:, :, :self.hidden_size] + outputs[:, : ,self.hidden_size:]\n","        \n","        return outputs,hidden\n","\n","    def hidden_init(self,batch_size):\n","        return torch.zeros(self.n_layers*2,batch_size,self.hidden_size,device=device)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2ZsVL85g49Er","colab_type":"code","colab":{}},"source":["# Luong attention layer\n","class Attn(torch.nn.Module):\n","    def __init__(self, method, hidden_size):\n","        super(Attn, self).__init__()\n","        self.method = method\n","        if self.method not in ['dot', 'general', 'concat']:\n","            raise ValueError(self.method, \"is not an appropriate attention method.\")\n","        self.hidden_size = hidden_size\n","        if self.method == 'general':\n","            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n","        elif self.method == 'concat':\n","            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n","            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n","\n","    def dot_score(self, hidden, encoder_output):\n","        return torch.sum(hidden * encoder_output, dim=2)\n","\n","    def general_score(self, hidden, encoder_output):\n","        energy = self.attn(encoder_output)\n","        return torch.sum(hidden * energy, dim=2)\n","\n","    def concat_score(self, hidden, encoder_output):\n","        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n","        return torch.sum(self.v * energy, dim=2)\n","\n","    def forward(self, hidden, encoder_outputs):\n","        # Calculate the attention weights (energies) based on the given method\n","        if self.method == 'general':\n","            attn_energies = self.general_score(hidden, encoder_outputs)\n","        elif self.method == 'concat':\n","            attn_energies = self.concat_score(hidden, encoder_outputs)\n","        elif self.method == 'dot':\n","            attn_energies = self.dot_score(hidden, encoder_outputs)\n","\n","        # Transpose max_length and batch_size dimensions\n","        attn_energies = attn_energies.t()\n","\n","        # Return the softmax normalized probability scores (with added dimension)\n","        return F.softmax(attn_energies, dim=1).unsqueeze(1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S6Vv95PR5TBu","colab_type":"code","colab":{}},"source":["class LuongAttnDecoderRNN(nn.Module):\n","    def __init__(self, attn_model, embedding, hidden_size, output_size, n_layers=1, dropout=0.1):\n","        super(LuongAttnDecoderRNN, self).__init__()\n","\n","        # Keep for reference\n","        self.attn_model = attn_model\n","        self.hidden_size = hidden_size\n","        self.output_size = output_size\n","        self.n_layers = n_layers\n","        self.dropout = dropout\n","\n","        # Define layers\n","        self.embedding = embedding\n","        self.embedding_dropout = nn.Dropout(dropout)\n","        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout=(0 if n_layers == 1 else dropout))\n","        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n","        self.out = nn.Linear(hidden_size, output_size)\n","\n","        self.attn = Attn(attn_model, hidden_size)\n","\n","    def forward(self, input_step, last_hidden, encoder_outputs):\n","        # Note: we run this one step (word) at a time\n","        # Get embedding of current input word\n","        embedded = self.embedding(input_step)\n","        embedded = self.embedding_dropout(embedded)\n","        # Forward through unidirectional GRU\n","        \n","        rnn_output, hidden = self.gru(embedded, last_hidden)\n","        \n","        # Calculate attention weights from the current GRU output\n","        attn_weights = self.attn(rnn_output, encoder_outputs)\n","        # Multiply attention weights to encoder outputs to get new \"weighted sum\" context vector\n","        context = attn_weights.bmm(encoder_outputs.transpose(0, 1))\n","        # Concatenate weighted context vector and GRU output using Luong eq. 5\n","        rnn_output = rnn_output.squeeze(0)\n","        context = context.squeeze(1)\n","        concat_input = torch.cat((rnn_output, context), 1)\n","        concat_output = torch.tanh(self.concat(concat_input))\n","        # Predict next word using Luong eq. 6\n","        output = self.out(concat_output)\n","        output = F.softmax(output, dim=1)\n","        # Return output and final hidden state\n","        return output, hidden"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bqc_v6v09aN3","colab_type":"code","colab":{}},"source":["def make_model(vocabulary_size,d_model=500,num_encoders=1,num_decoders=1,dropout_encoder=0.1,dropout_decoder=0.1,attn_model='general'):\n","\n","    embedding=nn.Embedding(vocabulary_size,d_model)\n","    embedding.weight.requires_grad=False\n","\n","    encoder=EncoderRNN(d_model,embedding,num_encoders,dropout_encoder)\n","    decoder=LuongAttnDecoderRNN(attn_model,embedding,d_model,vocabulary_size,num_decoders,dropout_decoder)\n","\n","    for p in encoder.parameters():\n","        if p.dim()>1:\n","            nn.init.xavier_uniform_(p)\n","    \n","    for p in decoder.parameters():\n","        if p.dim()>1:\n","            nn.init.xavier_uniform_(p)\n","\n","    return encoder,decoder\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nxlGp-uOKbLD","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"RIMnSo1Q5WKP","colab_type":"code","colab":{}},"source":["def maskNLLLoss(inp, target, mask):\n","    nTotal = mask.sum()\n","    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n","    loss = crossEntropy.masked_select(mask).mean()\n","    loss = loss.to(device)\n","    return loss, nTotal.item()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1xk1Eu8y5cYn","colab_type":"code","colab":{}},"source":["\n","MAX_LENGTH=10\n","def train(input_variable,lengths,target_variable,mask,max_target_len,encoder,decoder,\n","          encoder_optimizer,decoder_optimizer,batch_size,clip,max_length=MAX_LENGTH):\n","    \n","    encoder_optimizer.zero_grad()\n","    decoder_optimizer.zero_grad()\n","    \n","    input_variable=torch.tensor(input_variable).to(device)\n","    lengths=lengths.to(device)\n","\n","    target_variable=torch.tensor(target_variable).to(device)\n","    mask=mask.to(device)\n","    \n","    loss=0\n","    print_losses=[]\n","    n_totals=0\n","    encoder_hidden=encoder.hidden_init(input_variable.size()[1])\n","    encoder_outputs, encoder_hidden=encoder(input_variable,lengths,encoder_hidden)\n","    \n","    decoder_input=torch.LongTensor([[START_Token for _ in range(batch_size)]])\n","    decoder_input=decoder_input.to(device)\n","    use_teacher_forcing=True #if random.random()<teacher_forcing_ratio else False\n","    \n","    decoder_hidden=encoder_hidden[:decoder.n_layers]\n","    \n","    if use_teacher_forcing:\n","        \n","        for t in range(max_target_len):\n","            decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n","            \n","            decoder_input=target_variable[t].view(1,-1)\n","            \n","            mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n","            loss+=mask_loss\n","            print_losses.append(mask_loss.item()*nTotal)\n","            n_totals+=nTotal\n","            \n","\n","            \n","    else:\n","        \n","        for t in range(max_target_len):\n","            decoder_output,decoder_hidden=decoder(decoder_input,decoder_hidden,encoder_outputs)\n","            \n","            _,topi=decoder_output.topk(1)\n","            decoder_input=torch.LongTensor([[topi[i][0] for i in range(batch_size)]])\n","            decoder_input=decoder_input.to(device)\n","            \n","            mask_loss,nTotal=maskNLLLoss(decoder_output,target_variable[t],mask[t])\n","            loss+=mask_loss\n","            print_losses.append(mask_loss.item()*nTotal)\n","            n_totals+=nTotal\n","            \n","    \n","    loss.backward()\n","    \n","    _=nn.utils.clip_grad_norm_(encoder.parameters(),clip)\n","    _=nn.utils.clip_grad_norm_(decoder.parameters(),clip)\n","    \n","    \n","    # plot_grad_flow(encoder.named_parameters())\n","    # plot_grad_flow(decoder.named_parameters())\n","    \n","    encoder_optimizer.step()\n","    decoder_optimizer.step()\n","    \n","    return sum(print_losses)/n_totals\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"6-GQ9XmH5fLl","colab_type":"code","colab":{}},"source":["def trainIters(model_name,voc,pairs,encoder,decoder,encoder_optimizer,decoder_optimizer,\n","               encoder_n_layers,decoder_n_layers,save_dir,n_batches,batch_size,\n","               save_every,clip,corpus_name,loadFileName,n_epochs):\n","    \n","    training_batches=[batch2TrainData(voc,[random.choice(pairs) for _ in range(batch_size)]) for _ in range(n_batches)]\n","    \n","    start_epoch=0\n","    loss=0\n","    perplexity=0\n","    time_taken=0\n","    \n","    if loadFileName:\n","        start_epoch=checkpoint['epoch']+1\n","        time_taken=checkpoint['time']\n","        \n","        \n","    for epoch in range(start_epoch,n_epochs):\n","\n","        t1=time.time()\n","\n","        for i in range(n_batches):\n","            \n","            training_batch=training_batches[i]\n","            \n","            input_variable,lengths,target_variable,mask,max_target_len=training_batch\n","\n","            curr_loss=train(input_variable,lengths,target_variable,mask,max_target_len,encoder,decoder,\n","                    encoder_optimizer,decoder_optimizer,batch_size,clip)\n","            \n","            loss+=curr_loss\n","            perplexity+=math.exp(curr_loss)\n","            \n","        \n","        \n","        loss=loss/n_batches\n","        perplexity=perplexity/n_batches\n","\n","        \n","        \n","        \n","        \n","        \n","        if epoch%save_every==0:\n","\n","            directory=os.path.join(save_dir,model_name,corpus_name)\n","            if not os.path.exists(directory):\n","                os.makedirs(directory)\n","            \n","            torch.save({\n","                \"epoch\":epoch,\n","                \"encoder\":encoder.state_dict(),\n","                \"decoder\":decoder.state_dict(),\n","                \"loss\":loss,\n","                \"encoder_opt\":encoder_optimizer.state_dict(),\n","                \"decoder_opt\":decoder_optimizer.state_dict(),\n","                \"ppl\":perplexity,\n","                \"time\":time_taken\n","\n","            },os.path.join(directory,'{}_{}.tar'.format(epoch,\"checkpoint\")))\n","        \n","        print(\"=\"*100)\n","        print(\"| End of epoch : \"+str(epoch)+\"| Loss Value: \"+str(loss)+\"| PPL: \"+str(perplexity)+\"| Time Took: \"+\n","            str(time.time()-t1)+\" |\")\n","        print(\"=\"*100)\n","        time_taken+=(time.time()-t1)\n","\n","    print(\"| Training Finished | Took:\"+str(time_taken))          \n","        \n","\n","        \n","\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9D6B5hoG5mfA","colab_type":"code","colab":{}},"source":["model_name='seq2seq_attn'\n","corpus_name='cornell-movie'\n","\n","attn_model='dot'\n","num_encoder=2\n","num_decoder=2\n","d_model=500\n","dropout_encoder=0.1\n","dropout_decoder=0.1\n","\n","batch_size=10\n","n_batches=4000\n","\n","clip=50.0\n","teacher_forcing_ratio=1.0\n","learning_rate=0.0001\n","decoder_learning_ratio=5.0\n","\n","\n","save_every=10\n","n_epochs=100\n","\n","loadFile=None\n","\n","save_dir=\"/content/drive/My Drive/Model Data\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LkB9JkW15omn","colab_type":"code","outputId":"71999bab-bd9f-4955-964f-22f7b8ab3918","executionInfo":{"status":"ok","timestamp":1586879420390,"user_tz":-330,"elapsed":241920,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["\n","encoder,decoder=make_model(voc.num_words,d_model,num_encoder,num_decoder,dropout_encoder,dropout_decoder,attn_model)\n","\n","encoder_optimizer=torch.optim.Adam(encoder.parameters(),lr=learning_rate)\n","decoder_optimizer=torch.optim.Adam(decoder.parameters(),lr=learning_rate*decoder_learning_ratio)\n","\n","if loadFile:\n","    checkpoint=torch.load(loadFile)\n","\n","    encoder.load_state_dict(checkpoint['encoder'])\n","    decoder.load_state_dict(checkpoint['decoder'])\n","    encoder_optimizer.load_state_dict(checkpoint['encoder_opt'])\n","    decoder_optimizer.load_state_dict(checkpoint['decoder_opt'])\n","\n","\n","\n","encoder.to(device)\n","decoder.to(device)\n","\n","encoder.train()\n","decoder.train()\n","\n","trainIters(model_name, voc, pairs, encoder, decoder, encoder_optimizer, decoder_optimizer,\n","        num_encoder, num_decoder, save_dir, n_batches, batch_size, save_every, clip, corpus_name, loadFile,n_epochs)\n","\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if __name__ == '__main__':\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  if sys.path[0] == '':\n"],"name":"stderr"},{"output_type":"stream","text":["====================================================================================================\n","| End of epoch : 0| Loss Value: 4.152545327685159| PPL: 86.01618399549304| Time Took: 198.23842644691467 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 1| Loss Value: 3.6232382519304642| PPL: 40.298237671514116| Time Took: 196.15008091926575 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 2| Loss Value: 3.3704484115224105| PPL: 31.14305495654695| Time Took: 195.85544800758362 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 3| Loss Value: 3.1318964929252755| PPL: 24.419701989913396| Time Took: 197.13641548156738 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 4| Loss Value: 2.900815524191824| PPL: 19.289898771044157| Time Took: 199.82047200202942 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 5| Loss Value: 2.681201021908417| PPL: 15.406344100266232| Time Took: 199.241685628891 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 6| Loss Value: 2.475289223256993| PPL: 12.480888803767423| Time Took: 197.81722450256348 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 7| Loss Value: 2.284690294919316| PPL: 10.270472319032148| Time Took: 197.65589904785156 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 8| Loss Value: 2.105462072947545| PPL: 8.550925036201017| Time Took: 199.21004962921143 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 9| Loss Value: 1.944942971017696| PPL: 7.255516038062936| Time Took: 199.2591049671173 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 10| Loss Value: 1.7959522354490909| PPL: 6.232375668703646| Time Took: 198.75240540504456 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 11| Loss Value: 1.6624389333790424| PPL: 5.442055232284313| Time Took: 198.24655938148499 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 12| Loss Value: 1.5384850297121437| PPL: 4.795933973572862| Time Took: 198.5464117527008 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 13| Loss Value: 1.426273028013708| PPL: 4.277755217988844| Time Took: 199.28736329078674 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 14| Loss Value: 1.3227706149314975| PPL: 3.851372246606235| Time Took: 198.55041551589966 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 15| Loss Value: 1.2317398567379183| PPL: 3.5110669928216662| Time Took: 198.11435532569885 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 16| Loss Value: 1.1439587724905604| PPL: 3.2114284793006873| Time Took: 198.01654505729675 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 17| Loss Value: 1.0633484390226524| PPL: 2.9575918165758033| Time Took: 198.44383907318115 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 18| Loss Value: 0.9943841988153886| PPL: 2.7585132088113955| Time Took: 196.47007846832275 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 19| Loss Value: 0.9236326552302433| PPL: 2.567250563474035| Time Took: 195.11240887641907 |\n","====================================================================================================\n","====================================================================================================\n","| End of epoch : 20| Loss Value: 0.8655039148750172| PPL: 2.419907752648178| Time Took: 196.82369375228882 |\n","====================================================================================================\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Seh_alH2ksB9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"d49194a7-a1eb-4bd7-da86-8065014c2b3c","executionInfo":{"status":"ok","timestamp":1586966548980,"user_tz":-330,"elapsed":1872,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}}},"source":["for p in encoder.named_parameters():\n","    print(p)"],"execution_count":150,"outputs":[{"output_type":"stream","text":["('embedding.weight', Parameter containing:\n","tensor([[-0.0169,  0.0251,  0.0204,  ...,  0.0075,  0.0139,  0.0120],\n","        [ 0.0124,  0.0165,  0.0065,  ..., -0.0221,  0.0064,  0.0141],\n","        [-0.0076,  0.0232, -0.0088,  ...,  0.0180,  0.0148,  0.0076],\n","        ...,\n","        [-0.0122,  0.0191,  0.0154,  ..., -0.0023, -0.0032, -0.0015],\n","        [-0.0190,  0.0204,  0.0163,  ...,  0.0105, -0.0007, -0.0261],\n","        [ 0.0197,  0.0206, -0.0006,  ..., -0.0121,  0.0172,  0.0114]],\n","       device='cuda:0'))\n","('gru.weight_ih_l0', Parameter containing:\n","tensor([[-0.0411, -0.0188, -0.0036,  ..., -0.0146, -0.0212,  0.0180],\n","        [ 0.0507,  0.0262, -0.0105,  ..., -0.0385,  0.0167, -0.0551],\n","        [ 0.0147,  0.0347,  0.0093,  ..., -0.0529,  0.0524,  0.0382],\n","        ...,\n","        [-0.0365, -0.0202,  0.0214,  ...,  0.0426, -0.0402, -0.0249],\n","        [-0.0012,  0.0068,  0.0317,  ..., -0.0310, -0.0315,  0.0405],\n","        [-0.0432,  0.0164, -0.0080,  ...,  0.0012,  0.0052, -0.0178]],\n","       device='cuda:0', requires_grad=True))\n","('gru.weight_hh_l0', Parameter containing:\n","tensor([[ 0.0172, -0.0431,  0.0155,  ...,  0.0008,  0.0324, -0.0387],\n","        [ 0.0225,  0.0448, -0.0458,  ..., -0.0023, -0.0020, -0.0008],\n","        [-0.0142,  0.0490,  0.0253,  ..., -0.0172,  0.0224, -0.0255],\n","        ...,\n","        [ 0.0321, -0.0035,  0.0135,  ..., -0.0259, -0.0232, -0.0385],\n","        [ 0.0134,  0.0239,  0.0487,  ...,  0.0163, -0.0343,  0.0138],\n","        [ 0.0219, -0.0389,  0.0135,  ...,  0.0229,  0.0183, -0.0320]],\n","       device='cuda:0', requires_grad=True))\n","('gru.bias_ih_l0', Parameter containing:\n","tensor([ 0.0190, -0.0201,  0.0456,  ..., -0.0071, -0.0389, -0.0044],\n","       device='cuda:0', requires_grad=True))\n","('gru.bias_hh_l0', Parameter containing:\n","tensor([ 0.0208,  0.0270, -0.0074,  ...,  0.0367, -0.0320,  0.0132],\n","       device='cuda:0', requires_grad=True))\n","('gru.weight_ih_l0_reverse', Parameter containing:\n","tensor([[-0.0667, -0.0582, -0.0458,  ...,  0.0193, -0.0065,  0.0082],\n","        [-0.0358, -0.0426,  0.0401,  ...,  0.0466, -0.0105,  0.0386],\n","        [ 0.0494,  0.0395,  0.0183,  ...,  0.0004,  0.0246,  0.0082],\n","        ...,\n","        [-0.0044, -0.0483,  0.0427,  ...,  0.0383, -0.0330, -0.0443],\n","        [-0.0546,  0.0293,  0.0205,  ..., -0.0552, -0.0412,  0.0407],\n","        [ 0.0457,  0.0611, -0.0033,  ...,  0.0169,  0.0464,  0.0106]],\n","       device='cuda:0', requires_grad=True))\n","('gru.weight_hh_l0_reverse', Parameter containing:\n","tensor([[-0.0239, -0.0395, -0.0388,  ..., -0.0446,  0.0383, -0.0163],\n","        [-0.0326, -0.0292, -0.0143,  ..., -0.0072,  0.0543, -0.0393],\n","        [ 0.0316, -0.0051, -0.0394,  ...,  0.0043,  0.0507, -0.0022],\n","        ...,\n","        [-0.0102, -0.0195,  0.0257,  ..., -0.0493,  0.0007,  0.0078],\n","        [ 0.0279, -0.0367, -0.0209,  ..., -0.0002, -0.0544,  0.0179],\n","        [ 0.0447, -0.0429,  0.0411,  ...,  0.0258,  0.0309,  0.0241]],\n","       device='cuda:0', requires_grad=True))\n","('gru.bias_ih_l0_reverse', Parameter containing:\n","tensor([ 0.0279,  0.0312,  0.0054,  ..., -0.0070,  0.0255,  0.0227],\n","       device='cuda:0', requires_grad=True))\n","('gru.bias_hh_l0_reverse', Parameter containing:\n","tensor([ 0.0141,  0.0194, -0.0130,  ..., -0.0265,  0.0143,  0.0150],\n","       device='cuda:0', requires_grad=True))\n","('gru.weight_ih_l1', Parameter containing:\n","tensor([[-0.0236, -0.0116,  0.0292,  ..., -0.0402,  0.0323, -0.0171],\n","        [-0.0233, -0.0186,  0.0203,  ...,  0.0382,  0.0182,  0.0347],\n","        [-0.0438,  0.0142, -0.0322,  ..., -0.0003, -0.0062,  0.0139],\n","        ...,\n","        [-0.0047,  0.0473,  0.0106,  ..., -0.0258, -0.0212, -0.0472],\n","        [-0.0381,  0.0481,  0.0237,  ..., -0.0381, -0.0059,  0.0016],\n","        [ 0.0171, -0.0077, -0.0260,  ..., -0.0065, -0.0112, -0.0328]],\n","       device='cuda:0', requires_grad=True))\n","('gru.weight_hh_l1', Parameter containing:\n","tensor([[ 0.0148,  0.0362,  0.0150,  ...,  0.0096, -0.0516, -0.0354],\n","        [-0.0286, -0.0342,  0.0377,  ..., -0.0138,  0.0099, -0.0316],\n","        [-0.0113,  0.0207, -0.0515,  ...,  0.0155,  0.0508, -0.0030],\n","        ...,\n","        [ 0.0322,  0.0165,  0.0406,  ..., -0.0355, -0.0302, -0.0372],\n","        [-0.0437, -0.0146,  0.0146,  ..., -0.0252,  0.0338,  0.0461],\n","        [ 0.0537,  0.0614, -0.0078,  ..., -0.0299, -0.0205,  0.0140]],\n","       device='cuda:0', requires_grad=True))\n","('gru.bias_ih_l1', Parameter containing:\n","tensor([ 0.0015,  0.0088,  0.0162,  ...,  0.0366, -0.0070, -0.0200],\n","       device='cuda:0', requires_grad=True))\n","('gru.bias_hh_l1', Parameter containing:\n","tensor([ 0.0474, -0.0239, -0.0042,  ..., -0.0026,  0.0110,  0.0055],\n","       device='cuda:0', requires_grad=True))\n","('gru.weight_ih_l1_reverse', Parameter containing:\n","tensor([[-0.0251, -0.0055, -0.0021,  ..., -0.0039,  0.0132,  0.0244],\n","        [-0.0504,  0.0051, -0.0346,  ...,  0.0072, -0.0228,  0.0043],\n","        [ 0.0005,  0.0093,  0.0448,  ..., -0.0018, -0.0051, -0.0214],\n","        ...,\n","        [-0.0074, -0.0220,  0.0046,  ...,  0.0404,  0.0165, -0.0098],\n","        [ 0.0066, -0.0246, -0.0174,  ..., -0.0157,  0.0459,  0.0293],\n","        [ 0.0158, -0.0141, -0.0069,  ...,  0.0229,  0.0406,  0.0376]],\n","       device='cuda:0', requires_grad=True))\n","('gru.weight_hh_l1_reverse', Parameter containing:\n","tensor([[ 0.0128,  0.0316,  0.0295,  ...,  0.0029, -0.0228,  0.0361],\n","        [-0.0463,  0.0014, -0.0129,  ..., -0.0558,  0.0390,  0.0126],\n","        [-0.0400,  0.0423,  0.0280,  ..., -0.0067,  0.0011,  0.0489],\n","        ...,\n","        [-0.0516,  0.0053, -0.0121,  ...,  0.0236, -0.0237, -0.0456],\n","        [-0.0270,  0.0097, -0.0353,  ...,  0.0604,  0.0439, -0.0365],\n","        [-0.0151, -0.0375, -0.0256,  ...,  0.0711, -0.0041,  0.0393]],\n","       device='cuda:0', requires_grad=True))\n","('gru.bias_ih_l1_reverse', Parameter containing:\n","tensor([-6.2691e-03, -4.5462e-02,  3.0999e-02,  ...,  1.1390e-02,\n","         9.5689e-05, -3.2152e-02], device='cuda:0', requires_grad=True))\n","('gru.bias_hh_l1_reverse', Parameter containing:\n","tensor([-0.0037, -0.0073,  0.0465,  ...,  0.0289,  0.0106,  0.0002],\n","       device='cuda:0', requires_grad=True))\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OA5TjKYt5hhA","colab_type":"code","colab":{}},"source":["class GreedySearchDecoder(nn.Module):\n","    \n","    def __init__(self,encoder,decoder):\n","        super().__init__()\n","        \n","        self.encoder=encoder\n","        self.decoder=decoder\n","        \n","    def forward(self,input_seq,input_length,max_length):\n","        \n","        encoder_outputs,encoder_hidden=self.encoder(input_seq,input_length)\n","        \n","        decoder_hidden=encoder_hidden[:decoder.n_layers]\n","#         print(\"Decoder hidden state: \"+str(decoder_hidden))\n","        decoder_input=torch.ones(1,1,device=device,dtype=torch.long)*START_Token\n","        \n","        \n","#         print(\"Decoder's Input: \"+str(decoder_input))\n","        all_tokens=torch.zeros([0],device=device,dtype=torch.long)\n","        all_scores=torch.zeros([0],device=device)\n","        \n","        for _ in range(max_length):\n","            \n","            decoder_output,decoder_hidden=self.decoder(decoder_input,decoder_hidden,encoder_outputs)\n","#             print(\"Decoder Output: \"+str(decoder_output))\n","            decoder_scores,decoder_input=torch.max(decoder_output,dim=1)\n","            all_scores=torch.cat((all_scores,decoder_scores),dim=0)\n","            all_tokens=torch.cat((all_tokens,decoder_input),dim=0)\n","            \n","            decoder_input=torch.unsqueeze(decoder_input,0)\n","            \n","        return all_tokens, all_scores\n","        \n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EhpBX3QT5kCf","colab_type":"code","colab":{}},"source":["def evaluate(encoder, decoder, searcher,voc,sentence,max_length=MAX_LENGTH):\n","    \n","    index_batch=[indexesFromSentence(voc,sentence)]\n","#     print(\"Indexed sentence: \"+str(index_batch))\n","    lengths=torch.tensor([len(index) for index in index_batch])\n","#     print(\"The Lengths tensor: \"+str(lengths))\n","    input_batch=torch.LongTensor(index_batch).transpose(0,1)\n","    \n","    input_batch=input_batch.to(device)\n","    lengths=lengths.to(device)\n","    \n","    tokens, scores=searcher(input_batch,lengths,max_length)\n","#     print(\"The tokens: \"+str(tokens))\n","    decoded_words=[voc.index2word[token.item()] for token in tokens]\n","    return decoded_words\n","\n","def evaluateInput(encoder,decoder,searcher,voc):\n","    input_sentence=''\n","    while True:\n","        try:\n","            input_sentence=input('Human> ')\n","            \n","            if input_sentence=='q' or input_sentence=='quit':\n","                break\n","            input_sentence=normalizeString(input_sentence)\n","#             print(\"The Normalized Input Sentence: \"+str(input_sentence))\n","            output_words=evaluate(encoder,decoder,searcher,voc,input_sentence)\n","            \n","            output_words[:]=[x for x in output_words if not(x==\"PAD\" or x==\"EOS\")]\n","            print(\"Bot:\",\" \".join(output_words))\n","            \n","        except KeyError:\n","            print(\"Unknown Word\")\n","            \n","            \n","    "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Bk193gyI54Iv","colab_type":"code","outputId":"3e2f02da-1ef4-418b-dda1-e7b5e4965329","executionInfo":{"status":"ok","timestamp":1586879441242,"user_tz":-330,"elapsed":1273,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["encoder.eval()\n","decoder.eval()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LuongAttnDecoderRNN(\n","  (embedding): Embedding(7816, 500)\n","  (embedding_dropout): Dropout(p=0.1, inplace=False)\n","  (gru): GRU(500, 500, num_layers=2, dropout=0.1)\n","  (concat): Linear(in_features=1000, out_features=500, bias=True)\n","  (out): Linear(in_features=500, out_features=7816, bias=True)\n","  (attn): Attn()\n",")"]},"metadata":{"tags":[]},"execution_count":28}]},{"cell_type":"code","metadata":{"id":"VoxgXE87-169","colab_type":"code","outputId":"fa23150c-f8b1-4831-a3e0-385a0c74f637","executionInfo":{"status":"error","timestamp":1586879568292,"user_tz":-330,"elapsed":124334,"user":{"displayName":"deepak goyal","photoUrl":"https://lh5.googleusercontent.com/-3gfEZruD9Sk/AAAAAAAAAAI/AAAAAAAACvg/54H4lMsdOgA/s64/photo.jpg","userId":"05164064759516400423"}},"colab":{"base_uri":"https://localhost:8080/","height":779}},"source":["searcher=GreedySearchDecoder(encoder,decoder)\n","evaluateInput(encoder,decoder,searcher,voc)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Human> hello\n","Bot: hi . to go . .\n","Human> goodbye\n","Bot: you re not a good idea . .\n","Human> how do you do\n","Bot: i m not going to be . .\n","Human> what do you do\n","Bot: i m not going to be . .\n","Human> where do you live\n","Bot: i m not going to be .\n","Human> what are you daying\n","Unknown Word\n","Human> who are you\n","Bot: i m not going to be . .\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    474\u001b[0m         \"\"\"\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: ","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-62ea121ae24b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msearcher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGreedySearchDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluateInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msearcher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-25-9eaf0c6e4e3e>\u001b[0m in \u001b[0;36mevaluateInput\u001b[0;34m(encoder, decoder, searcher, voc)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0minput_sentence\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Human> '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'q'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minput_sentence\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'quit'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"pAvPOTMXZ-Ic","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}
